{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98a7df89-4e5e-4b18-bf50-a6b5d2ff22b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential Jupyter Notebook Magic\n",
    "%matplotlib inline\n",
    "\n",
    "# General Purpose and Data Handling Libraries\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from natsort import natsorted\n",
    "import pickle\n",
    "from operator import add\n",
    "import random\n",
    "\n",
    "# MatPlotlib for Plotting and Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.tri as tri\n",
    "import matplotlib as mpl\n",
    "from matplotlib import cm, ticker\n",
    "from matplotlib.colors import LogNorm, LightSource, ListedColormap, BoundaryNorm\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib.ticker import LogFormatter, LogFormatterSciNotation\n",
    "from matplotlib.ticker import LogLocator, MultipleLocator, NullFormatter\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from streamtracer import StreamTracer, VectorGrid\n",
    "\n",
    "# Scipy for Scientific Computing and Analysis\n",
    "from scipy import stats, interpolate\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.interpolate import interp1d, griddata\n",
    "from scipy.ndimage import label, gaussian_filter\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "\n",
    "# Image Handling and Processing\n",
    "from PIL import Image\n",
    "\n",
    "# Tecplot for Scientific Data Visualization\n",
    "import tecplot as tp\n",
    "from tecplot.exception import *\n",
    "from tecplot.constant import *\n",
    "\n",
    "# For 3d plotting\n",
    "from skimage import measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f627e04a-7246-448b-9ecd-f1e5b7e8c3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Constants\n",
    "amu = 1.67e-27\n",
    "k_b = 1.38e-23\n",
    "mu_0 = 1.257e-6\n",
    "R_M = 2440e3 #m\n",
    "m_p = 1.67e-27 # kg\n",
    "e = 1.60218e-19 # C\n",
    "\n",
    "# Define utility functions\n",
    "def read_dataset(mypath):\n",
    "    # Reads in file \"mypath\" and returns a dataset object. May take a while for larger files.\n",
    "\n",
    "    print(\"reading:\",mypath)\n",
    "    # First connect to TecPlot\n",
    "    tp.session.connect(port=7600)\n",
    "\n",
    "    # Configure layout\n",
    "    tp.new_layout()\n",
    "    dataset = tp.data.load_tecplot(mypath)\n",
    "    frame = tp.active_frame()\n",
    "    frame.plot_type = PlotType.Cartesian3D\n",
    "\n",
    "    # Return dataset\n",
    "    return dataset\n",
    "\n",
    "def Bz_dip(x_array,y_array,z_array):\n",
    "    # Input: arrays of x,y,z (in planet centered coords).\n",
    "    # Output: Bz at each point\n",
    "    \n",
    "    return - 200.9 * (3*(z_array-0.2)**2 - (x_array**2+y_array**2+(z_array-0.2)**2))/((x_array**2+y_array**2+(z_array-0.2)**2)**(5/2))\n",
    "\n",
    "def get_files(dir, key=\".*cut_particle_region0_0.*\", read_time = False, reduce = True):\n",
    "    # For a directory \"dir\", return a list of all files which match the regex expression \"key\"\n",
    "    \n",
    "    all_files = [f for f in listdir(dir) if isfile(join(dir, f))]\n",
    "    files=[]\n",
    "    for file in all_files:\n",
    "        match = re.search(key,file)\n",
    "        if match != None:\n",
    "            files.append(file)\n",
    "    files.sort()\n",
    "    \n",
    "    # Now give them the appropriate name for their time\n",
    "    # If we haven't already named these files with their time, do that now\n",
    "    named_files = {}\n",
    "    if read_time == False:\n",
    "        for i in range(len(files)):\n",
    "            time = round(i*dt+start_time,3)\n",
    "            named_files[time] = files[i]\n",
    "    # Otherwise, read the time right from the (last 6 elements) filename\n",
    "    else:\n",
    "        for i in range(len(files)):\n",
    "            time = str(\"%.2f\"%float(files[i][-6:]))\n",
    "            named_files[time] = files[i]        \n",
    "    \n",
    "    # Now cut the list down to files inside t_bound\n",
    "    if reduce:\n",
    "        reduced_files = {}\n",
    "        for time in list(named_files.keys())[int((t_bound[0]-start_time)/dt):int((t_bound[1]-start_time)/dt)]: #only loop over the times within t_bound\n",
    "            reduced_files[time] = str(named_files[time])\n",
    "        return reduced_files\n",
    "\n",
    "    else:\n",
    "        return named_files\n",
    "\n",
    "def dat_to_plt(dir,files):\n",
    "    # Hand it a directory with the dict of files in it, and it will convert them to .plt and save in dir\n",
    "    \n",
    "    for file in files:\n",
    "        dataset=read_dataset(str(dir+files[file]))\n",
    "        print(\"saving file:\",str(dir+files[file][:-3]+\"plt\"))\n",
    "        tp.data.save_tecplot_plt(str(dir+files[file][:-3]+\"plt\"))\n",
    "        os.remove(str(dir+files[file]))\n",
    "        print(f\"Deleted original .dat file: {files[file]}\")\n",
    "\n",
    "def plt_to_numpy(dataset,var_ls=[\"Bz\"],save_cs = True):\n",
    "    # Input: the path to a .plt file, and a list of variables to convert into a numpy meshgrid\n",
    "    # Output: a dictionary of arrays, each labelled according to its name in var_ls\n",
    "    # Var_ls should be *extensive*, so that this long process does not need to be rerun\n",
    "\n",
    "    # Extract the coordinate axes\n",
    "    x_axis = np.unique(dataset.variable(\"X\").values(0).as_numpy_array())\n",
    "    y_axis = np.unique(dataset.variable(\"Y\").values(0).as_numpy_array())[1:-1]\n",
    "    z_axis = np.unique(dataset.variable(\"Z\").values(0).as_numpy_array())\n",
    "\n",
    "    # Create an ordered zone\n",
    "    rect_zone = dataset.add_ordered_zone('rect_zone',[len(x_axis),len(y_axis-2),len(z_axis)])\n",
    "\n",
    "    # Create 3D coordinate meshgrids\n",
    "    xxx,yyy,zzz = np.meshgrid(x_axis,y_axis,z_axis)\n",
    "\n",
    "    # Assign coordinate values to the rect_zone using the meshgrids\n",
    "    rect_zone.values('X')[:] = xxx.ravel()\n",
    "    rect_zone.values('Y')[:] = yyy.ravel()\n",
    "    rect_zone.values('Z')[:] = zzz.ravel()\n",
    "\n",
    "    # Compute derivatives in tecplot, which does it efficiently\n",
    "    # Compute current density, in A/m^2\n",
    "    if (\"Jx\" in var_ls) or (\"Jy\" in var_ls) or (\"Jz\" in var_ls):\n",
    "        print(\"Computing J = ∇xB\")\n",
    "        tp.data.operate.execute_equation(equation='{Jx} = (ddy({Bz}) - ddz({By}))/(1.2566*10**(-6))/2440000*10**(-9)',\n",
    "            ignore_divide_by_zero=True)\n",
    "        tp.data.operate.execute_equation(equation='{Jy} = (ddz({Bx}) - ddx({Bz}))/(1.2566*10**(-6))/2440000*10**(-9)',\n",
    "            ignore_divide_by_zero=True)\n",
    "        tp.data.operate.execute_equation(equation='{Jz} = (ddx({By}) - ddy({Bx}))/(1.2566*10**(-6))/2440000*10**(-9)',\n",
    "            ignore_divide_by_zero=True)\n",
    "\n",
    "    # Compute plasma pressure gradient, in nPa / m\n",
    "    if (\"dp_dx\" in var_ls) or (\"dp_dy\" in var_ls) or (\"dp_dz\" in var_ls):\n",
    "        print(\"Computing ∇$p$\")\n",
    "        tp.data.operate.execute_equation(equation='{dp_dx} = (ddx({pxxS1}+{pxxS0}+{pyyS1}+{pyyS0}+{pzzS1}+{pzzS0}))/3/2440000',\n",
    "        ignore_divide_by_zero=True)\n",
    "        tp.data.operate.execute_equation(equation='{dp_dy} = (ddy({pxxS1}+{pxxS0}+{pyyS1}+{pyyS0}+{pzzS1}+{pzzS0}))/3/2440000',\n",
    "            ignore_divide_by_zero=True)\n",
    "        tp.data.operate.execute_equation(equation='{dp_dz} = (ddz({pxxS1}+{pxxS0}+{pyyS1}+{pyyS0}+{pzzS1}+{pzzS0}))/3/2440000',\n",
    "            ignore_divide_by_zero=True)\n",
    "        \n",
    "    # Compute magnetic field gradient , in nT / m\n",
    "    if (\"dB_dx\" in var_ls) or (\"dB_dy\" in var_ls) or (\"dB_dz\" in var_ls): \n",
    "        print(\"Computing ∇B\")\n",
    "        tp.data.operate.execute_equation(equation='{dB_dx} = (ddx(({Bx}*{Bx}+{By}*{By}+{Bz}*{Bz})**(0.5)))/2440000',\n",
    "            ignore_divide_by_zero=True)\n",
    "        tp.data.operate.execute_equation(equation='{dB_dy} = (ddy(({Bx}*{Bx}+{By}*{By}+{Bz}*{Bz})**(0.5)))/2440000',\n",
    "            ignore_divide_by_zero=True)\n",
    "        tp.data.operate.execute_equation(equation='{dB_dz} = (ddz(({Bx}*{Bx}+{By}*{By}+{Bz}*{Bz})**(0.5)))/2440000',\n",
    "            ignore_divide_by_zero=True)\n",
    "\n",
    "    print(\"Beginning interpolation...\")\n",
    "    # Interpolate onto rect_zone\n",
    "    tp.data.operate.interpolate_linear(source_zones=[0],\n",
    "        destination_zone=1,\n",
    "        fill_value=0)\n",
    "\n",
    "    # Define dictionary to save results\n",
    "    data3d = {\"X\":xxx,\"Y\":yyy,\"Z\":zzz}\n",
    "\n",
    "    # All all variables to data\n",
    "    for var in var_ls:\n",
    "        data3d[var] = rect_zone.values(var).as_numpy_array().reshape(xxx.shape)\n",
    "\n",
    "    # Save in place\n",
    "    print(\"Extraction complete! Saving 3D data ...\")\n",
    "    save_file = open(str(dir+file[:-4]+\"_numpy_t_\"+'{:06.2f}'.format(round(time,2))), 'wb') \n",
    "    pickle.dump(data3d, save_file) \n",
    "    print(\"Done!\")\n",
    "\n",
    "    if save_cs:\n",
    "        #Calculate the plasma beta meshgrid\n",
    "        beta_meshgrid = (2*mu_0*(rect_zone.values(\"pxxS0\").as_numpy_array()+rect_zone.values(\"pyyS0\").as_numpy_array()+rect_zone.values(\"pzzS0\").as_numpy_array()+rect_zone.values(\"pxxS1\").as_numpy_array()+\n",
    "                                rect_zone.values(\"pyyS1\").as_numpy_array()+rect_zone.values(\"pzzS1\").as_numpy_array())*1e9/3/(rect_zone.values(\"Bx\").as_numpy_array()**2+rect_zone.values(\"By\").as_numpy_array()**2+rect_zone.values(\"Bz\").as_numpy_array()**2)).reshape(xxx.shape)\n",
    "        beta_meshgrid[np.isnan(beta_meshgrid)] = -1\n",
    "        \n",
    "         # New code: extract all of the Z coords, smooth them, and then find the values interpolated to those points!\n",
    "        data = {\"X\":xxx[:,:,0],\"Y\":yyy[:,:,0]} #, \"Z\":np.zeros_like(xxx[:,:,0])}\n",
    "        print(\"Saving cs data...\")\n",
    "        # Define empty array to save the unsmoothed Z values to\n",
    "        Z_rough = np.zeros_like(xxx[:,:,0])+0.2\n",
    "        # At each x/y, find the z coord of max beta and save that\n",
    "        for idy in range(len(yyy[:,0,0])):\n",
    "            for idx in range(len(xxx[0,:,0])):\n",
    "                # If any of the beta values in this column are -1 near the middle, that means we are at the inner edge of the bounding box\n",
    "                # In this case, set the data value to 0 to let me know where the boundary is!\n",
    "                if np.min(beta_meshgrid[idy,idx,len(z_axis)//4:-len(z_axis)//4]) == -1:\n",
    "                    Z_rough[idy,idx] = 0.2\n",
    "                else:\n",
    "                    idz = np.argmax(beta_meshgrid[idy,idx,:])\n",
    "                    Z_rough[idy,idx] = zzz[idy,idx,idz]\n",
    "    \n",
    "        # Smoothing parameter\n",
    "        smoothing_param = 5\n",
    "        # Smooth the Z meshgrid\n",
    "        data['Z'] = smooth_meshgrid(xxx[:,:,0], yyy[:,:,0], Z_rough, smoothing_param)\n",
    "    \n",
    "        # Use this as a template to extract all the other data with\n",
    "        for name in var_ls:\n",
    "            data[name] = np.zeros_like(xxx[:,:,0])\n",
    "    \n",
    "            # Extract each variable from tecplot as an array\n",
    "            var = rect_zone.values(name).as_numpy_array().reshape(xxx.shape)\n",
    "    \n",
    "            # At each x/y, find the z coord of max beta and save that\n",
    "            for idy in range(len(yyy[:,0,0])):\n",
    "                for idx in range(len(xxx[0,:,0])):\n",
    "                    # If any of the beta values in this column are -1 near the middle, that means we are at the inner edge of the bounding box\n",
    "                    # In this case, set the data value to 0 to let me know where the boundary is!\n",
    "                    if np.min(beta_meshgrid[idy,idx,len(z_axis)//4:-len(z_axis)//4]) == -1:\n",
    "                        data[name][idy,idx] = 0\n",
    "                    else:\n",
    "                        # Find the indices of the two nearest points\n",
    "                        lower_idz = np.searchsorted(zzz[idy,idx,:], data['Z'][idy,idx]) - 1\n",
    "                        upper_idz = lower_idz + 1\n",
    "    \n",
    "                        # Get the coordinates of the nearest points\n",
    "                        Z_lower = zzz[idy,idx,lower_idz]\n",
    "                        Z_upper = zzz[idy,idx,upper_idz]\n",
    "                        var_lower = var[idy,idx,lower_idz]\n",
    "                        var_upper = var[idy,idx,upper_idz]\n",
    "                        \n",
    "                        # Perform linear interpolation\n",
    "                        data[name][idy,idx] = var_lower + (var_upper - var_lower) * (data['Z'][idy,idx] - Z_lower) / (Z_upper - Z_lower)\n",
    "    \n",
    "        print(\"Done!\")\n",
    "        save_file = open(str(dir+file[:-4]+\"_csdata_t_\"+'{:06.2f}'.format(round(time,2))), 'wb') \n",
    "        pickle.dump(data, save_file) \n",
    "\n",
    "\n",
    "def smooth_meshgrid(X, Y, Z, smoothing_param):\n",
    "    \"\"\"\n",
    "    Smooth the Z values of a meshgrid defined by X, Y coordinates using a Gaussian filter.\n",
    "    \n",
    "    Parameters:\n",
    "    X (2D numpy array): The X coordinates of the meshgrid.\n",
    "    Y (2D numpy array): The Y coordinates of the meshgrid.\n",
    "    Z (2D numpy array): The Z coordinates of the meshgrid.\n",
    "    smoothing_param (float): The standard deviation for the Gaussian kernel, controlling the smoothing.\n",
    "    \n",
    "    Returns:\n",
    "    Z_smoothed (2D numpy array): The smoothed Z values of the meshgrid.\n",
    "    \"\"\"\n",
    "    # Check if X, Y, Z are of the same shape\n",
    "    if X.shape != Y.shape or X.shape != Z.shape:\n",
    "        raise ValueError(\"X, Y, and Z meshgrids must have the same shape\")\n",
    "    \n",
    "    # Apply Gaussian filter to the Z meshgrid\n",
    "    Z_smoothed = gaussian_filter(Z, sigma=smoothing_param)\n",
    "    \n",
    "    return Z_smoothed\n",
    "\n",
    "def plot_sphere(ax, radius=1, center=(0, 0, 0), color='b', alpha=0.5, zorder = 1,quarter=False, xlims = [-10,10], ylims = [-10,10], zlims = [-10,10]):\n",
    "    \"\"\"\n",
    "    Plots a sphere of given radius centered at center on the provided 3D axis.\n",
    "    \n",
    "    Parameters:\n",
    "    - ax: The 3D axis to plot the sphere on.\n",
    "    - radius: The radius of the sphere (default: 1).\n",
    "    - center: The (x, y, z) coordinates of the sphere's center (default: (0, 0, 0)).\n",
    "    - color: The color of the sphere (default: blue).\n",
    "    - alpha: The transparency of the sphere (default: 0.5).\n",
    "    \"\"\"\n",
    "    u = np.linspace(np.pi/2, 3/2 * np.pi, 100)\n",
    "    if quarter:\n",
    "        v = np.linspace(0, np.pi/2, 100)\n",
    "    else:\n",
    "        v = np.linspace(0, np.pi, 100)\n",
    "    x = radius * np.outer(np.cos(u), np.sin(v)) + center[0]\n",
    "    y = radius * np.outer(np.sin(u), np.sin(v)) + center[1]\n",
    "    z = radius * np.outer(np.ones(np.size(u)), np.cos(v)) + center[2]\n",
    "\n",
    "    # Mask out any values outside the axes lims\n",
    "    mask = (x < xlims[0]) | (x > xlims[1]) | (y < ylims[0]) | (y > ylims[1]) | (z < zlims[0]) | (z > zlims[1]) \n",
    "    x[mask] = np.nan\n",
    "    y[mask] = np.nan\n",
    "    z[mask] = np.nan\n",
    "\n",
    "    ax.plot_surface(x, y, z, color=color, alpha=alpha, zorder=zorder)\n",
    "\n",
    "def average_value(var_ls,t0,t_start,t_stop,type='csdata'):\n",
    "    # Input: Variables to average, the current time (t0), and the times relative to present to average over (t0+t_start to t0+t_stop)\n",
    "    # Ouput: dictionary of arrays of time-averaged values\n",
    "\n",
    "    averages = {}\n",
    "    count = 0\n",
    "\n",
    "    temp_files = get_files(dir,key=\"3d\\_fluid.*\"+type+\"\\_t\\_...\\...\",read_time = True, reduce = False)\n",
    "\n",
    "    for t in list(temp_files.keys()): \n",
    "        # Check to see if this file is in the time range we want\n",
    "        if (float(t) >= (t0+t_start)) and (float(t) <= t0+t_stop):\n",
    "            temp_file = str(temp_files[t])\n",
    "    \n",
    "            # Read in this data\n",
    "            with open(dir+temp_file, 'rb') as f:\n",
    "                temp_data = pickle.load(f) \n",
    "            \n",
    "            # Add the data to our running average for each variable\n",
    "            for var in var_ls:\n",
    "                if var not in averages.keys():\n",
    "                    averages[var] = temp_data[var]\n",
    "                else:\n",
    "                    averages[var] += temp_data[var]\n",
    "\n",
    "            count += 1\n",
    "        \n",
    "    # Divide by total time steps\n",
    "    for var in var_ls:\n",
    "        averages[var] = averages[var]/count\n",
    "\n",
    "    return averages\n",
    "\n",
    "def find_indices(X, Y, XX, YY):\n",
    "    # Function used to get ix and iy for some coordinates X and Y\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    XX = np.array(XX)\n",
    "    YY = np.array(YY)\n",
    "\n",
    "    ix = []\n",
    "    iy = []\n",
    "    \n",
    "    for (x, y) in zip(X, Y):\n",
    "        # Find the closest index in the meshgrid for the x coordinate\n",
    "        ix_index = np.abs(XX[0] - x).argmin()\n",
    "        # Find the closest index in the meshgrid for the y coordinate\n",
    "        iy_index = np.abs(YY[:, 0] - y).argmin()\n",
    "        \n",
    "        ix.append(ix_index)\n",
    "        iy.append(iy_index)\n",
    "        \n",
    "    return iy, ix\n",
    "\n",
    "def remove_duplicate_rows(arr):\n",
    "    # Used in df_tracker... does something to remove repeated rows in the matching matrix\n",
    "    seen = set()\n",
    "    filtered_rows = []\n",
    "    for row in arr:\n",
    "        if row[0] not in seen:\n",
    "            filtered_rows.append(row)\n",
    "            seen.add(row[0])\n",
    "    return np.array(filtered_rows)\n",
    "\n",
    "def find_boundary_points(X, Y):\n",
    "    # Combine the coordinate lists into a single array of points\n",
    "    points = np.column_stack((X, Y))\n",
    "\n",
    "    # Compute the convex hull of the points\n",
    "    hull = ConvexHull(points)\n",
    "\n",
    "    # Extract the boundary points\n",
    "    boundary_points = hull.vertices\n",
    "\n",
    "    # Boundary points in original coordinate lists\n",
    "    boundary_X = points[boundary_points, 0]\n",
    "    boundary_Y = points[boundary_points, 1]\n",
    "\n",
    "    return boundary_X.tolist(), boundary_Y.tolist()\n",
    "\n",
    "def create_above_surface_mask(X, Y, Z, XX, YY, ZZ):\n",
    "    # Works out all the 3D points above a 2D surface ie all the points above the current sheet.\n",
    "    # Used for 3D plotting to determine what is above what.\n",
    "    # Check that XX, YY, ZZ have the same shape\n",
    "    assert XX.shape == YY.shape == ZZ.shape, \"Arrays XX, YY, and ZZ must have the same shape\"\n",
    "    \n",
    "    # Check that X, Y, Z have the same shape\n",
    "    assert X.shape == Y.shape == Z.shape, \"Arrays X, Y, and Z must have the same shape\"\n",
    "\n",
    "    # Determine the shape of the input arrays\n",
    "    nx, ny, nz = XX.shape\n",
    "\n",
    "    # Initialize a mask with the same shape as ZZ\n",
    "    mask = np.zeros_like(ZZ, dtype=bool)\n",
    "\n",
    "    # Iterate over the entire 3D meshgrid\n",
    "    for i in range(nx):\n",
    "        for j in range(ny):\n",
    "            # Find the index in the 2D arrays corresponding to the x and y coordinates\n",
    "            xi = np.argmin(np.abs(X[0] - XX[i, j, 0]))\n",
    "            yi = np.argmin(np.abs(Y[:, 0] - YY[i, j, 0]))\n",
    "\n",
    "            # Compare ZZ with Z to determine the mask\n",
    "            mask[i, j, :] = ZZ[i, j, :] > Z[yi, xi]\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ea1adfd-cb2e-44ef-9653-b79ff295ceec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000111_n00032464_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000111_n00032464_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000111_n00032464_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000111_n00032491_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000111_n00032491_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000111_n00032491_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000111_n00032518_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000111_n00032518_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000111_n00032518_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000111_n00032545_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000111_n00032545_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000111_n00032545_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000111_n00032573_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000111_n00032573_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000111_n00032573_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000111_n00032601_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000111_n00032601_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000111_n00032601_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000111_n00032630_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000111_n00032630_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000111_n00032630_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000111_n00032659_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000111_n00032659_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000111_n00032659_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000111_n00032687_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000111_n00032687_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000111_n00032687_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000111_n00032717_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000111_n00032717_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000111_n00032717_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000111_n00032747_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000111_n00032747_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000111_n00032747_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000111_n00032778_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000111_n00032778_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000111_n00032778_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000111_n00032809_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000111_n00032809_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000111_n00032809_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000111_n00032840_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000111_n00032840_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000111_n00032840_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000111_n00032870_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000111_n00032870_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000111_n00032870_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000111_n00032898_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000111_n00032898_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000111_n00032898_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000111_n00032926_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000111_n00032926_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000111_n00032926_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000111_n00032954_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000111_n00032954_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000111_n00032954_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000112_n00032980_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000112_n00032980_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000112_n00032980_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000112_n00033007_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000112_n00033007_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000112_n00033007_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000112_n00033033_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000112_n00033033_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000112_n00033033_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000112_n00033059_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000112_n00033059_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000112_n00033059_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000112_n00033085_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000112_n00033085_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000112_n00033085_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000112_n00033112_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000112_n00033112_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000112_n00033112_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000112_n00033138_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000112_n00033138_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000112_n00033138_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000112_n00033165_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000112_n00033165_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000112_n00033165_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000112_n00033192_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000112_n00033192_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000112_n00033192_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000112_n00033218_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000112_n00033218_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000112_n00033218_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000112_n00033244_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000112_n00033244_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000112_n00033244_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000112_n00033270_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000112_n00033270_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000112_n00033270_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000112_n00033295_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000112_n00033295_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000112_n00033295_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000112_n00033320_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000112_n00033320_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000112_n00033320_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000112_n00033346_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000112_n00033346_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000112_n00033346_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000112_n00033371_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000112_n00033371_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000112_n00033371_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000112_n00033399_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000112_n00033399_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000112_n00033399_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000112_n00033429_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000112_n00033429_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000112_n00033429_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000112_n00033457_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000112_n00033457_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000112_n00033457_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000112_n00033483_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000112_n00033483_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000112_n00033483_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000113_n00033508_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000113_n00033508_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000113_n00033508_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000113_n00033533_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000113_n00033533_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000113_n00033533_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000113_n00033558_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000113_n00033558_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000113_n00033558_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000113_n00033583_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000113_n00033583_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000113_n00033583_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000113_n00033608_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000113_n00033608_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000113_n00033608_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000113_n00033634_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000113_n00033634_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000113_n00033634_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000113_n00033658_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000113_n00033658_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000113_n00033658_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000113_n00033683_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000113_n00033683_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000113_n00033683_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000113_n00033709_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000113_n00033709_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000113_n00033709_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000113_n00033734_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000113_n00033734_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000113_n00033734_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000113_n00033759_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000113_n00033759_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000113_n00033759_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000113_n00033783_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000113_n00033783_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000113_n00033783_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000113_n00033808_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000113_n00033808_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000113_n00033808_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000113_n00033834_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000113_n00033834_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000113_n00033834_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000113_n00033860_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000113_n00033860_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000113_n00033860_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000113_n00033886_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000113_n00033886_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000113_n00033886_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000113_n00033911_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000113_n00033911_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000113_n00033911_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000113_n00033937_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000113_n00033937_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000113_n00033937_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000113_n00033964_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000113_n00033964_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000113_n00033964_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000113_n00033989_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000113_n00033989_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000113_n00033989_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000114_n00034014_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n",
      "saving file: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000114_n00034014_amrex.plt\n",
      "Deleted original .dat file: 3d_fluid_region0_0_t00000114_n00034014_amrex.dat\n",
      "reading: /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/3d_fluid_region0_0_t00000114_n00034039_amrex.dat\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7600\n",
      "Connection established.\n"
     ]
    },
    {
     "ename": "ZMQError",
     "evalue": "Operation cannot be accomplished in current state",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tecplot/data/load.py:1906\u001b[0m, in \u001b[0;36mload_tecplot\u001b[0;34m(filenames, frame, read_data_option, reset_style, initial_plot_first_zone_only, initial_plot_type, zones, variables, collapse, skip, assign_strand_ids, add_zones_to_existing_strands, include_text, include_geom, include_custom_labels, include_data)\u001b[0m\n\u001b[1;32m   1905\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1906\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tecplot_loader_load_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1907\u001b[0m \u001b[43m        \u001b[49m\u001b[43marglist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread_data_option\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_data_option\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1908\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_style\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_style\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1909\u001b[0m \u001b[43m        \u001b[49m\u001b[43minitial_plot_first_zone_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_plot_first_zone_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1910\u001b[0m \u001b[43m        \u001b[49m\u001b[43minitial_plot_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_plot_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1911\u001b[0m \u001b[43m        \u001b[49m\u001b[43massign_strand_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43massign_strand_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1912\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_zones_to_existing_strands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_zones_to_existing_strands\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1913\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tecplot/data/load.py:58\u001b[0m, in \u001b[0;36m_tecplot_loader_load_data\u001b[0;34m(arglist, frame, read_data_option, reset_style, initial_plot_first_zone_only, initial_plot_type, assign_strand_ids, add_zones_to_existing_strands)\u001b[0m\n\u001b[1;32m     56\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(msg)\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43m_tecutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataSetReadX\u001b[49m\u001b[43m(\u001b[49m\u001b[43marglist\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TecplotSystemError()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tecplot/tecutil/preamble.py:26\u001b[0m, in \u001b[0;36mtecutil_preamble.<locals>._fn\u001b[0;34m(self, *a, **kw)\u001b[0m\n\u001b[1;32m     25\u001b[0m     client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnector\u001b[38;5;241m.\u001b[39mclient\n\u001b[0;32m---> 26\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tecplot/tecutil/tecutil_rpc.py:1860\u001b[0m, in \u001b[0;36mTecUtilRPC.DataSetReadX\u001b[0;34m(self, arg_list)\u001b[0m\n\u001b[1;32m   1859\u001b[0m args\u001b[38;5;241m=\u001b[39m((ValueType\u001b[38;5;241m.\u001b[39mAddress,c_uint64,\u001b[38;5;28mgetattr\u001b[39m(arg_list,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m,arg_list)),)\n\u001b[0;32m-> 1860\u001b[0m rep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msndrcv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDataSetReadX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchk(rep)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tecplot/tecutil/tecutil_client.py:368\u001b[0m, in \u001b[0;36mTecUtilClient.sndrcv\u001b[0;34m(self, tecutil_command, *args, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m reply \u001b[38;5;241m=\u001b[39m tecrpc\u001b[38;5;241m.\u001b[39mReply()\n\u001b[0;32m--> 368\u001b[0m reply_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m reply\u001b[38;5;241m.\u001b[39mParseFromString(reply_buffer)\n",
      "File \u001b[0;32mzmq/backend/cython/socket.pyx:805\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mzmq/backend/cython/socket.pyx:841\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mzmq/backend/cython/socket.pyx:194\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/zmq/backend/cython/checkrc.pxd:13\u001b[0m, in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mZMQError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_first:\n\u001b[1;32m     15\u001b[0m     files \u001b[38;5;241m=\u001b[39m get_files(\u001b[38;5;28mdir\u001b[39m,key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3d\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m_fluid.*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.dat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m     \u001b[43mdat_to_plt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m files \u001b[38;5;241m=\u001b[39m get_files(\u001b[38;5;28mdir\u001b[39m,key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3d\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m_fluid.*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.plt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m time \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(files\u001b[38;5;241m.\u001b[39mkeys()): \n",
      "Cell \u001b[0;32mIn[4], line 70\u001b[0m, in \u001b[0;36mdat_to_plt\u001b[0;34m(dir, files)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdat_to_plt\u001b[39m(\u001b[38;5;28mdir\u001b[39m,files):\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# Hand it a directory with the dict of files in it, and it will convert them to .plt and save in dir\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[0;32m---> 70\u001b[0m         dataset\u001b[38;5;241m=\u001b[39m\u001b[43mread_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaving file:\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mdir\u001b[39m\u001b[38;5;241m+\u001b[39mfiles[file][:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplt\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     72\u001b[0m         tp\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39msave_tecplot_plt(\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mdir\u001b[39m\u001b[38;5;241m+\u001b[39mfiles[file][:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplt\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "Cell \u001b[0;32mIn[4], line 19\u001b[0m, in \u001b[0;36mread_dataset\u001b[0;34m(mypath)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Configure layout\u001b[39;00m\n\u001b[1;32m     18\u001b[0m tp\u001b[38;5;241m.\u001b[39mnew_layout()\n\u001b[0;32m---> 19\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_tecplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmypath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m frame \u001b[38;5;241m=\u001b[39m tp\u001b[38;5;241m.\u001b[39mactive_frame()\n\u001b[1;32m     21\u001b[0m frame\u001b[38;5;241m.\u001b[39mplot_type \u001b[38;5;241m=\u001b[39m PlotType\u001b[38;5;241m.\u001b[39mCartesian3D\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 79\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tecplot/data/load.py:1879\u001b[0m, in \u001b[0;36mload_tecplot\u001b[0;34m(filenames, frame, read_data_option, reset_style, initial_plot_first_zone_only, initial_plot_type, zones, variables, collapse, skip, assign_strand_ids, add_zones_to_existing_strands, include_text, include_geom, include_custom_labels, include_data)\u001b[0m\n\u001b[1;32m   1776\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Read a tecplot data file.\u001b[39;00m\n\u001b[1;32m   1777\u001b[0m \n\u001b[1;32m   1778\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1876\u001b[0m \u001b[38;5;124;03m    ``r\"C:\\\\Users\"`` and ``r\"\\\\\\\\server\\\\path\"``\u001b[39;00m\n\u001b[1;32m   1877\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1878\u001b[0m filenames \u001b[38;5;241m=\u001b[39m tecutil\u001b[38;5;241m.\u001b[39mnormalize_filenames(filenames)\n\u001b[0;32m-> 1879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m StringList(filenames) \u001b[38;5;28;01mas\u001b[39;00m fnames:\n\u001b[1;32m   1880\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tecutil\u001b[38;5;241m.\u001b[39mArgList() \u001b[38;5;28;01mas\u001b[39;00m arglist:\n\u001b[1;32m   1881\u001b[0m         allocd \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tecplot/tecutil/stringlist.py:95\u001b[0m, in \u001b[0;36mStringList.__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdealloc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tecplot/tecutil/stringlist.py:117\u001b[0m, in \u001b[0;36mStringList.dealloc\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdealloc\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 117\u001b[0m     \u001b[43m_tecutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStringListDealloc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpointer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tecplot/tecutil/preamble.py:26\u001b[0m, in \u001b[0;36mtecutil_preamble.<locals>._fn\u001b[0;34m(self, *a, **kw)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnector\u001b[38;5;241m.\u001b[39mconnected:\n\u001b[1;32m     25\u001b[0m     client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnector\u001b[38;5;241m.\u001b[39mclient\n\u001b[0;32m---> 26\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tecplot/tecutil/tecutil_rpc.py:5421\u001b[0m, in \u001b[0;36mTecUtilRPC.StringListDealloc\u001b[0;34m(self, string_list)\u001b[0m\n\u001b[1;32m   5419\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mStringListDealloc\u001b[39m(\u001b[38;5;28mself\u001b[39m,string_list):\n\u001b[1;32m   5420\u001b[0m  args\u001b[38;5;241m=\u001b[39m((ValueType\u001b[38;5;241m.\u001b[39mAddress,c_uint64,string_list\u001b[38;5;241m.\u001b[39mcontents\u001b[38;5;241m.\u001b[39mvalue),)\n\u001b[0;32m-> 5421\u001b[0m  rep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msndrcv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mStringListDealloc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5422\u001b[0m  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchk(rep)\n\u001b[1;32m   5423\u001b[0m  \u001b[38;5;28;01mreturn\u001b[39;00m rep\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39muint64\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tecplot/tecutil/tecutil_client.py:365\u001b[0m, in \u001b[0;36mTecUtilClient.sndrcv\u001b[0;34m(self, tecutil_command, *args, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m optype \u001b[38;5;241m=\u001b[39m build_tecutil_request(request, tecutil_command, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    364\u001b[0m request_buffer \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mSerializeToString()\n\u001b[0;32m--> 365\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest_buffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    367\u001b[0m reply \u001b[38;5;241m=\u001b[39m tecrpc\u001b[38;5;241m.\u001b[39mReply()\n\u001b[1;32m    368\u001b[0m reply_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket\u001b[38;5;241m.\u001b[39mrecv()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/zmq/sugar/socket.py:696\u001b[0m, in \u001b[0;36mSocket.send\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    689\u001b[0m         data \u001b[38;5;241m=\u001b[39m zmq\u001b[38;5;241m.\u001b[39mFrame(\n\u001b[1;32m    690\u001b[0m             data,\n\u001b[1;32m    691\u001b[0m             track\u001b[38;5;241m=\u001b[39mtrack,\n\u001b[1;32m    692\u001b[0m             copy\u001b[38;5;241m=\u001b[39mcopy \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    693\u001b[0m             copy_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy_threshold,\n\u001b[1;32m    694\u001b[0m         )\n\u001b[1;32m    695\u001b[0m     data\u001b[38;5;241m.\u001b[39mgroup \u001b[38;5;241m=\u001b[39m group\n\u001b[0;32m--> 696\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrack\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mzmq/backend/cython/socket.pyx:742\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mzmq/backend/cython/socket.pyx:789\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mzmq/backend/cython/socket.pyx:255\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mzmq/backend/cython/socket.pyx:250\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/zmq/backend/cython/checkrc.pxd:28\u001b[0m, in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mZMQError\u001b[0m: Operation cannot be accomplished in current state"
     ]
    }
   ],
   "source": [
    "# STEP ONE: process data\n",
    "dir = \"/Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-4e/\" #   # Directory with data \n",
    "start_time = 71                                              # What is the start time of the dataset?\n",
    "t_bound = [71,93] #70,107                                                   # Start and stop times of this data to be processed\n",
    "dt = 0.05                                                     # What is the timestZep between files?\n",
    "convert_first = True # Set to true to make sure files are converted from .dat to .plt. Set to false if there are .dat files in the directory which do not need to be converted\n",
    "\n",
    "var_ls = [\"Bx\",\"By\",\"Bz\",\"Ex\",\"Ey\",\"Ez\",\"rhoS0\",\"uxS0\",\"uyS0\",\"uzS0\",\"pxxS0\",\"pyyS0\",\"pzzS0\",\"pxyS0\",\"pxzS0\",\"pyzS0\",\n",
    "          \"rhoS1\",\"uxS1\",\"uyS1\",\"uzS1\",\"pxxS1\",\"pyyS1\",\"pzzS1\",\"pxyS1\",\"pxzS1\",\"pyzS1\",\"Jx\",\"Jy\",\"Jz\",\"dp_dx\",\"dp_dy\",\"dp_dz\",\n",
    "          \"dB_dx\",\"dB_dy\",\"dB_dz\"]\n",
    "\n",
    "\n",
    "# RUN\n",
    "if convert_first:\n",
    "    files = get_files(dir,key=\"3d\\_fluid.*\\.dat\")\n",
    "    dat_to_plt(dir,files)\n",
    "\n",
    "files = get_files(dir,key=\"3d\\_fluid.*\\.plt\")\n",
    "\n",
    "for time in list(files.keys()): \n",
    "    print(\"Extracting data for t =\",time)\n",
    "    file = str(files[time])\n",
    "\n",
    "    # Read in dataset\n",
    "    dataset = read_dataset(dir+file)\n",
    "    # Save .plt as numpy data\n",
    "    data = plt_to_numpy(dataset,var_ls=var_ls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e746b22-560a-4ebf-87a8-9523e149c272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP TWO: read and plot\n",
    "dir = \"/Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-234e/\"     # Directory with data \n",
    "start_time = 30 \n",
    "t_bound = [51.5,75]                                               # Start and stop times of this data to be plot\n",
    "dt = 0.05         \n",
    "\n",
    "# Plotmode settings\n",
    "plot_preset = '3D_gridscale_df_tracker'\n",
    "\n",
    "'''\n",
    "\"3D_Bz\": Bz in PIC domain.\n",
    "\n",
    "\"3D_Bz1\": Bz1 in PIC domain.\n",
    "\n",
    "\"3D_delta_Bz\": delta Bz in PIC domain.\n",
    "\n",
    "\"3D_df_tracker\": show DFs and track their trajectories, saving a dictionary of their data\n",
    "\n",
    "\"3D_field_lines\": view of field line geometry in FLEKS domain\n",
    "\n",
    "\"3D_flux_tube_content\":\n",
    "\n",
    "\"3D_current_sheet\": Shows 3 xz plane slices of the plasma beta and current density, to demonstrate cs fit\n",
    "\n",
    "\"3D_gridscale_df_tracker\": Similar to df_tracker, but does not compute DF-averaged quantities, instead finding full electric field and current terms\n",
    "'''\n",
    "\n",
    "# Zoom controls\n",
    "do_zoom = True # whether panels should zoom\n",
    "zoom_time_start = 51.50 # when to start zooming\n",
    "zoom_time_end = 53.00 # when to end\n",
    "zoom_x_range = [-2.25,-0.75] # what x region to zoom to\n",
    "zoom_y_range = [-1.1,0.5] # what y region to zoom to\n",
    "zoom_z_range = [-0.1,0.5]\n",
    "azim_start = -110\n",
    "azim_end = -130\n",
    "\n",
    "#RUN\n",
    "files3D = get_files(dir,key=\"3d\\_fluid.*numpy\\_t\\_...\\...\",read_time = True)\n",
    "filescs = get_files(dir,key=\"3d\\_fluid.*csdata\\_t\\_...\\...\",read_time = True)\n",
    "iter = 0\n",
    "for time in list(files3D.keys()): \n",
    "    print(\"Plotting t =\",time)\n",
    "\n",
    "    # Read in the 3D data\n",
    "    file3D = str(files3D[time])\n",
    "    with open(dir+file3D, 'rb') as f:\n",
    "        data3d = pickle.load(f) \n",
    "    \n",
    "    # Read in current sheet data\n",
    "    filecs = str(filescs[time])\n",
    "    with open(dir+filecs, 'rb') as f:\n",
    "        datacs = pickle.load(f) \n",
    "\n",
    "    # PLOT PRESET 'Bz'\n",
    "    if plot_preset=='3D_Bz':\n",
    "        fig = plt.figure(figsize=(13,6), constrained_layout=True)\n",
    "        ax = fig.add_subplot(111, projection=\"3d\",computed_zorder=False)\n",
    "\n",
    "        # Unpack variables\n",
    "        X = datacs[\"X\"]\n",
    "        Y = datacs[\"Y\"]\n",
    "        Z = datacs[\"Z\"]\n",
    "        Bz = datacs[\"Bz\"]\n",
    "\n",
    "        # Mask out values\n",
    "        radius = 1.10\n",
    "        mask = (X**2 + Y**2) < radius**2\n",
    "        Z[mask] = np.nan\n",
    "\n",
    "        mid = 71 # Row index corresponding to midnight \n",
    "        # Define colormap and lighting\n",
    "        norm = plt.Normalize(-50,50)\n",
    "        dawn_colors = cm.bwr(norm(Bz[:mid,:]),alpha=0.5)\n",
    "        dusk_colors = cm.bwr(norm(Bz[mid:,:]),alpha=0.5)\n",
    "\n",
    "        # Set the lighting\n",
    "        light = LightSource()  # Azimuth and altitude of the light source\n",
    "        dawn_illuminated_colors = light.shade_rgb(dawn_colors, Z[:mid,:], blend_mode='soft')  # Apply light source shading\n",
    "        dusk_illuminated_colors = light.shade_rgb(dusk_colors, Z[mid:,:], blend_mode='soft')  # Apply light source shading\n",
    "\n",
    "        # move camera view\n",
    "        ax.view_init(elev=20, azim=-110)\n",
    "\n",
    "        # Create the surface plot\n",
    "        surf1 = ax.plot_surface(X[:mid,:], Y[:mid,:], Z[:mid,:], facecolors=dawn_illuminated_colors, rstride=1, cstride=1, antialiased=False, zorder=2)\n",
    "        surf2 = ax.plot_surface(X[mid:,:], Y[mid:,:], Z[mid:,:], facecolors=dusk_illuminated_colors, rstride=1, cstride=1, antialiased=False, zorder=1.5)\n",
    "        plot_sphere(ax,radius=1,color='lightgrey',alpha=0.5,zorder=-1)\n",
    "        plot_sphere(ax,radius=0.8,color='grey',alpha=1,zorder=-0.75)\n",
    "        \n",
    "        # Add stream traces\n",
    "        nsteps = 10000\n",
    "        step_size = 0.001\n",
    "        tracer = StreamTracer(nsteps, step_size)\n",
    "        ny,nx,nz = data3d[\"Bx\"].shape\n",
    "        \n",
    "        field = np.zeros((nx,ny,nz,3))\n",
    "        field[:,:,:,0] = np.transpose(data3d[\"Bx\"],axes=[1,0,2])\n",
    "        field[:,:,:,1] = np.transpose(data3d[\"By\"],axes=[1,0,2])\n",
    "        field[:,:,:,2] = np.transpose(data3d[\"Bz\"],axes=[1,0,2])\n",
    "        \n",
    "        grid_spacing = [1/64,1/64,1/64]\n",
    "        grid = VectorGrid(field, grid_spacing, origin_coord = [data3d[\"X\"].min(),data3d[\"Y\"].min(),data3d[\"Z\"].min()])\n",
    "        \n",
    "        seeds = np.array([[-1.5,0,0.2], [-1.75,0,0.2],[-2,0,0.2],[-2.25,0,0.2]])\n",
    "        tracer.trace(seeds, grid)\n",
    "\n",
    "        for seed in range(len(seeds)):\n",
    "            start = np.where(tracer.xs[seed][:,2]>=seeds[seed][2])[0][0]\n",
    "            ax.plot(tracer.xs[seed][start:,0],tracer.xs[seed][start:,1],tracer.xs[seed][start:,2],color='black',linewidth=0.5,zorder=2)\n",
    "\n",
    "        # Add a color bar \n",
    "        m = cm.ScalarMappable(cmap=cm.bwr, norm=norm)\n",
    "        m.set_array(Bz)\n",
    "        clb = fig.colorbar(m, ax=ax, shrink=0.3, aspect=7,anchor=(0.5,0.3))\n",
    "        clb.ax.tick_params(labelsize=12)\n",
    "        clb.ax.set_title('$B_z$ [nT]',fontsize=12)\n",
    "\n",
    "        # Set axes\n",
    "        z_lower = -0.6\n",
    "        z_upper = 1.0\n",
    "        ax.set_zlim(z_lower,z_upper)\n",
    "        x_range = X.max() - X.min()\n",
    "        y_range = Y.max() - Y.min()\n",
    "        z_range = z_upper - z_lower\n",
    "        ax.set_box_aspect([x_range, y_range, z_range])  # Aspect ratio is set based on the data limits\n",
    "        \n",
    "        # Add labels\n",
    "        ax.set_xlabel(\"X [$R_M$]\",fontsize=12)\n",
    "        ax.set_ylabel(\"Y [$R_M$]\",fontsize=12)\n",
    "        ax.set_zlabel(\"Z [$R_M$]\",fontsize=12)\n",
    "        ax.tick_params(axis='both',labelsize=12)\n",
    "        ax.set_title(str(\"$B_z$ at t=\"+time+\"s\"),fontsize=12,y=1.0, pad=-14)\n",
    "\n",
    "        # Save\n",
    "        fig.savefig(str(str(dir[:-1])+\"_plots/\"+plot_preset+\"_\"+time+'.png'),bbox_inches='tight',pad_inches=0.3, dpi=300)\n",
    "        plt.close(fig)\n",
    "\n",
    "    # PLOT PRESET '3D_Bz1'\n",
    "    if plot_preset=='3D_Bz1':\n",
    "        fig = plt.figure(figsize=(13,6), constrained_layout=True)\n",
    "        ax = fig.add_subplot(111, projection=\"3d\",computed_zorder=False)\n",
    "\n",
    "        # Unpack variables\n",
    "        Xcs = datacs[\"X\"]\n",
    "        Ycs = datacs[\"Y\"]\n",
    "        Zcs = datacs[\"Z\"]\n",
    "        Bzcs = datacs[\"Bz\"]\n",
    "        Bz1cs = Bzcs - Bz_dip(Xcs,Ycs,Zcs)\n",
    "        \n",
    "        X3d = data3d[\"X\"]\n",
    "        Y3d = data3d[\"Y\"]\n",
    "        Z3d = data3d[\"Z\"]\n",
    "        Bz3d = data3d[\"Bz\"]\n",
    "        Bz13d = Bz3d - Bz_dip(X3d,Y3d,Z3d)\n",
    "\n",
    "        # Mask out values\n",
    "        radius = 1.10\n",
    "        mask = (Xcs**2 + Ycs**2) < radius**2\n",
    "        Zcs[mask] = np.nan\n",
    "\n",
    "        mid = 71 # Row index corresponding to midnight \n",
    "        # Define colormap and lighting\n",
    "        vmin=-100\n",
    "        vmax=0\n",
    "        norm = plt.Normalize(-100,10)\n",
    "        dawn_colors = cm.plasma(norm(Bz1cs[:mid,:]),alpha=0.5)\n",
    "        dusk_colors = cm.plasma(norm(Bz1cs[mid:,:]),alpha=0.5)\n",
    "\n",
    "        # Set the lighting\n",
    "        light = LightSource()  # Azimuth and altitude of the light source\n",
    "        dawn_illuminated_colors = light.shade_rgb(dawn_colors, Z[:mid,:], blend_mode='soft')  # Apply light source shading\n",
    "        dusk_illuminated_colors = light.shade_rgb(dusk_colors, Z[mid:,:], blend_mode='soft')  # Apply light source shading\n",
    "\n",
    "        # move camera view\n",
    "        ax.view_init(elev=5, azim=-90)\n",
    "\n",
    "        # Create the surface plot\n",
    "        surf1 = ax.plot_surface(X[:mid,:], Y[:mid,:], Z[:mid,:], facecolors=dawn_illuminated_colors, rstride=1, cstride=1, antialiased=False, zorder=2)\n",
    "        surf2 = ax.plot_surface(X[mid:,:], Y[mid:,:], Z[mid:,:], facecolors=dusk_illuminated_colors, rstride=1, cstride=1, antialiased=False, zorder=1)\n",
    "        plot_sphere(ax,radius=1,color='lightgrey',alpha=0.5,zorder=1)\n",
    "        plot_sphere(ax,radius=0.8,color='grey',alpha=1,zorder=1.25)\n",
    "        \n",
    "        # Add isosurfaces\n",
    "        b1min = 0\n",
    "        iso = ax.scatter(X3d[Bz13d>b1min],Y3d[Bz13d>b1min],Z3d[Bz13d>b1min],c=Bz13d[Bz13d>b1min],\n",
    "                         vmin=vmin,vmax=vmax,cmap='plasma',s=1,alpha=0.5)\n",
    "\n",
    "        # Add a color bar \n",
    "        m = cm.ScalarMappable(cmap=cm.plasma, norm=norm)\n",
    "        m.set_array(Bz1cs)\n",
    "        clb = fig.colorbar(m, ax=ax, shrink=0.3, aspect=7,anchor=(0.5,0.3))\n",
    "        clb.ax.tick_params(labelsize=12)\n",
    "        clb.ax.set_title('$B_{z1}$ [nT]',fontsize=12,pad=10)\n",
    "\n",
    "        # Set axes\n",
    "        z_lower = -0.6\n",
    "        z_upper = 1.0\n",
    "        ax.set_zlim(z_lower,z_upper)\n",
    "        x_range = X.max() - X.min()\n",
    "        y_range = Y.max() - Y.min()\n",
    "        z_range = z_upper - z_lower\n",
    "        ax.set_box_aspect([x_range, y_range, z_range])  # Aspect ratio is set based on the data limits\n",
    "        \n",
    "        # Add labels\n",
    "        ax.set_xlabel(\"X [$R_M$]\",fontsize=12)\n",
    "        ax.set_ylabel(\"Y [$R_M$]\",fontsize=12)\n",
    "        ax.set_zlabel(\"Z [$R_M$]\",fontsize=12)\n",
    "        ax.tick_params(axis='both',labelsize=12)\n",
    "        ax.set_title(str(\"$B_{z1}$ at t=\"+time+\"s\"),fontsize=12,y=1.0, pad=-14)\n",
    "\n",
    "        # Save\n",
    "        fig.savefig(str(str(dir[:-1])+\"_plots/\"+plot_preset+\"_\"+time+'.png'),bbox_inches='tight',pad_inches=0.3, dpi=300)\n",
    "        plt.close(fig)\n",
    "\n",
    "\n",
    "    # PLOT PRESET '3D_delta_Bz'\n",
    "    if plot_preset=='3D_delta_Bz':\n",
    "        fig = plt.figure(figsize=(13,6), constrained_layout=True)\n",
    "        ax = fig.add_subplot(111, projection=\"3d\",computed_zorder=False)\n",
    "        x_cutoff = 0 # How many indices in X to cutoff\n",
    "        z_cutoff = 0 # How many indices in Z to cutoff\n",
    "\n",
    "        # Unpack variables\n",
    "        Xcs = datacs[\"X\"][:,x_cutoff:]\n",
    "        Ycs = datacs[\"Y\"][:,x_cutoff:]\n",
    "        Zcs = datacs[\"Z\"][:,x_cutoff:]\n",
    "        Bzcs = datacs[\"Bz\"][:,x_cutoff:]\n",
    "        deltaBzcs = Bzcs - average_value([\"Bz\"],float(time),-5,-2,type='csdata')[\"Bz\"][:,x_cutoff:]\n",
    "        \n",
    "        X3d = data3d[\"X\"][:,x_cutoff:,z_cutoff:]\n",
    "        Y3d = data3d[\"Y\"][:,x_cutoff:,z_cutoff:]\n",
    "        Z3d = data3d[\"Z\"][:,x_cutoff:,z_cutoff:]\n",
    "        Bz3d = data3d[\"Bz\"][:,x_cutoff:,z_cutoff:]\n",
    "        deltaBz3d = Bz3d - average_value([\"Bz\"],float(time),-5,2,type='numpy')[\"Bz\"][:,x_cutoff:,z_cutoff:]\n",
    "\n",
    "\n",
    "        # Mask out values\n",
    "        radius = 1.01\n",
    "        mask = (Xcs**2 + Ycs**2) < radius**2\n",
    "        Zcs[mask] = np.nan\n",
    "\n",
    "        mid = 71 # Row index corresponding to midnight \n",
    "        # Define colormap and lighting\n",
    "        vmin=-25\n",
    "        vmax=25\n",
    "        norm = plt.Normalize(vmin,vmax)\n",
    "        dawn_colors = cm.bwr(norm(deltaBzcs[:mid,:]),alpha=0.9)\n",
    "        dusk_colors = cm.bwr(norm(deltaBzcs[mid:,:]),alpha=0.9)\n",
    "\n",
    "        # Set the lighting\n",
    "        light = LightSource()  # Azimuth and altitude of the light source\n",
    "        dawn_illuminated_colors = light.shade_rgb(dawn_colors, Zcs[:mid,:], blend_mode='soft')  # Apply light source shading\n",
    "        dusk_illuminated_colors = light.shade_rgb(dusk_colors, Zcs[mid:,:], blend_mode='soft')  # Apply light source shading\n",
    "\n",
    "        # move camera view\n",
    "        ax.view_init(elev=30, azim=-160)\n",
    "\n",
    "        # Create the surface plot\n",
    "        surf1 = ax.plot_surface(Xcs[:mid,:], Ycs[:mid,:], Zcs[:mid,:], facecolors=dawn_illuminated_colors, rstride=1, cstride=1, antialiased=False, zorder=2)\n",
    "        surf2 = ax.plot_surface(Xcs[mid:,:], Ycs[mid:,:], Zcs[mid:,:], facecolors=dusk_illuminated_colors, rstride=1, cstride=1, antialiased=False, zorder=1.5)\n",
    "        plot_sphere(ax,radius=1,color='lightgrey',alpha=0.5,zorder=1)\n",
    "        plot_sphere(ax,radius=0.8,color='grey',alpha=1,zorder=1.25)\n",
    "        \n",
    "        # Add isosurfaces\n",
    "        Bmin = 10\n",
    "        above_mask = (deltaBz3d>Bmin) & create_above_surface_mask(Xcs, Ycs, Zcs, X3d, Y3d, Z3d) \n",
    "        #iso1 = ax.scatter(X3d[above_mask],Y3d[above_mask],Z3d[above_mask],c=deltaBz3d[above_mask],cmap='bwr',vmin=vmin,vmax=vmax,\n",
    "        #                 s=0.8,zorder=3,alpha = np.clip(((deltaBz3d[above_mask]-Bmin)/(vmax-Bmin))**0.2,0,1))\n",
    "        iso1 = ax.scatter(X3d[above_mask],Y3d[above_mask],Z3d[above_mask],c=(-Z3d[above_mask]),cmap='Greens',vmin=-0.6,vmax=0.1,\n",
    "                         s=0.8,zorder=3,alpha = 0.8)#,alpha = np.clip(((deltaBz3d[above_mask]-Bmin)/(vmax-Bmin))**0.2,0,1))\n",
    "        below_mask = (deltaBz3d>Bmin) & ~(create_above_surface_mask(Xcs, Ycs, Zcs, X3d, Y3d, Z3d)) \n",
    "        iso2 = ax.scatter(X3d[below_mask],Y3d[below_mask],Z3d[below_mask],c=(-Z3d[below_mask]),cmap='Greens',vmin=-0.5,vmax=0.5,\n",
    "                         s=0.8,zorder=0.75,alpha = 0.8)#,alpha = np.clip(((deltaBz3d[below_mask]-Bmin)/(vmax-Bmin))**0.2,0,1))\n",
    "\n",
    "        # Add Bz=0 line\n",
    "        #contour_mask = np.isclose(Bzcs, 0, atol=0.5) & (Xcs<-1.3)\n",
    "        #ax.scatter(Xcs[contour_mask], Ycs[contour_mask], Zcs[contour_mask],c='black',s=0.03,zorder=2.1)\n",
    "        \n",
    "        # Add a color bar \n",
    "        m = cm.ScalarMappable(cmap=cm.bwr, norm=norm)\n",
    "        m.set_array(deltaBzcs)\n",
    "        clb = fig.colorbar(m, ax=ax, shrink=0.3, aspect=7,anchor=(-0.5,0.3))\n",
    "        clb.ax.tick_params(labelsize=12)\n",
    "        clb.ax.set_title('$\\delta B_{z}$ [nT]',fontsize=12,pad=10)\n",
    "\n",
    "        # Add big x axis\n",
    "        ax.plot([np.min(Xcs[:mid,:]),-1],[0,0],[0.2,0.2],color='black',lw=2)\n",
    "        ax.scatter([-4,-3,-2,-1],[0,0,0,0],[0.2,0.2,0.2,0.2],s=5,color='black')\n",
    "\n",
    "        # Set axes\n",
    "        z_lower = -0.1\n",
    "        z_upper = 1.0\n",
    "        ax.set_zlim(z_lower,z_upper)\n",
    "        x_range = Xcs.max() - Xcs.min()\n",
    "        y_range = Ycs.max() - Ycs.min()\n",
    "        z_range = z_upper - z_lower\n",
    "        ax.set_box_aspect([x_range, y_range, z_range])  # Aspect ratio is set based on the data limits\n",
    "        \n",
    "        # Add labels\n",
    "        ax.set_xlabel(\"\\nX [$R_M$]\",fontsize=12)\n",
    "        ax.set_ylabel(\"Y [$R_M$]\",fontsize=12)\n",
    "        ax.set_zlabel(\"Z [$R_M$]\",fontsize=12)\n",
    "        ax.tick_params(axis='both',labelsize=12)\n",
    "        ax.set_title(str(\"$\\delta B_{z}$ at t=\"+time+\"s\"),fontsize=12,y=1.0, pad=-14)\n",
    "\n",
    "        # Save\n",
    "        fig.savefig(str(str(dir[:-1])+\"_plots/\"+plot_preset+\"_\"+time+'.png'),bbox_inches='tight',pad_inches=0.3, dpi=300)\n",
    "        plt.close(fig)\n",
    "\n",
    "    if plot_preset=='3D_field_lines':\n",
    "\n",
    "        # Set up plot environment\n",
    "        fig = plt.figure(figsize=(18,6))\n",
    "        ax = fig.add_subplot(111, projection=\"3d\",computed_zorder=False)\n",
    "        \n",
    "        # Unpack data\n",
    "        Xcs = datacs[\"X\"]\n",
    "        Ycs = datacs[\"Y\"]\n",
    "        Zcs = datacs[\"Z\"]\n",
    "        X3d = data3d[\"X\"]\n",
    "        Y3d = data3d[\"Y\"]\n",
    "        Z3d = data3d[\"Z\"]\n",
    "        Bx3d = data3d[\"Bx\"]\n",
    "        By3d = data3d[\"By\"]\n",
    "        Bz3d = data3d[\"Bz\"]\n",
    "        ncs = datacs[\"rhoS1\"]\n",
    "        n3d = data3d[\"rhoS1\"] * 1e6 # convert to SI\n",
    "        pe3d = ((data3d[\"pxxS0\"]+data3d[\"pyyS0\"]+data3d[\"pzzS0\"])/3*1e-9) # convert to SI\n",
    "        pi3d = ((data3d[\"pxxS1\"]+data3d[\"pyyS1\"]+data3d[\"pzzS1\"])/3*1e-9) # convert to SI\n",
    "\n",
    "        # Set axes\n",
    "        z_lower = -1\n",
    "        z_upper = 1\n",
    "        ax.set_zlim(z_lower,z_upper)\n",
    "        x_range = X3d.max() - X3d.min()\n",
    "        y_range = Y3d.max() - Y3d.min()\n",
    "        z_range = z_upper - z_lower\n",
    "        ax.set_box_aspect([x_range, y_range, z_range])  # Aspect ratio is set based on the data limits\n",
    "\n",
    "        # Set up grid for field line tracing\n",
    "        ny,nx,nz = Bx3d.shape\n",
    "        field = np.zeros((nx,ny,nz,3))\n",
    "        field[:,:,:,0] = np.transpose(Bx3d,axes=[1,0,2])\n",
    "        field[:,:,:,1] = np.transpose(By3d,axes=[1,0,2])\n",
    "        field[:,:,:,2] = np.transpose(Bz3d,axes=[1,0,2])\n",
    "        grid_spacing = [1/64,1/64,1/64]\n",
    "        grid = VectorGrid(field, grid_spacing, origin_coord = [X3d.min(),Y3d.min(),Z3d.min()])\n",
    "        nsteps = 10000\n",
    "        step_size = 0.001\n",
    "        tracer = StreamTracer(nsteps, step_size)\n",
    "\n",
    "        # Add stream trace seed at each CS x,y\n",
    "        trace_skip=16\n",
    "        seeds = np.zeros((len(Xcs[::trace_skip,::trace_skip].ravel()),3))\n",
    "        seeds[:,0] = Xcs[::trace_skip,::trace_skip].ravel()\n",
    "        seeds[:,1] = Ycs[::trace_skip,::trace_skip].ravel()\n",
    "        seeds[:,2] = Zcs[::trace_skip,::trace_skip].ravel()\n",
    "\n",
    "        # Trace the field lines\n",
    "        tracer.trace(seeds, grid)\n",
    "\n",
    "        # Integrate quantities along field line\n",
    "        #for i,seed in enumerate(seeds):\n",
    "        #    print(tracer.xs[i][0,:])\n",
    "\n",
    "        # Plot field lines\n",
    "\n",
    "        # Define colormap to use for field lines\n",
    "        cmap = plt.colormaps[\"Reds\"] #plt.get_cmap('Greys')  # You can choose any colormap you like\n",
    "        norm = plt.Normalize(-1.2, 0.8)\n",
    "        \n",
    "        for i,seed in enumerate(seeds):\n",
    "            above = np.where(tracer.xs[i][:,2]>=seeds[i][2])[0]\n",
    "            below = np.where(tracer.xs[i][:,2]<seeds[i][2])[0]\n",
    "            # Plot the streamlines as a series of lines, without connecting between places where the indexing jumps\n",
    "            start = 0 \n",
    "            for j in range(1,len(above)):\n",
    "                if (above[j]-above[j-1]>1) or (j==(len(above)-1)):\n",
    "                    x = tracer.xs[i][above[start:j-1],0]\n",
    "                    y = tracer.xs[i][above[start:j-1],1]\n",
    "                    z = tracer.xs[i][above[start:j-1],2]\n",
    "                    points = np.array([x,y,z]).T.reshape(-1, 1, 3)\n",
    "                    segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "                    lc = Line3DCollection(segments, cmap=cmap, norm=norm, linewidth=0.5)\n",
    "                    lc.set_array(-z)\n",
    "                    ax.add_collection3d(lc)\n",
    "                    #ax.plot(tracer.xs[i][above[start:j-1],0],tracer.xs[i][above[start:j-1],1],tracer.xs[i][above[start:j-1],2],\n",
    "                    #       color=\"black\",lw=0.3,alpha=1,zorder=3.6) \n",
    "                    start = j\n",
    "                \n",
    "            start = 0\n",
    "            for j in range(1,len(below)):\n",
    "                if (below[j]-below[j-1]>1) or (j==(len(below)-1)):\n",
    "                    x = tracer.xs[i][below[start:j-1],0]\n",
    "                    y = tracer.xs[i][below[start:j-1],1]\n",
    "                    z = tracer.xs[i][below[start:j-1],2]\n",
    "                    points = np.array([x,y,z]).T.reshape(-1, 1, 3)\n",
    "                    segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "                    lc = Line3DCollection(segments, cmap=cmap, norm=norm, linewidth=0.5)\n",
    "                    lc.set_array(-z)\n",
    "                    ax.add_collection3d(lc)\n",
    "                    #ax.plot(tracer.xs[i][below[start:j-1],0],tracer.xs[i][below[start:j-1],1],tracer.xs[i][below[start:j-1],2],\n",
    "                    #       color=\"black\",lw=0.3,alpha=1,zorder=1.5) \n",
    "                    start = j\n",
    "\n",
    "        # Mask out values\n",
    "        radius = 1.01\n",
    "        mask = (Xcs**2 + Ycs**2) < radius**2\n",
    "        Zcs[mask] = np.nan\n",
    "\n",
    "        mid = 71 # Row index corresponding to midnight \n",
    "        # Define colormap and lighting\n",
    "        vmin=0.1\n",
    "        vmax=10\n",
    "        norm = LogNorm(vmin,vmax) #plt.Normalize(vmin,vmax)\n",
    "        dawn_colors = cm.plasma(norm(ncs[:mid,:]),alpha=0.01)\n",
    "        dusk_colors = cm.plasma(norm(ncs[mid:,:]),alpha=0.01)\n",
    "\n",
    "        # Set the lighting\n",
    "        light = LightSource()  # Azimuth and altitude of the light source\n",
    "        dawn_illuminated_colors = light.shade_rgb(dawn_colors, Zcs[:mid,:], blend_mode='soft')  # Apply light source shading\n",
    "        dusk_illuminated_colors = light.shade_rgb(dusk_colors, Zcs[mid:,:], blend_mode='soft')  # Apply light source shading\n",
    "\n",
    "        # move camera view\n",
    "        ax.view_init(elev=35, azim=-145)\n",
    "\n",
    "        # Create the surface plot\n",
    "        #surf1 = ax.plot_surface(Xcs[:mid,:], Ycs[:mid,:], Zcs[:mid,:], facecolors=dawn_illuminated_colors, rstride=1, cstride=1, antialiased=False, zorder=2)\n",
    "        #surf2 = ax.plot_surface(Xcs[mid:,:], Ycs[mid:,:], Zcs[mid:,:], facecolors=dusk_illuminated_colors, rstride=1, cstride=1, antialiased=False, zorder=1.5)\n",
    "        plot_sphere(ax,radius=1,color='lightgrey',alpha=0.5,zorder=1)\n",
    "        plot_sphere(ax,radius=0.8,color='grey',alpha=1,zorder=1.25)\n",
    "\n",
    "        # Add a color bar \n",
    "        m = cm.ScalarMappable(cmap=cm.plasma, norm=norm)\n",
    "        m.set_array(ncs)\n",
    "        clb = fig.colorbar(m, ax=ax, shrink=0.3, aspect=7,anchor=(-0.5,0.3))\n",
    "        clb.ax.tick_params(labelsize=12)\n",
    "        clb.ax.set_title('$n$ [cm$^{-3}$]',fontsize=12,pad=10)\n",
    "\n",
    "        # Add big x axis\n",
    "        ax.plot([np.min(Xcs[:mid,:]),-1],[0,0],[0.2,0.2],color='black',lw=0.8,zorder=3)\n",
    "        ax.scatter([-4,-3,-2,-1],[0,0,0,0],[0.2,0.2,0.2,0.2],s=5,color='black',zorder=3)\n",
    "        \n",
    "        # Add labels\n",
    "        ax.set_xlabel(\"\\nX [$R_M$]\",fontsize=12)\n",
    "        ax.set_ylabel(\"Y [$R_M$]\",fontsize=12)\n",
    "        ax.set_zlabel(\"Z [$R_M$]\",fontsize=12)\n",
    "        ax.tick_params(axis='both',labelsize=12)\n",
    "        ax.set_title(str(\"Density at t=\"+time+\"s\"),fontsize=12,y=1.0, pad=-14)\n",
    "\n",
    "        # Save\n",
    "        fig.savefig(str(str(dir[:-1])+\"_plots/\"+plot_preset+\"_\"+time+'.png'),bbox_inches='tight',pad_inches=0.3, dpi=300)\n",
    "        plt.close(fig)\n",
    "\n",
    "    \n",
    "    if plot_preset=='3D_df_tracker':\n",
    "\n",
    "        # On the first iteration, define an empty dictionary to save our DF data to\n",
    "        if iter == 0:\n",
    "            df_data = {} # This stores all the DFs we have seen\n",
    "            df_dict = None # This stores all the cells of DFs from the previous step\n",
    "            df_seeds = {} # This stores all the field line seed locations for the DFs\n",
    "\n",
    "        # Define X cutoff, if required\n",
    "        x_cutoff=0\n",
    "\n",
    "        # Unpack data\n",
    "        X = datacs[\"X\"][:,x_cutoff:]\n",
    "        Y = datacs[\"Y\"][:,x_cutoff:]\n",
    "        Z = datacs[\"Z\"][:,x_cutoff:]\n",
    "        X3d = data3d[\"X\"][:,x_cutoff:,:]\n",
    "        Y3d = data3d[\"Y\"][:,x_cutoff:,:]\n",
    "        Z3d = data3d[\"Z\"][:,x_cutoff:,:]\n",
    "        Bx3d = data3d[\"Bx\"][:,x_cutoff:,:]\n",
    "        By3d = data3d[\"By\"][:,x_cutoff:,:]\n",
    "        Bz3d = data3d[\"Bz\"][:,x_cutoff:,:]\n",
    "        Jx = datacs[\"Jx\"][:,x_cutoff:]\n",
    "        Jy = datacs[\"Jy\"][:,x_cutoff:]\n",
    "        Jz = datacs[\"Jz\"][:,x_cutoff:]\n",
    "        Bx = datacs[\"Bx\"][:,x_cutoff:] \n",
    "        By = datacs[\"By\"][:,x_cutoff:] \n",
    "        Bz = datacs[\"Bz\"][:,x_cutoff:] \n",
    "        n = datacs[\"rhoS1\"][:,x_cutoff:] * 1e6 # convert to SI\n",
    "        pe = ((datacs[\"pxxS0\"]+datacs[\"pyyS0\"]+datacs[\"pzzS0\"])/3*1e-9)[:,x_cutoff:] # convert to SI\n",
    "        Te = pe/n/k_b / 11605 / 1e3 #Convert to keV\n",
    "        uix = datacs[\"uxS1\"][:,x_cutoff:]\n",
    "        uiy = datacs[\"uyS1\"][:,x_cutoff:]\n",
    "        uiz = datacs[\"uyS1\"][:,x_cutoff:]\n",
    "        uex = datacs[\"uxS0\"][:,x_cutoff:]\n",
    "        uey = datacs[\"uyS0\"][:,x_cutoff:]\n",
    "        uez = datacs[\"uyS0\"][:,x_cutoff:]\n",
    "        beta = (2*mu_0*(datacs[\"pxxS0\"]+datacs[\"pyyS0\"]+datacs[\"pzzS0\"]+datacs[\"pxxS1\"]+datacs[\"pyyS1\"]+datacs[\"pzzS1\"])*1e9/3/(datacs[\"Bx\"]**2+datacs[\"By\"]**2+datacs[\"Bz\"]**2))[:,x_cutoff:]\n",
    "        E_convx = (-(uey*Bz-uez*By)*1000*1e-9) # Convert to V/m ie SI\n",
    "        E_convy = (-(uez*Bx-uex*Bz)*1000*1e-9)\n",
    "        E_convz = (-(uex*By-uey*Bx)*1000*1e-9)\n",
    "        dp_dx = datacs['dp_dx'][:,x_cutoff:]\n",
    "        dp_dy = datacs['dp_dy'][:,x_cutoff:]\n",
    "        dp_dz = datacs['dp_dz'][:,x_cutoff:]\n",
    "\n",
    "        # Compute average values of Bz in the 5seconds preceeding the current time\n",
    "        Bz_avg = average_value([\"Bz\"],float(time),-1,0)[\"Bz\"][:,x_cutoff:]\n",
    "        delta_Bz3d = Bz3d - average_value([\"Bz\"],float(time),-5,-2,type='numpy')[\"Bz\"][:,x_cutoff:,:]\n",
    "\n",
    "        # Compute DF metric\n",
    "        metric = (Bz-Bz_avg)\n",
    "\n",
    "        # Set bounds on metric\n",
    "        min_value = 10 #nT \n",
    "        min_size = 10\n",
    "        dx = 1/64\n",
    "\n",
    "        # Set z bounds\n",
    "        z_lower = -1\n",
    "        z_upper = 1\n",
    "\n",
    "        # Compute zoom rates, if activated\n",
    "        if do_zoom:\n",
    "            zoom_dxdt_min = (zoom_x_range[0]-np.min(X))/(zoom_time_end-zoom_time_start)\n",
    "            zoom_dxdt_max = (np.max(X)-zoom_x_range[1])/(zoom_time_end-zoom_time_start)\n",
    "            zoom_dydt_min = (zoom_y_range[0]-np.min(Y))/(zoom_time_end-zoom_time_start)\n",
    "            zoom_dydt_max = (np.max(Y)-zoom_y_range[1])/(zoom_time_end-zoom_time_start)\n",
    "            zoom_dzdt_min = (zoom_z_range[0]-z_lower)/(zoom_time_end-zoom_time_start)\n",
    "            zoom_dzdt_max = (z_upper-zoom_y_range[1])/(zoom_time_end-zoom_time_start)\n",
    "            zoom_dazimdt = (azim_end - azim_start)/(zoom_time_end-zoom_time_start)\n",
    "        \n",
    "        # Find DF regions\n",
    "        # Create boolean mask where Z exceeds z_0\n",
    "        mask = metric > min_value\n",
    "        \n",
    "        # Label connected regions\n",
    "        structure = np.zeros((3, 3), dtype=bool)  # Structuring element\n",
    "        structure[1,:] = True\n",
    "        structure[:,1] = True # Use a + shaped mask\n",
    "        labeled, num_features = label(mask, structure=structure)\n",
    "        \n",
    "        # Find all the DF regions in this time slice\n",
    "        new_df_dict = {}\n",
    "        count=1\n",
    "        for feature_num in range(1, num_features + 1):\n",
    "            region = (labeled == feature_num)\n",
    "            DF_beta = np.mean(beta[region])\n",
    "            # Remove regions that are too small or have an average beta<1\n",
    "            if (len(X[region])>min_size) and (DF_beta>1):\n",
    "                new_df_dict[count] = (X[region], Y[region])\n",
    "                count+=1\n",
    "    \n",
    "        print(\"Found\",len(new_df_dict.keys()),\"DFs at this time\")\n",
    "\n",
    "        ################# Plot #################\n",
    "        fig = plt.figure(figsize=(18,6))\n",
    "        ax = fig.add_subplot(111, projection=\"3d\",computed_zorder=False)\n",
    "\n",
    "        mid = 95 # Row index corresponding to midnight \n",
    "\n",
    "        # Mask out values\n",
    "        if do_zoom and (float(time)>zoom_time_start):\n",
    "            if (float(time)>=zoom_time_end):\n",
    "                zoom_time = zoom_time_stop-zoom_time_start # Effectively applies a stopping condition, to \"stay\" zoomed\n",
    "            else:\n",
    "                zoom_time = float(time)-zoom_time_start\n",
    "            zoom_xmin = np.min(X)+zoom_time*zoom_dxdt_min\n",
    "            zoom_xmax = np.max(X)-zoom_time*zoom_dxdt_max\n",
    "            zoom_ymin = np.min(Y)+zoom_time*zoom_dydt_min\n",
    "            zoom_ymax = np.max(Y)-zoom_time*zoom_dydt_max\n",
    "            zoom_zmin = z_lower+zoom_time*zoom_dzdt_min\n",
    "            zoom_zmax = z_upper-zoom_time*zoom_dzdt_max\n",
    "            zoom_mask = (X > zoom_xmax) | (X < zoom_xmin) | (Y > zoom_ymax) | (Y < zoom_ymin) \n",
    "            Z[zoom_mask] = np.nan\n",
    "        radius = 1.01\n",
    "        mask = (X**2 + Y**2) < radius**2\n",
    "        Z[mask] = np.nan\n",
    "\n",
    "        mid = 90 # Row index corresponding to midnight \n",
    "        # Define colormap and lighting\n",
    "        vmin=-25\n",
    "        vmax=25\n",
    "        norm = plt.Normalize(vmin,vmax)\n",
    "        dawn_colors = cm.bwr(norm(metric[:mid,:]),alpha=0.9)\n",
    "        dusk_colors = cm.bwr(norm(metric[mid:,:]),alpha=0.9)\n",
    "\n",
    "        # Set the lighting\n",
    "        light = LightSource()  # Azimuth and altitude of the light source\n",
    "        dawn_illuminated_colors = light.shade_rgb(dawn_colors, Z[:mid,:], blend_mode='soft')  # Apply light source shading\n",
    "        dusk_illuminated_colors = light.shade_rgb(dusk_colors, Z[mid:,:], blend_mode='soft')  # Apply light source shading\n",
    "\n",
    "        # move camera view\n",
    "        if do_zoom and (float(time)>zoom_time_start):\n",
    "            ax.view_init(elev=25, azim=azim_start + zoom_dazimdt*(zoom_time))\n",
    "        else:\n",
    "            ax.view_init(elev=25, azim=azim_start)\n",
    "            \n",
    "        # Create the surface plot\n",
    "        surf1 = ax.plot_surface(X[:mid,:], Y[:mid,:], Z[:mid,:], facecolors=dawn_illuminated_colors, rstride=1, cstride=1, antialiased=False, zorder=2)\n",
    "        surf2 = ax.plot_surface(X[mid:,:], Y[mid:,:], Z[mid:,:], facecolors=dusk_illuminated_colors, rstride=1, cstride=1, antialiased=False, zorder=0.75)\n",
    "        \n",
    "        # Add a color bar \n",
    "        m = cm.ScalarMappable(cmap=cm.bwr, norm=norm)\n",
    "        m.set_array(metric)\n",
    "        clb = fig.colorbar(m, ax=ax, shrink=0.3, aspect=7,anchor=(0.0,0.3))\n",
    "        clb.ax.tick_params(labelsize=12)\n",
    "        clb.ax.set_title('$\\delta B_{z}$ [nT]',fontsize=12,pad=10)\n",
    "\n",
    "        # Add big x axis\n",
    "        if do_zoom and (float(time)>zoom_time_start):\n",
    "            ax.plot([zoom_xmin,-1],[0,0],[0.2,0.2],color='black',lw=1)\n",
    "            ax.scatter(np.arange(int(zoom_xmin),0),np.arange(int(zoom_xmin),0)*0,np.arange(int(zoom_xmin),0)*0+0.2,s=4,color='black')\n",
    "            # Show Mercury\n",
    "            plot_sphere(ax,radius=1,color='lightgrey',alpha=0.5,zorder=1,quarter=False,\n",
    "                    xlims=[zoom_xmin,zoom_xmax],ylims=[zoom_ymin,zoom_ymax],zlims=[zoom_zmin,zoom_zmax])\n",
    "            plot_sphere(ax,radius=0.8,color='grey',alpha=1,zorder=1.25,quarter=False,\n",
    "                    xlims=[zoom_xmin,zoom_xmax],ylims=[zoom_ymin,zoom_ymax],zlims=[zoom_zmin,zoom_zmax])\n",
    "        else:\n",
    "            ax.plot([np.min(X[:mid,:]),-1],[0,0],[0.2,0.2],color='black',lw=1)\n",
    "            ax.scatter([-4,-3,-2,-1],[0,0,0,0],[0.2,0.2,0.2,0.2],s=4,color='black')\n",
    "            # Show Mercury\n",
    "            plot_sphere(ax,radius=1,color='lightgrey',alpha=0.5,zorder=1,quarter=False)\n",
    "            plot_sphere(ax,radius=0.8,color='grey',alpha=1,zorder=1.25,quarter=False)\n",
    "\n",
    "        # Add labels\n",
    "        ax.set_xlabel(\"X [$R_M$]\",fontsize=12)\n",
    "        ax.set_ylabel(\"Y [$R_M$]\",fontsize=12)\n",
    "        ax.set_zlabel(\"Z [$R_M$]\",fontsize=12)\n",
    "        ax.tick_params(axis='both',labelsize=12)\n",
    "        ax.set_title(str(\"$\\delta B_{z}$ at t=\"+time+\"s\"),fontsize=12,y=1.0, pad=-5)\n",
    "\n",
    "        ################# END PLOT #################\n",
    "        \n",
    "        # Compare to previous df_dict, if any, and relabel DFs for continuity\n",
    "    \n",
    "        if df_dict is not None and len(new_df_dict.keys())>0: # Only proceed with attempting to match DFs if we have data from last timestep and there is at least 1 DF in this timestep\n",
    "            # The name of the game is just to relabel all the keys appropriately.\n",
    "            # Set up a new dictionary where we will make all these changes.\n",
    "            next_df_dict = {}\n",
    "    \n",
    "            # Iterate through new_key_dict, which has all the dfs identified in this step (with keys which will generally be totally wrong)\n",
    "            new_keys = list(new_df_dict.keys()).copy()\n",
    "            overlap_masks = [] # Here, we will store key pairs: [new_key, old_key, agreement_lvl]\n",
    "            for new_key in new_keys:\n",
    "                for old_key in df_dict.keys():\n",
    "                    # Compare all the currently identified DFs to those from the previous step, and save an entry to overlap_masks if any overlap\n",
    "                    xmask = np.isin(new_df_dict[new_key][0],df_dict[old_key][0])\n",
    "                    ymask = np.isin(new_df_dict[new_key][1],df_dict[old_key][1])\n",
    "                    mask=xmask&ymask\n",
    "                    if mask.any():\n",
    "                        print(\"New DF#\"+str(new_key)+\" overlaps with old DF#\"+str(old_key))\n",
    "                        overlap_masks.append([new_key,old_key,sum(mask)]) # sum(mask) gives the number of \"True\" in the list\n",
    "            # Sometimes a weird error happens where we have new DFs but none overlap and we have an empty matrix.. this is a hotfix for that case:\n",
    "            #if len(overlap_masks)==0:\n",
    "            #    df_dict = new_df_dict   \n",
    "            #else:\n",
    "            # Matrix stores the relationship between the DFs labelled at this time and the previous time.\n",
    "            unfiltered_matrix = np.array(overlap_masks, ndmin=2)\n",
    "            # If a new DF has appeared, we have not accounted for it yet (since it will have no overlap with the previous step).\n",
    "            for key in new_keys:\n",
    "                if len(overlap_masks)==0:\n",
    "                    unfiltered_matrix = np.array([key,-1,0], ndmin=2) # In some cases, we have only new DFs and no overlap, so unfiltered matrix cannot be indexed in the next elif and the code crashes. This hotfix solves that.\n",
    "                elif key not in unfiltered_matrix[:,0]:\n",
    "                    unfiltered_matrix = np.vstack([unfiltered_matrix, [key,-1,0]]) # Add newly formed DFs to the register, and associate it with the previous DF -1 (i.e. assocaited with none)\n",
    "            unfiltered_matrix = unfiltered_matrix[unfiltered_matrix[:,2].argsort()[::-1]] # Sort to start with largest overlap ones\n",
    "            \n",
    "            # We now need to remove repeated rows with repeated values of new_key (column zero) to stop an infinite cascade of new DFs\n",
    "            # Now that we've sorted the data, the dfs with the most overlap will be selected for\n",
    "            # Only need to filter out rows if there are more rows in matrix than the number of dfs at this time\n",
    "            if len(unfiltered_matrix[:,0])>len(new_df_dict.keys()):\n",
    "                matrix = remove_duplicate_rows(unfiltered_matrix)\n",
    "            else:\n",
    "                matrix = unfiltered_matrix\n",
    "            \n",
    "            print(\"NEW DF KEY   OLD DF KEY   MATCH\")\n",
    "            print(matrix)\n",
    "    \n",
    "            temp_key=-1\n",
    "    \n",
    "            for i in range(len(matrix[:,0])):\n",
    "                if matrix[i,1]==-1: # this means its a newly formed DF in this step.\n",
    "                    print(\"DF#\"+str(matrix[i,0]),\"is a new one and is temporarily assigned #\"+str(temp_key))\n",
    "                    r = np.mean(np.sqrt(new_df_dict[matrix[i,0]][0]**2+new_df_dict[matrix[i,0]][1]**2))\n",
    "                    if r>1.25:\n",
    "                        next_df_dict[temp_key] = new_df_dict[matrix[i,0]] # Give it a temporary name, we will come back to it at the end\n",
    "                        temp_key-=1\n",
    "                    else:\n",
    "                        print(\"This DF formed too close to the planet, throwing it out...\")\n",
    "                        #print(\"position:\",r,\"    beta:\",beta_DR)\n",
    "                elif (matrix[i,1] not in next_df_dict.keys()): # Check to see if this DF has already been named for the updated dict. If its not there, add it\n",
    "                    print(\"DF#\"+str(matrix[i,1])+\" has been tracked from the previous step\")\n",
    "                    next_df_dict[matrix[i,1]] = new_df_dict[matrix[i,0]] # The name of the DF is taken from df_dict, and is populated with data from the new dict. The matrix is used as a reference to connect the two.\n",
    "                else: # This means this DF has already been identified with a previous DF that has more overlap with it i.e. it is a child\n",
    "                    print(\"DF#\"+str(matrix[i,1])+\" has split and formed a new DF, which is temporarily assigned #\"+str(temp_key))\n",
    "                    next_df_dict[temp_key] = new_df_dict[matrix[i,0]] # Give it a temporary name, we will come back to it at the end\n",
    "                    temp_key-=1\n",
    "            # All DFs identified in this step have been assigned names in next_df_dict. Now, we need to rename the negative ones to the next largest names\n",
    "            if len(df_data.keys())==0:\n",
    "                new_df_key = 1    \n",
    "            else:\n",
    "                new_df_key = np.max(list(df_data.keys()))+1 # Start naming at one larger than the maximum df number already used\n",
    "            for key in list(next_df_dict.keys()).copy():\n",
    "                if key<0:\n",
    "                    print(\"Reassigning the temporary DF#\"+str(key),\"to DF#\"+str(new_df_key))\n",
    "                    next_df_dict[new_df_key] = next_df_dict.pop(key)\n",
    "                    new_df_key+=1\n",
    "            print(\"Feature tracking complete!\")\n",
    "            df_dict = next_df_dict   \n",
    "        else:\n",
    "            df_dict = new_df_dict   \n",
    "\n",
    "        ####### PLOT 2 SETUP ######\n",
    "        color_ls = [\"tab:blue\",\"tab:green\",\"tab:blue\",\"tab:orange\",\"tab:purple\",\"tab:brown\",\"tab:pink\",\"tab:olive\",\"tab:cyan\"]\n",
    "        # Set up grid for field line tracing\n",
    "        ny,nx,nz = Bx3d.shape\n",
    "        field = np.zeros((nx,ny,nz,3))\n",
    "        field[:,:,:,0] = np.transpose(Bx3d,axes=[1,0,2])\n",
    "        field[:,:,:,1] = np.transpose(By3d,axes=[1,0,2])\n",
    "        field[:,:,:,2] = np.transpose(Bz3d,axes=[1,0,2])\n",
    "        grid_spacing = [1/64,1/64,1/64]\n",
    "        grid = VectorGrid(field, grid_spacing, origin_coord = [X3d.min(),Y3d.min(),Z3d.min()])\n",
    "        nsteps = 10000\n",
    "        step_size = 0.001\n",
    "        tracer = StreamTracer(nsteps, step_size)\n",
    "        ##### END PLOT 2 SETUP #########\n",
    "\n",
    "            \n",
    "        # For each DF, either create a new item to store info about it or add to an existing item\n",
    "        for key in df_dict.keys():\n",
    "            if key not in df_data.keys(): # Create new dataframe if this df has not been registered already\n",
    "                df_data[key] = pd.DataFrame(columns=['time','X','Y','Z','Bx','By','Bz','Te','n','uix',\"uiy\",\"uiz\",'uex',\"uey\",\"uez\",\n",
    "                                                     \"E_convx\",\"E_convy\",\"E_convz\",\"dp_dx\",\"dp_dy\",\"dp_dz\",\n",
    "                                                     \"J_inrt,x\",\"J_inrt,y\",\"J_inrt,z\",\"J_gradp,x\",\"J_gradp,y\",\"J_gradp,z\",\n",
    "                                                     \"Jx\",\"Jy\",\"Jz\",\"Bz_max\",'area'])\n",
    "            new_row = np.zeros(32)\n",
    "            # Now we iterate over each coordinate associated with this DF\n",
    "            Bz_max_ls = []\n",
    "            for i in range(len(df_dict[key][0])):\n",
    "                coord = [df_dict[key][0][i],df_dict[key][1][i]] # Remember, each item in df_dict is a tuple of the X coords and Y coords\n",
    "                # Find which indices of \"data\" these coordinates correspond to\n",
    "                ix = np.where(X[0,:]==coord[0])[0]\n",
    "                iy = np.where(Y[:,1]==coord[1])[0]\n",
    "                new_row[1] = new_row[1] + X[iy,ix].item()\n",
    "                new_row[2] = new_row[2] + Y[iy,ix].item()\n",
    "                new_row[3] = new_row[3] + Z[iy,ix].item()\n",
    "                new_row[4] = new_row[4] + Bx[iy,ix].item()\n",
    "                new_row[5] = new_row[5] + By[iy,ix].item()\n",
    "                new_row[6] = new_row[6] + Bz[iy,ix].item()\n",
    "                new_row[7] = new_row[7] + Te[iy,ix].item()\n",
    "                new_row[8] = new_row[8] + n[iy,ix].item()\n",
    "                new_row[9] = new_row[9] + uix[iy,ix].item()\n",
    "                new_row[10] = new_row[10] + uiy[iy,ix].item()\n",
    "                new_row[11] = new_row[11] + uiz[iy,ix].item()\n",
    "                new_row[12] = new_row[12] + uex[iy,ix].item()\n",
    "                new_row[13] = new_row[13] + uey[iy,ix].item()\n",
    "                new_row[14] = new_row[14] + uez[iy,ix].item()\n",
    "                new_row[15] = new_row[15] + E_convx[iy,ix].item()\n",
    "                new_row[16] = new_row[16] + E_convy[iy,ix].item()\n",
    "                new_row[17] = new_row[17] + E_convz[iy,ix].item()\n",
    "                new_row[18] = new_row[18] + dp_dx[iy,ix].item()\n",
    "                new_row[19] = new_row[19] + dp_dy[iy,ix].item()\n",
    "                new_row[20] = new_row[20] + dp_dz[iy,ix].item()\n",
    "                if len(df_data[key])>0: # Compute inertial current using the acceleration between last time step and this one\n",
    "                    # Problem: The velocity from the last time step is the average... will that be an issue?\n",
    "                    new_row[21] = new_row[21] + (n[iy,ix].item())*m_p/((Bx[iy,ix].item()**2+By[iy,ix].item()**2+Bz[iy,ix].item()**2)*1e-9) * (By[iy,ix].item()*(uiz[iy,ix].item()-df_data[key]['uiz'].iloc[-1])/dt - Bz[iy,ix].item()*(uiy[iy,ix].item()-df_data[key]['uiy'].iloc[-1])/dt)*1e3 #A/m^2\n",
    "                    new_row[22] = new_row[22] + (n[iy,ix].item())*m_p/((Bx[iy,ix].item()**2+By[iy,ix].item()**2+Bz[iy,ix].item()**2)*1e-9) * (Bz[iy,ix].item()*(uix[iy,ix].item()-df_data[key]['uix'].iloc[-1])/dt - Bx[iy,ix].item()*(uiz[iy,ix].item()-df_data[key]['uiz'].iloc[-1])/dt)*1e3 #A/m^2\n",
    "                    new_row[23] = new_row[23] + (n[iy,ix].item())*m_p/((Bx[iy,ix].item()**2+By[iy,ix].item()**2+Bz[iy,ix].item()**2)*1e-9) * (Bx[iy,ix].item()*(uiy[iy,ix].item()-df_data[key]['uiy'].iloc[-1])/dt - By[iy,ix].item()*(uix[iy,ix].item()-df_data[key]['uix'].iloc[-1])/dt)*1e3 #A/m^2\n",
    "                else:\n",
    "                    new_row[21] = 0\n",
    "                    new_row[22] = 0\n",
    "                    new_row[23] = 0\n",
    "                new_row[24] = new_row[24] + 1/((Bx[iy,ix].item()**2+By[iy,ix].item()**2+Bz[iy,ix].item()**2)) * (By[iy,ix].item()*dp_dz[iy,ix].item()+Bz[iy,ix].item()*dp_dy[iy,ix].item()) #A/m^2\n",
    "                new_row[25] = new_row[25] + 1/((Bx[iy,ix].item()**2+By[iy,ix].item()**2+Bz[iy,ix].item()**2)) * (Bz[iy,ix].item()*dp_dx[iy,ix].item()+Bx[iy,ix].item()*dp_dz[iy,ix].item()) #A/m^2\n",
    "                new_row[26] = new_row[26] + 1/((Bx[iy,ix].item()**2+By[iy,ix].item()**2+Bz[iy,ix].item()**2)) * (Bx[iy,ix].item()*dp_dy[iy,ix].item()+By[iy,ix].item()*dp_dx[iy,ix].item()) #A/m^2\n",
    "                new_row[27] = new_row[27] + Jx[iy,ix].item()\n",
    "                new_row[28] = new_row[28] + Jy[iy,ix].item()\n",
    "                new_row[29] = new_row[29] + Jz[iy,ix].item()\n",
    "\n",
    "                Bz_max_ls.append(Bz[iy,ix]) # Save all the Bz values to find the max in the DF\n",
    "                \n",
    "            # Divide by the total number of cells for this DF to get the average quantity\n",
    "            new_row = new_row/(i+1) \n",
    "            new_row[0] = time # Set the first column to the time\n",
    "            new_row[30] = np.max(Bz_max_ls) # Set the 9th column to the max Bz\n",
    "            new_row[31] = (1/64)**2*(i+1) # Set the last row to the area\n",
    "            \n",
    "            temp = df_data[key]\n",
    "            temp.loc[len(temp)] = new_row\n",
    "            df_data[key] = temp # Add this new row to the correct dataframe\n",
    "\n",
    "            # Show a trace of each current DF's path\n",
    "            #ax.plot(temp[\"X\"],temp[\"Y\"],temp[\"Z\"], color = color_ls[key%10])\n",
    "\n",
    "            ######################## PLOT2 START ################################\n",
    "\n",
    "            # Plot outline and traces of each DF\n",
    "        \n",
    "            # Pull out X,Y,Z coords of each cell of this DF in the current sheet\n",
    "            X_region, Y_region = df_dict[key]\n",
    "            Z_region = Z[find_indices(X_region, Y_region, X, Y)].tolist()\n",
    "            # Get boundary points to outline this df\n",
    "            #X_bound,Y_bound = find_boundary_points(X_region, Y_region)\n",
    "            #Z_bound = Z[find_indices(X_bound, Y_bound, X, Y)].tolist()\n",
    "            # Make the plot wrap around as a loop\n",
    "            #X_bound.append(X_bound[0])\n",
    "            #Y_bound.append(Y_bound[0])\n",
    "            #Z_bound.append(Z_bound[0])\n",
    "            #ax.scatter(X_bound, Y_bound, Z_bound, alpha=0.05, color = color_ls[key%10],zorder=5)#, label=str('DF '+str(key)),zorder=5)\n",
    "            #ax.plot(X_bound, Y_bound, Z_bound, alpha=0.9, color = color_ls[key%9],zorder=2.5, linewidth=1)#, label=str('DF '+str(key)),zorder=5)\n",
    "            ax.scatter(X_region, Y_region, Z_region, s = 0.15, color = color_ls[key%9],zorder=6)#, label=str('DF '+str(key)),zorder=5)\n",
    "\n",
    "            # Find seed points for field lines\n",
    "            if key in df_seeds.keys():   \n",
    "                # Update DF seeds through bulk electron velocity\n",
    "                df_seeds[key][:,0] = df_seeds[key][:,0] + dt*df_data[key]['uex'].iloc[-1]*1e3/R_M\n",
    "                df_seeds[key][:,1] = df_seeds[key][:,1] + dt*df_data[key]['uey'].iloc[-1]*1e3/R_M\n",
    "                # Field lines tend to advect outside of the DF, so iterate through each to check\n",
    "                for iseed in range(len(df_seeds[key])):\n",
    "                    if (df_seeds[key][iseed,0] > np.max(X_region)) or (df_seeds[key][iseed,0] < np.min(X_region)) or (df_seeds[key][iseed,1] > np.max(Y_region)) or (df_seeds[key][iseed,1] < np.min(Y_region)):\n",
    "                        new_loc = random.randint(0,len(X_region)-1)\n",
    "                        print(\"Field line seed left the DF! Moved seed at\",df_seeds[key][iseed,:],\"to\",X_region[new_loc],Y_region[new_loc],0.2)\n",
    "                        df_seeds[key][iseed,0] = X_region[new_loc]\n",
    "                        df_seeds[key][iseed,1] = Y_region[new_loc]\n",
    "                        df_seeds[key][iseed,2] = 0.2\n",
    "                    \n",
    "            # For first time this DF is generated, make all new seed points\n",
    "            else:\n",
    "                # Add stream traces\n",
    "                trace_skip=10\n",
    "                df_seeds[key] = np.zeros((len(X_region)//trace_skip+1,3))\n",
    "                df_seeds[key][:,0] = X_region[::max(len(X_region),trace_skip)]\n",
    "                df_seeds[key][:,1] = Y_region[::max(len(X_region),trace_skip)]\n",
    "                df_seeds[key][:,2] = Z_region[::max(len(X_region),trace_skip)]\n",
    "\n",
    "            # Trace the field lines\n",
    "            tracer.trace(df_seeds[key], grid)\n",
    "\n",
    "            # Plot them\n",
    "            for iseed in range(len(df_seeds[key])):\n",
    "                if do_zoom and (float(time)>zoom_time_start):\n",
    "                    above = np.where((tracer.xs[iseed][:,2]>=df_seeds[key][iseed][2]) & (tracer.xs[iseed][:,0]<zoom_xmax) & (tracer.xs[iseed][:,0]>zoom_xmin) & (tracer.xs[iseed][:,1]<zoom_ymax) & (tracer.xs[iseed][:,1]>zoom_xmin) & (tracer.xs[iseed][:,2]<zoom_zmax) & (tracer.xs[iseed][:,2]>zoom_zmin))[0]\n",
    "                    below = np.where((tracer.xs[iseed][:,2]<df_seeds[key][iseed][2]) & (tracer.xs[iseed][:,0]<zoom_xmax) & (tracer.xs[iseed][:,0]>zoom_xmin) & (tracer.xs[iseed][:,1]<zoom_ymax) & (tracer.xs[iseed][:,1]>zoom_xmin) & (tracer.xs[iseed][:,2]<zoom_zmax) & (tracer.xs[iseed][:,2]>zoom_zmin))[0]\n",
    "                else:\n",
    "                    above = np.where(tracer.xs[iseed][:,2]>=df_seeds[key][iseed][2])[0]\n",
    "                    below = np.where(tracer.xs[iseed][:,2]<df_seeds[key][iseed][2])[0]\n",
    "                # Plot the streamlines as a series of lines, without connecting between places where the indexing jumps\n",
    "                start = 0 \n",
    "                for j in range(1,len(above)):\n",
    "                    if (above[j]-above[j-1]>1) or (j==(len(above)-1)):\n",
    "                        ax.plot(tracer.xs[iseed][above[start:j-1],0],tracer.xs[iseed][above[start:j-1],1],tracer.xs[iseed][above[start:j-1],2],\n",
    "                               color=color_ls[key%9],lw=0.3,alpha=1,zorder=3.6) \n",
    "                        start = j\n",
    "                    \n",
    "                start = 0\n",
    "                for j in range(1,len(below)):\n",
    "                    if (below[j]-below[j-1]>1) or (j==(len(below)-1)):\n",
    "                        ax.plot(tracer.xs[iseed][below[start:j-1],0],tracer.xs[iseed][below[start:j-1],1],tracer.xs[iseed][below[start:j-1],2],\n",
    "                               color=color_ls[key%9],lw=0.3,alpha=1,zorder=0.5) \n",
    "                        start = j\n",
    "                #ax.scatter(tracer.xs[iseed][above,0],tracer.xs[iseed][above,1],tracer.xs[iseed][above,2],color=color_ls[key%9],s=0.0005,alpha=0.8,zorder=3.6)\n",
    "                #ax.scatter(tracer.xs[iseed][below,0],tracer.xs[iseed][below,1],tracer.xs[iseed][below,2],color=color_ls[key%9],s=0.0005,alpha=0.8,zorder=0.5)\n",
    "\n",
    "        # Set axes\n",
    "        if do_zoom and (float(time)>zoom_time_start):\n",
    "            ax.set_xlim(zoom_xmin,zoom_xmax)\n",
    "            ax.set_ylim(zoom_ymin,zoom_ymax)\n",
    "            ax.set_zlim(zoom_zmin,zoom_zmax)\n",
    "            x_range = zoom_xmax - zoom_xmin\n",
    "            y_range = zoom_ymax - zoom_ymin\n",
    "            z_range = zoom_zmax - zoom_zmin\n",
    "            ax.set_box_aspect([x_range, y_range, z_range])\n",
    "        else:\n",
    "            ax.set_xlim(X.min(),X.max())\n",
    "            ax.set_ylim(Y.min(),Y.max())\n",
    "            ax.set_zlim(z_lower,z_upper)\n",
    "            x_range = X.max() - X.min()\n",
    "            y_range = Y.max() - Y.min()\n",
    "            z_range = z_upper - z_lower\n",
    "            ax.set_box_aspect([x_range, y_range, z_range])  # Aspect ratio is set based on the data limits\n",
    "\n",
    "        ######################## PLOT2 END ################################\n",
    "\n",
    "    \n",
    "        # Save\n",
    "        fig.savefig(str(str(dir[:-1])+\"_plots/\"+plot_preset+\"_\"+\"%.2f\"%round(float(time),2)+'.png'),bbox_inches='tight',dpi = 300)\n",
    "        plt.close(fig)\n",
    "\n",
    "    # PLOT PRESET '3D_current_sheet'\n",
    "    if plot_preset=='3D_current_sheet':\n",
    "        fig,axs = plt.subplots(nrows = 3, ncols = 2, figsize=(18,10))#, constrained_layout=True)\n",
    "\n",
    "        # Define y values for xz planes\n",
    "        y0=-0.5\n",
    "        y1=0\n",
    "        y2=0.5\n",
    "\n",
    "        # Unpack cs variables\n",
    "        Xcs = datacs[\"X\"]\n",
    "        Ycs = datacs[\"Y\"]\n",
    "        Zcs = datacs[\"Z\"]\n",
    "\n",
    "        # Unpack 3d variables\n",
    "        X3d = data3d[\"X\"]\n",
    "        Y3d = data3d[\"Y\"]\n",
    "        Z3d = data3d[\"Z\"]\n",
    "        Bx3d = data3d[\"Bx\"]\n",
    "        By3d = data3d[\"By\"]\n",
    "        Bz3d = data3d[\"Bz\"]\n",
    "        J3d = np.sqrt(data3d[\"Jx\"]**2+data3d[\"Jy\"]**2+data3d[\"Jz\"]**2)\n",
    "        beta3d = (2*mu_0*(data3d[\"pxxS0\"]+data3d[\"pyyS0\"]+data3d[\"pzzS0\"]+data3d[\"pxxS1\"]+data3d[\"pyyS1\"]+data3d[\"pzzS1\"])*1e9/3/(Bx3d**2+By3d**2+Bz3d**2))\n",
    "\n",
    "        # Find indices for each xz plane\n",
    "        y0i = np.where(Y3d[:,0,0]<y0)[0][-1]\n",
    "        y1i = np.where(Y3d[:,0,0]<y1)[0][-1]\n",
    "        y2i = np.where(Y3d[:,0,0]<y2)[0][-1]\n",
    "\n",
    "        # Plot current density\n",
    "        y_ls = [y0,y1,y2]\n",
    "        yi_ls = [y0i,y1i,y2i]\n",
    "        levels = np.logspace(0,3,21)\n",
    "        for i in range(len(y_ls)):\n",
    "            jplot = axs[i,0].contourf(X3d[yi_ls[i],:,:],Z3d[yi_ls[i],:,:],J3d[yi_ls[i],:,:]*1e9,norm=LogNorm(),levels=levels,cmap='plasma',extend='both')\n",
    "            # Add field lines\n",
    "            xx,zz = np.meshgrid(np.linspace(X3d[yi_ls[i],0,0],X3d[yi_ls[i],-1,0],len(X3d[yi_ls[i],:,0])),\n",
    "                                np.linspace(Z3d[yi_ls[i],0,0],Z3d[yi_ls[i],0,-1],len(Z3d[yi_ls[i],0,:])))\n",
    "            axs[i,0].streamplot(xx,zz,Bx3d[yi_ls[i],:,:].T,Bz3d[yi_ls[i],:,:].T,color='white',linewidth=0.5,broken_streamlines=False,arrowsize=0.5)\n",
    "            # Add current sheet fit\n",
    "            xmax = np.where(datacs['rhoS1'][yi_ls[i],:]==0.0)[0][0]\n",
    "            axs[i,0].plot(Xcs[yi_ls[i],:xmax],Zcs[yi_ls[i],:xmax],color='green',lw=2)\n",
    "            # Other config\n",
    "            axs[i,0].add_patch(plt.Circle((0, 0), np.sqrt(1-y_ls[i]**2), color='grey'))\n",
    "            axs[i,0].add_patch(plt.Circle((0, 0), np.sqrt(0.8**2-y_ls[i]**2), color='black'))\n",
    "            axs[i,0].set_aspect(1) # you may also use am.imshow(..., aspect=\"auto\") to restore the aspect ratio\n",
    "            axs[i,0].set_xlim(-4,-0.5)\n",
    "            axs[i,0].set_ylim(-0.7,0.8)\n",
    "            axs[i,0].tick_params(axis='both',labelsize=15)\n",
    "            axs[i,0].set_title(str(\"Current density at Y = \"+str(y_ls[i])),fontsize=15)\n",
    "            axs[i,0].set_ylabel(\"Z [$R_M$]\",fontsize=15)\n",
    "        axs[i,0].set_xlabel(\"X [$R_M$]\",fontsize=15)\n",
    "        clb1 = fig.colorbar(jplot, ax=axs[:,0], norm=LogNorm()) \n",
    "        clb1.ax.tick_params(labelsize=15)\n",
    "        clb1.locator = LogLocator()\n",
    "        clb1.formatter = LogFormatterSciNotation()  \n",
    "        clb1.ax.set_title('J [nA/m$^2$]',fontsize=15)\n",
    "\n",
    "        # Plot plasma beta\n",
    "        levels = np.logspace(-3,3,21)\n",
    "        for i in range(len(y_ls)):\n",
    "            betaplot = axs[i,1].contourf(X3d[yi_ls[i],:,:],Z3d[yi_ls[i],:,:],beta3d[yi_ls[i],:,:],norm=LogNorm(),levels=levels,cmap='bwr',extend='both')\n",
    "            # Add field lines\n",
    "            xx,zz = np.meshgrid(np.linspace(X3d[yi_ls[i],0,0],X3d[yi_ls[i],-1,0],len(X3d[yi_ls[i],:,0])),\n",
    "                                np.linspace(Z3d[yi_ls[i],0,0],Z3d[yi_ls[i],0,-1],len(Z3d[yi_ls[i],0,:])))\n",
    "            axs[i,1].streamplot(xx,zz,Bx3d[yi_ls[i],:,:].T,Bz3d[yi_ls[i],:,:].T,color='black',linewidth=0.5,broken_streamlines=False,arrowsize=0.5)\n",
    "            # Add current sheet fit\n",
    "            xmax = np.where(datacs['rhoS1'][yi_ls[i],:]==0.0)[0][0]\n",
    "            axs[i,1].plot(Xcs[yi_ls[i],:xmax],Zcs[yi_ls[i],:xmax],color='green',lw=2)\n",
    "            axs[i,1].add_patch(plt.Circle((0, 0), np.sqrt(1-y_ls[i]**2), color='grey'))\n",
    "            axs[i,1].add_patch(plt.Circle((0, 0), np.sqrt(0.8**2-y_ls[i]**2), color='black'))\n",
    "            axs[i,1].set_aspect(1) # you may also use am.imshow(..., aspect=\"auto\") to restore the aspect ratio\n",
    "            axs[i,1].set_xlim(-4,-0.5)\n",
    "            axs[i,1].set_ylim(-0.7,0.8)\n",
    "            axs[i,1].tick_params(axis='both',labelsize=15)\n",
    "            axs[i,1].set_title(str(\"Plasma beta at Y = \"+str(y_ls[i])),fontsize=15)\n",
    "            axs[i,1].set_ylabel(\"Z [$R_M$]\",fontsize=15)\n",
    "        axs[i,1].set_xlabel(\"X [$R_M$]\",fontsize=15)\n",
    "        clb2 = fig.colorbar(betaplot, ax=axs[:,1], norm=LogNorm()) \n",
    "        clb2.ax.tick_params(labelsize=15)\n",
    "        clb2.locator = LogLocator()\n",
    "        clb2.formatter = LogFormatterSciNotation()  \n",
    "        clb2.ax.set_title('beta',fontsize=15)\n",
    "\n",
    "        '''\n",
    "        \n",
    "        # Add labels\n",
    "        ax.set_xlabel(\"X [$R_M$]\",fontsize=12)\n",
    "        ax.set_ylabel(\"Y [$R_M$]\",fontsize=12)\n",
    "        ax.set_zlabel(\"Z [$R_M$]\",fontsize=12)\n",
    "        ax.tick_params(axis='both',labelsize=12)\n",
    "        ax.set_title(str(\"$B_z$ at t=\"+time+\"s\"),fontsize=12,y=1.0, pad=-14)\n",
    "\n",
    "        '''\n",
    "\n",
    "        # Save\n",
    "        fig.savefig(str(str(dir[:-1])+\"_plots/\"+plot_preset+\"_\"+time+'.png'),bbox_inches='tight',pad_inches=0.3, dpi=300)\n",
    "        plt.close(fig)\n",
    "\n",
    "    if plot_preset=='3D_flux_tube_content':\n",
    "\n",
    "        # Set up plot environment\n",
    "        fig = plt.figure(figsize=(18,6))\n",
    "        ax = fig.add_subplot(111)\n",
    "\n",
    "        xlims = [-4,0]\n",
    "        ylims = [-1.2,1.2]\n",
    "        \n",
    "        # Unpack data\n",
    "        Xcs = datacs[\"X\"]\n",
    "        Ycs = datacs[\"Y\"]\n",
    "        Zcs = datacs[\"Z\"]\n",
    "        X3d = data3d[\"X\"]\n",
    "        Y3d = data3d[\"Y\"]\n",
    "        Z3d = data3d[\"Z\"]\n",
    "        Bx3d = data3d[\"Bx\"]\n",
    "        By3d = data3d[\"By\"]\n",
    "        Bz3d = data3d[\"Bz\"]\n",
    "        ncs = datacs[\"rhoS1\"]\n",
    "        n3d = data3d[\"rhoS1\"] * 1e6 # convert to SI\n",
    "        pe3d = ((data3d[\"pxxS0\"]+data3d[\"pyyS0\"]+data3d[\"pzzS0\"])/3*1e-9) # convert to SI\n",
    "        pi3d = ((data3d[\"pxxS1\"]+data3d[\"pyyS1\"]+data3d[\"pzzS1\"])/3*1e-9) # convert to SI\n",
    "\n",
    "        # Ratio of specific heats\n",
    "        gamma = 5/3\n",
    "\n",
    "        # Set up grid for field line tracing\n",
    "        ny,nx,nz = Bx3d.shape\n",
    "        field = np.zeros((nx,ny,nz,3))\n",
    "        field[:,:,:,0] = np.transpose(Bx3d,axes=[1,0,2])\n",
    "        field[:,:,:,1] = np.transpose(By3d,axes=[1,0,2])\n",
    "        field[:,:,:,2] = np.transpose(Bz3d,axes=[1,0,2])\n",
    "        grid_spacing = [1/64,1/64,1/64]\n",
    "        grid = VectorGrid(field, grid_spacing, origin_coord = [X3d.min(),Y3d.min(),Z3d.min()])\n",
    "        nsteps = 10000\n",
    "        step_size = 0.001\n",
    "        tracer = StreamTracer(nsteps, step_size)\n",
    "        trace_skip = 2\n",
    "\n",
    "        # Compute entropy integrand and define interpolator\n",
    "        entropy = (pe3d+pi3d)**(gamma)/np.sqrt(Bx3d**2+By3d**2+Bz3d**2)*1e9 # SI\n",
    "        interpolator = RegularGridInterpolator((X3d[0, :, 0], Y3d[:, 0, 0], Z3d[0, 0, :]), np.swapaxes(entropy,0,1), bounds_error=False, fill_value=None)\n",
    "        \n",
    "        # Define array to save field line entropy\n",
    "        entropy_content = np.zeros_like(Xcs[::trace_skip,::trace_skip])\n",
    "        for ix in range(len(entropy_content[0,:])):\n",
    "            for iy in range(len(entropy_content[:,0])):\n",
    "                seed = np.array((Xcs[iy*trace_skip,ix*trace_skip],Ycs[iy*trace_skip,ix*trace_skip],Zcs[iy*trace_skip,ix*trace_skip]))\n",
    "                tracer.trace(seed, grid)\n",
    "                entropy_content[iy,ix] = np.sum(np.nan_to_num(interpolator(tracer.xs[0])*step_size*R_M))\n",
    "                #if seed[0]>-1.5:\n",
    "                #    print(seed)\n",
    "                #    print(tracer.xs[0])\n",
    "                 #   print(entropy_content[iy,ix])\n",
    "        '''\n",
    "        # Add stream trace seed at each CS x,y\n",
    "        #trace_skip=10\n",
    "        seeds = np.zeros((len(Xcs[::trace_skip,::trace_skip].ravel()),3))\n",
    "        seeds[:,0] = Xcs[::trace_skip,::trace_skip].ravel()\n",
    "        seeds[:,1] = Ycs[::trace_skip,::trace_skip].ravel()\n",
    "        seeds[:,2] = Zcs[::trace_skip,::trace_skip].ravel()\n",
    "\n",
    "        # Trace the field lines\n",
    "        tracer.trace(seeds, grid)\n",
    "\n",
    "        # Set up linear interpolator to get values at each field line point\n",
    "        entropy = (pe3d+pi3d)**(gamma)/np.sqrt(Bx3d**2+By3d**2+Bz3d**2)*1e9 # SI\n",
    "        interpolator = RegularGridInterpolator((X3d[0, :, 0], Y3d[:, 0, 0], Z3d[0, 0, :]), np.swapaxes(entropy,0,1), bounds_error=False, fill_value=None)\n",
    "        \n",
    "        # Integrate quantities along field line\n",
    "        entropy_content = np.zeros(len(seeds))\n",
    "        for i,seed in enumerate(seeds):\n",
    "            entropy_content[i] = np.sum(interpolator(tracer.xs[i])*step_size*R_M)\n",
    "        '''\n",
    "        levels = np.logspace(-5, 2, 31)\n",
    "        plot = ax.contourf(Xcs[::trace_skip,::trace_skip],Ycs[::trace_skip,::trace_skip],entropy_content,cmap=\"viridis\",\n",
    "                           norm=LogNorm(),levels=levels,extend='both')\n",
    "\n",
    "        inner = plt.Circle((0, 0), np.sqrt(0.8**2-np.mean(Z)**2), color='black')\n",
    "        outer = plt.Circle((0, 0), np.sqrt(1-np.mean(Z)**2), color='grey')\n",
    "\n",
    "        x_major_ticks = np.arange(xlims[0], xlims[1], 0.25)\n",
    "        x_minor_ticks = np.arange(xlims[0], xlims[1], 0.05)\n",
    "        y_major_ticks = np.arange(ylims[0], ylims[1], 0.25)\n",
    "        y_minor_ticks = np.arange(ylims[0], ylims[1], 0.05)\n",
    "\n",
    "        ax.set_xticks(x_major_ticks)\n",
    "        ax.set_xticks(x_minor_ticks, minor=True)\n",
    "        ax.set_yticks(y_major_ticks)\n",
    "        ax.set_yticks(y_minor_ticks, minor=True)\n",
    "\n",
    "        ax.grid(which='both')\n",
    "        ax.grid(which='minor', alpha=0.2)\n",
    "        ax.grid(which='major', alpha=0.5)\n",
    "        \n",
    "        clb1 = fig.colorbar(plot, ax=ax, norm=LogNorm()) \n",
    "        clb1.ax.tick_params(labelsize=15)\n",
    "        clb1.locator = LogLocator()\n",
    "        clb1.formatter = LogFormatterSciNotation()  \n",
    "        clb1.ax.set_title('$H$ ',fontsize=15)\n",
    "        \n",
    "        # Add labels\n",
    "        ax.set_xlabel(\"X [$R_M$]\",fontsize=12)\n",
    "        ax.set_ylabel(\"Y [$R_M$]\",fontsize=12)\n",
    "        ax.add_patch(outer)\n",
    "        ax.add_patch(inner)\n",
    "        ax.set_xlim(xlims)\n",
    "        ax.set_ylim(ylims)\n",
    "        ax.tick_params(axis='both',labelsize=12)\n",
    "        ax.set_title(str(\"Density at t=\"+time+\"s\"),fontsize=12)\n",
    "        ax.set_aspect(1)\n",
    "\n",
    "        # Save\n",
    "        fig.savefig(str(str(dir[:-1])+\"_plots/\"+plot_preset+\"_\"+time+'.png'),bbox_inches='tight',pad_inches=0.3, dpi=300)\n",
    "        plt.close(fig)\n",
    "\n",
    "    if plot_preset=='3D_gridscale_df_tracker':\n",
    "\n",
    "        # On the first iteration, define an empty dictionary to save our DF data to\n",
    "        if iter == 0:\n",
    "            df_data = {} # This stores all the DFs we have seen\n",
    "            df_dict = None # This stores all the cells of DFs from the previous step\n",
    "            df_seeds = {} # This stores all the field line seed locations for the DFs\n",
    "\n",
    "        # Define X cutoff, if required\n",
    "        x_cutoff=0\n",
    "\n",
    "        # Unpack data\n",
    "        X = datacs[\"X\"][:,x_cutoff:]\n",
    "        Y = datacs[\"Y\"][:,x_cutoff:]\n",
    "        Z = datacs[\"Z\"][:,x_cutoff:]\n",
    "        X3d = data3d[\"X\"][:,x_cutoff:,:]\n",
    "        Y3d = data3d[\"Y\"][:,x_cutoff:,:]\n",
    "        Z3d = data3d[\"Z\"][:,x_cutoff:,:]\n",
    "        Bx3d = data3d[\"Bx\"][:,x_cutoff:,:]\n",
    "        By3d = data3d[\"By\"][:,x_cutoff:,:]\n",
    "        Bz3d = data3d[\"Bz\"][:,x_cutoff:,:]\n",
    "        Jx = datacs[\"Jx\"][:,x_cutoff:]\n",
    "        Jy = datacs[\"Jy\"][:,x_cutoff:]\n",
    "        Jz = datacs[\"Jz\"][:,x_cutoff:]\n",
    "        Bx = datacs[\"Bx\"][:,x_cutoff:] \n",
    "        By = datacs[\"By\"][:,x_cutoff:] \n",
    "        Bz = datacs[\"Bz\"][:,x_cutoff:] \n",
    "        n = datacs[\"rhoS1\"][:,x_cutoff:] * 1e6 # convert to SI\n",
    "        pe = ((datacs[\"pxxS0\"]+datacs[\"pyyS0\"]+datacs[\"pzzS0\"])/3*1e-9)[:,x_cutoff:] # convert to SI\n",
    "        Te = pe/n/k_b / 11605 / 1e3 #Convert to keV\n",
    "        uix = datacs[\"uxS1\"][:,x_cutoff:]\n",
    "        uiy = datacs[\"uyS1\"][:,x_cutoff:]\n",
    "        uiz = datacs[\"uyS1\"][:,x_cutoff:]\n",
    "        uex = datacs[\"uxS0\"][:,x_cutoff:]\n",
    "        uey = datacs[\"uyS0\"][:,x_cutoff:]\n",
    "        uez = datacs[\"uyS0\"][:,x_cutoff:]\n",
    "        beta = (2*mu_0*(datacs[\"pxxS0\"]+datacs[\"pyyS0\"]+datacs[\"pzzS0\"]+datacs[\"pxxS1\"]+datacs[\"pyyS1\"]+datacs[\"pzzS1\"])*1e9/3/(datacs[\"Bx\"]**2+datacs[\"By\"]**2+datacs[\"Bz\"]**2))[:,x_cutoff:]\n",
    "        E_convx = (-(uey*Bz-uez*By)*1000*1e-9) # Convert to V/m ie SI\n",
    "        E_convy = (-(uez*Bx-uex*Bz)*1000*1e-9)\n",
    "        E_convz = (-(uex*By-uey*Bx)*1000*1e-9)\n",
    "        dp_dx = datacs['dp_dx'][:,x_cutoff:]\n",
    "        dp_dy = datacs['dp_dy'][:,x_cutoff:]\n",
    "        dp_dz = datacs['dp_dz'][:,x_cutoff:]\n",
    "\n",
    "        # Compute average values of Bz in the 5seconds preceeding the current time\n",
    "        Bz_avg = average_value([\"Bz\"],float(time),-1,0)[\"Bz\"][:,x_cutoff:]\n",
    "        delta_Bz3d = Bz3d - average_value([\"Bz\"],float(time),-5,-2,type='numpy')[\"Bz\"][:,x_cutoff:,:]\n",
    "\n",
    "        # Compute DF metric\n",
    "        metric = (Bz-Bz_avg)\n",
    "\n",
    "        # Set bounds on metric\n",
    "        min_value = 10 #nT \n",
    "        min_size = 10\n",
    "        dx = 1/64\n",
    "\n",
    "        # Set z bounds\n",
    "        z_lower = -1\n",
    "        z_upper = 1\n",
    "\n",
    "        # Compute zoom rates, if activated\n",
    "        if do_zoom:\n",
    "            zoom_dxdt_min = (zoom_x_range[0]-np.min(X))/(zoom_time_end-zoom_time_start)\n",
    "            zoom_dxdt_max = (np.max(X)-zoom_x_range[1])/(zoom_time_end-zoom_time_start)\n",
    "            zoom_dydt_min = (zoom_y_range[0]-np.min(Y))/(zoom_time_end-zoom_time_start)\n",
    "            zoom_dydt_max = (np.max(Y)-zoom_y_range[1])/(zoom_time_end-zoom_time_start)\n",
    "            zoom_dzdt_min = (zoom_z_range[0]-z_lower)/(zoom_time_end-zoom_time_start)\n",
    "            zoom_dzdt_max = (z_upper-zoom_y_range[1])/(zoom_time_end-zoom_time_start)\n",
    "            zoom_dazimdt = (azim_end - azim_start)/(zoom_time_end-zoom_time_start)\n",
    "        \n",
    "        # Find DF regions\n",
    "        # Create boolean mask where Z exceeds z_0\n",
    "        mask = metric > min_value\n",
    "        \n",
    "        # Label connected regions\n",
    "        structure = np.zeros((3, 3), dtype=bool)  # Structuring element\n",
    "        structure[1,:] = True\n",
    "        structure[:,1] = True # Use a + shaped mask\n",
    "        labeled, num_features = label(mask, structure=structure)\n",
    "        \n",
    "        # Find all the DF regions in this time slice\n",
    "        new_df_dict = {}\n",
    "        count=1\n",
    "        for feature_num in range(1, num_features + 1):\n",
    "            region = (labeled == feature_num)\n",
    "            DF_beta = np.mean(beta[region])\n",
    "            # Remove regions that are too small or have an average beta<1\n",
    "            if (len(X[region])>min_size) and (DF_beta>1):\n",
    "                new_df_dict[count] = (X[region], Y[region])\n",
    "                count+=1\n",
    "    \n",
    "        print(\"Found\",len(new_df_dict.keys()),\"DFs at this time\")\n",
    "\n",
    "        ################# Plot #################\n",
    "        fig = plt.figure(figsize=(18,6))\n",
    "        ax = fig.add_subplot(111, projection=\"3d\",computed_zorder=False)\n",
    "\n",
    "        mid = 95 # Row index corresponding to midnight \n",
    "\n",
    "        # Mask out values\n",
    "        if do_zoom and (float(time)>zoom_time_start):\n",
    "            if (float(time)>=zoom_time_end):\n",
    "                zoom_time = zoom_time_stop-zoom_time_start # Effectively applies a stopping condition, to \"stay\" zoomed\n",
    "            else:\n",
    "                zoom_time = float(time)-zoom_time_start\n",
    "            zoom_xmin = np.min(X)+zoom_time*zoom_dxdt_min\n",
    "            zoom_xmax = np.max(X)-zoom_time*zoom_dxdt_max\n",
    "            zoom_ymin = np.min(Y)+zoom_time*zoom_dydt_min\n",
    "            zoom_ymax = np.max(Y)-zoom_time*zoom_dydt_max\n",
    "            zoom_zmin = z_lower+zoom_time*zoom_dzdt_min\n",
    "            zoom_zmax = z_upper-zoom_time*zoom_dzdt_max\n",
    "            zoom_mask = (X > zoom_xmax) | (X < zoom_xmin) | (Y > zoom_ymax) | (Y < zoom_ymin) \n",
    "            Z[zoom_mask] = np.nan\n",
    "        radius = 1.01\n",
    "        mask = (X**2 + Y**2) < radius**2\n",
    "        Z[mask] = np.nan\n",
    "\n",
    "        mid = 90 # Row index corresponding to midnight \n",
    "        # Define colormap and lighting\n",
    "        vmin=-25\n",
    "        vmax=25\n",
    "        norm = plt.Normalize(vmin,vmax)\n",
    "        dawn_colors = cm.bwr(norm(metric[:mid,:]),alpha=0.9)\n",
    "        dusk_colors = cm.bwr(norm(metric[mid:,:]),alpha=0.9)\n",
    "\n",
    "        # Set the lighting\n",
    "        light = LightSource()  # Azimuth and altitude of the light source\n",
    "        dawn_illuminated_colors = light.shade_rgb(dawn_colors, Z[:mid,:], blend_mode='soft')  # Apply light source shading\n",
    "        dusk_illuminated_colors = light.shade_rgb(dusk_colors, Z[mid:,:], blend_mode='soft')  # Apply light source shading\n",
    "\n",
    "        # move camera view\n",
    "        if do_zoom and (float(time)>zoom_time_start):\n",
    "            ax.view_init(elev=25, azim=azim_start + zoom_dazimdt*(zoom_time))\n",
    "        else:\n",
    "            ax.view_init(elev=25, azim=azim_start)\n",
    "            \n",
    "        # Create the surface plot\n",
    "        surf1 = ax.plot_surface(X[:mid,:], Y[:mid,:], Z[:mid,:], facecolors=dawn_illuminated_colors, rstride=1, cstride=1, antialiased=False, zorder=2)\n",
    "        surf2 = ax.plot_surface(X[mid:,:], Y[mid:,:], Z[mid:,:], facecolors=dusk_illuminated_colors, rstride=1, cstride=1, antialiased=False, zorder=0.75)\n",
    "        \n",
    "        # Add a color bar \n",
    "        m = cm.ScalarMappable(cmap=cm.bwr, norm=norm)\n",
    "        m.set_array(metric)\n",
    "        clb = fig.colorbar(m, ax=ax, shrink=0.3, aspect=7,anchor=(0.0,0.3))\n",
    "        clb.ax.tick_params(labelsize=12)\n",
    "        clb.ax.set_title('$\\delta B_{z}$ [nT]',fontsize=12,pad=10)\n",
    "\n",
    "        # Add big x axis\n",
    "        if do_zoom and (float(time)>zoom_time_start):\n",
    "            #ax.plot([zoom_xmin,-1],[0,0],[0.2,0.2],color='black',lw=1)\n",
    "            #ax.scatter(np.arange(int(zoom_xmin),0),np.arange(int(zoom_xmin),0)*0,np.arange(int(zoom_xmin),0)*0+0.2,s=4,color='black')\n",
    "            # Show Mercury\n",
    "            plot_sphere(ax,radius=1,color='lightgrey',alpha=0.5,zorder=1,quarter=False,\n",
    "                    xlims=[zoom_xmin,zoom_xmax],ylims=[zoom_ymin,zoom_ymax],zlims=[zoom_zmin,zoom_zmax])\n",
    "            plot_sphere(ax,radius=0.8,color='grey',alpha=1,zorder=1.25,quarter=False,\n",
    "                    xlims=[zoom_xmin,zoom_xmax],ylims=[zoom_ymin,zoom_ymax],zlims=[zoom_zmin,zoom_zmax])\n",
    "        else:\n",
    "            ax.plot([np.min(X[:mid,:]),-1],[0,0],[0.2,0.2],color='black',lw=1)\n",
    "            ax.scatter([-4,-3,-2,-1],[0,0,0,0],[0.2,0.2,0.2,0.2],s=4,color='black')\n",
    "            # Show Mercury\n",
    "            plot_sphere(ax,radius=1,color='lightgrey',alpha=0.5,zorder=1,quarter=False)\n",
    "            plot_sphere(ax,radius=0.8,color='grey',alpha=1,zorder=1.25,quarter=False)\n",
    "\n",
    "        # Add labels\n",
    "        ax.set_xlabel(\"X [$R_M$]\",fontsize=12)\n",
    "        ax.set_ylabel(\"Y [$R_M$]\",fontsize=12)\n",
    "        ax.set_zlabel(\"Z [$R_M$]\",fontsize=12)\n",
    "        ax.tick_params(axis='both',labelsize=12)\n",
    "        ax.set_title(str(\"$\\delta B_{z}$ at t=\"+time+\"s\"),fontsize=12,y=1.0, pad=-5)\n",
    "\n",
    "        ################# END PLOT #################\n",
    "        \n",
    "        # Compare to previous df_dict, if any, and relabel DFs for continuity\n",
    "    \n",
    "        if df_dict is not None and len(new_df_dict.keys())>0: # Only proceed with attempting to match DFs if we have data from last timestep and there is at least 1 DF in this timestep\n",
    "            # The name of the game is just to relabel all the keys appropriately.\n",
    "            # Set up a new dictionary where we will make all these changes.\n",
    "            next_df_dict = {}\n",
    "    \n",
    "            # Iterate through new_key_dict, which has all the dfs identified in this step (with keys which will generally be totally wrong)\n",
    "            new_keys = list(new_df_dict.keys()).copy()\n",
    "            overlap_masks = [] # Here, we will store key pairs: [new_key, old_key, agreement_lvl]\n",
    "            for new_key in new_keys:\n",
    "                for old_key in df_dict.keys():\n",
    "                    # Compare all the currently identified DFs to those from the previous step, and save an entry to overlap_masks if any overlap\n",
    "                    xmask = np.isin(new_df_dict[new_key][0],df_dict[old_key][0])\n",
    "                    ymask = np.isin(new_df_dict[new_key][1],df_dict[old_key][1])\n",
    "                    mask=xmask&ymask\n",
    "                    if mask.any():\n",
    "                        print(\"New DF#\"+str(new_key)+\" overlaps with old DF#\"+str(old_key))\n",
    "                        overlap_masks.append([new_key,old_key,sum(mask)]) # sum(mask) gives the number of \"True\" in the list\n",
    "            # Sometimes a weird error happens where we have new DFs but none overlap and we have an empty matrix.. this is a hotfix for that case:\n",
    "            #if len(overlap_masks)==0:\n",
    "            #    df_dict = new_df_dict   \n",
    "            #else:\n",
    "            # Matrix stores the relationship between the DFs labelled at this time and the previous time.\n",
    "            unfiltered_matrix = np.array(overlap_masks, ndmin=2)\n",
    "            # If a new DF has appeared, we have not accounted for it yet (since it will have no overlap with the previous step).\n",
    "            for key in new_keys:\n",
    "                if len(overlap_masks)==0:\n",
    "                    unfiltered_matrix = np.array([key,-1,0], ndmin=2) # In some cases, we have only new DFs and no overlap, so unfiltered matrix cannot be indexed in the next elif and the code crashes. This hotfix solves that.\n",
    "                elif key not in unfiltered_matrix[:,0]:\n",
    "                    unfiltered_matrix = np.vstack([unfiltered_matrix, [key,-1,0]]) # Add newly formed DFs to the register, and associate it with the previous DF -1 (i.e. assocaited with none)\n",
    "            unfiltered_matrix = unfiltered_matrix[unfiltered_matrix[:,2].argsort()[::-1]] # Sort to start with largest overlap ones\n",
    "            \n",
    "            # We now need to remove repeated rows with repeated values of new_key (column zero) to stop an infinite cascade of new DFs\n",
    "            # Now that we've sorted the data, the dfs with the most overlap will be selected for\n",
    "            # Only need to filter out rows if there are more rows in matrix than the number of dfs at this time\n",
    "            if len(unfiltered_matrix[:,0])>len(new_df_dict.keys()):\n",
    "                matrix = remove_duplicate_rows(unfiltered_matrix)\n",
    "            else:\n",
    "                matrix = unfiltered_matrix\n",
    "            \n",
    "            print(\"NEW DF KEY   OLD DF KEY   MATCH\")\n",
    "            print(matrix)\n",
    "    \n",
    "            temp_key=-1\n",
    "    \n",
    "            for i in range(len(matrix[:,0])):\n",
    "                if matrix[i,1]==-1: # this means its a newly formed DF in this step.\n",
    "                    print(\"DF#\"+str(matrix[i,0]),\"is a new one and is temporarily assigned #\"+str(temp_key))\n",
    "                    r = np.mean(np.sqrt(new_df_dict[matrix[i,0]][0]**2+new_df_dict[matrix[i,0]][1]**2))\n",
    "                    if r>1.25:\n",
    "                        next_df_dict[temp_key] = new_df_dict[matrix[i,0]] # Give it a temporary name, we will come back to it at the end\n",
    "                        temp_key-=1\n",
    "                    else:\n",
    "                        print(\"This DF formed too close to the planet, throwing it out...\")\n",
    "                        #print(\"position:\",r,\"    beta:\",beta_DR)\n",
    "                elif (matrix[i,1] not in next_df_dict.keys()): # Check to see if this DF has already been named for the updated dict. If its not there, add it\n",
    "                    print(\"DF#\"+str(matrix[i,1])+\" has been tracked from the previous step\")\n",
    "                    next_df_dict[matrix[i,1]] = new_df_dict[matrix[i,0]] # The name of the DF is taken from df_dict, and is populated with data from the new dict. The matrix is used as a reference to connect the two.\n",
    "                else: # This means this DF has already been identified with a previous DF that has more overlap with it i.e. it is a child\n",
    "                    print(\"DF#\"+str(matrix[i,1])+\" has split and formed a new DF, which is temporarily assigned #\"+str(temp_key))\n",
    "                    next_df_dict[temp_key] = new_df_dict[matrix[i,0]] # Give it a temporary name, we will come back to it at the end\n",
    "                    temp_key-=1\n",
    "            # All DFs identified in this step have been assigned names in next_df_dict. Now, we need to rename the negative ones to the next largest names\n",
    "            if len(df_data.keys())==0:\n",
    "                new_df_key = 1    \n",
    "            else:\n",
    "                new_df_key = np.max(list(df_data.keys()))+1 # Start naming at one larger than the maximum df number already used\n",
    "            for key in list(next_df_dict.keys()).copy():\n",
    "                if key<0:\n",
    "                    print(\"Reassigning the temporary DF#\"+str(key),\"to DF#\"+str(new_df_key))\n",
    "                    next_df_dict[new_df_key] = next_df_dict.pop(key)\n",
    "                    new_df_key+=1\n",
    "            print(\"Feature tracking complete!\")\n",
    "            df_dict = next_df_dict   \n",
    "        else:\n",
    "            df_dict = new_df_dict   \n",
    "\n",
    "        ####### PLOT 2 SETUP ######\n",
    "        color_ls = [\"tab:blue\",\"tab:green\",\"tab:blue\",\"tab:orange\",\"tab:purple\",\"tab:brown\",\"tab:pink\",\"tab:olive\",\"tab:cyan\"]\n",
    "        # Set up grid for field line tracing\n",
    "        ny,nx,nz = Bx3d.shape\n",
    "        field = np.zeros((nx,ny,nz,3))\n",
    "        field[:,:,:,0] = np.transpose(Bx3d,axes=[1,0,2])\n",
    "        field[:,:,:,1] = np.transpose(By3d,axes=[1,0,2])\n",
    "        field[:,:,:,2] = np.transpose(Bz3d,axes=[1,0,2])\n",
    "        grid_spacing = [1/64,1/64,1/64]\n",
    "        grid = VectorGrid(field, grid_spacing, origin_coord = [X3d.min(),Y3d.min(),Z3d.min()])\n",
    "        nsteps = 10000\n",
    "        step_size = 0.001\n",
    "        tracer = StreamTracer(nsteps, step_size)\n",
    "        ##### END PLOT 2 SETUP #########\n",
    "\n",
    "            \n",
    "        # For each DF, either create a new item to store info about it or add to an existing item\n",
    "        for key in df_dict.keys():\n",
    "            if key not in df_data.keys(): # Create new dataframe if this df has not been registered already\n",
    "                df_data[key] = pd.DataFrame(columns=['time','X','Y','Z','Bx','By','Bz','Te','n','uix',\"uiy\",\"uiz\",'uex',\"uey\",\"uez\",\n",
    "                                                     \"E_convx\",\"E_convy\",\"E_convz\",\"dp_dx\",\"dp_dy\",\"dp_dz\",\n",
    "                                                     \"J_inrt,x\",\"J_inrt,y\",\"J_inrt,z\",\"J_gradp,x\",\"J_gradp,y\",\"J_gradp,z\",\n",
    "                                                     \"Jx\",\"Jy\",\"Jz\",\"Bz_max\",'area'])\n",
    "            new_row = np.zeros(32)\n",
    "            # Now we iterate over each coordinate associated with this DF\n",
    "            Bz_max_ls = []\n",
    "            for i in range(len(df_dict[key][0])):\n",
    "                coord = [df_dict[key][0][i],df_dict[key][1][i]] # Remember, each item in df_dict is a tuple of the X coords and Y coords\n",
    "                # Find which indices of \"data\" these coordinates correspond to\n",
    "                ix = np.where(X[0,:]==coord[0])[0]\n",
    "                iy = np.where(Y[:,1]==coord[1])[0]\n",
    "                new_row[1] = new_row[1] + X[iy,ix].item()\n",
    "                new_row[2] = new_row[2] + Y[iy,ix].item()\n",
    "                new_row[3] = new_row[3] + Z[iy,ix].item()\n",
    "                new_row[4] = new_row[4] + Bx[iy,ix].item()\n",
    "                new_row[5] = new_row[5] + By[iy,ix].item()\n",
    "                new_row[6] = new_row[6] + Bz[iy,ix].item()\n",
    "                new_row[7] = new_row[7] + Te[iy,ix].item()\n",
    "                new_row[8] = new_row[8] + n[iy,ix].item()\n",
    "                new_row[9] = new_row[9] + uix[iy,ix].item()\n",
    "                new_row[10] = new_row[10] + uiy[iy,ix].item()\n",
    "                new_row[11] = new_row[11] + uiz[iy,ix].item()\n",
    "                new_row[12] = new_row[12] + uex[iy,ix].item()\n",
    "                new_row[13] = new_row[13] + uey[iy,ix].item()\n",
    "                new_row[14] = new_row[14] + uez[iy,ix].item()\n",
    "                new_row[15] = new_row[15] + E_convx[iy,ix].item()\n",
    "                new_row[16] = new_row[16] + E_convy[iy,ix].item()\n",
    "                new_row[17] = new_row[17] + E_convz[iy,ix].item()\n",
    "                new_row[18] = new_row[18] + dp_dx[iy,ix].item()\n",
    "                new_row[19] = new_row[19] + dp_dy[iy,ix].item()\n",
    "                new_row[20] = new_row[20] + dp_dz[iy,ix].item()\n",
    "                if len(df_data[key])>0: # Compute inertial current using the acceleration between last time step and this one\n",
    "                    # Problem: The velocity from the last time step is the average... will that be an issue?\n",
    "                    new_row[21] = new_row[21] + (n[iy,ix].item())*m_p/((Bx[iy,ix].item()**2+By[iy,ix].item()**2+Bz[iy,ix].item()**2)*1e-9) * (By[iy,ix].item()*(uiz[iy,ix].item()-df_data[key]['uiz'].iloc[-1])/dt - Bz[iy,ix].item()*(uiy[iy,ix].item()-df_data[key]['uiy'].iloc[-1])/dt)*1e3 #A/m^2\n",
    "                    new_row[22] = new_row[22] + (n[iy,ix].item())*m_p/((Bx[iy,ix].item()**2+By[iy,ix].item()**2+Bz[iy,ix].item()**2)*1e-9) * (Bz[iy,ix].item()*(uix[iy,ix].item()-df_data[key]['uix'].iloc[-1])/dt - Bx[iy,ix].item()*(uiz[iy,ix].item()-df_data[key]['uiz'].iloc[-1])/dt)*1e3 #A/m^2\n",
    "                    new_row[23] = new_row[23] + (n[iy,ix].item())*m_p/((Bx[iy,ix].item()**2+By[iy,ix].item()**2+Bz[iy,ix].item()**2)*1e-9) * (Bx[iy,ix].item()*(uiy[iy,ix].item()-df_data[key]['uiy'].iloc[-1])/dt - By[iy,ix].item()*(uix[iy,ix].item()-df_data[key]['uix'].iloc[-1])/dt)*1e3 #A/m^2\n",
    "                else:\n",
    "                    new_row[21] = 0\n",
    "                    new_row[22] = 0\n",
    "                    new_row[23] = 0\n",
    "                new_row[24] = new_row[24] + 1/((Bx[iy,ix].item()**2+By[iy,ix].item()**2+Bz[iy,ix].item()**2)) * (By[iy,ix].item()*dp_dz[iy,ix].item()+Bz[iy,ix].item()*dp_dy[iy,ix].item()) #A/m^2\n",
    "                new_row[25] = new_row[25] + 1/((Bx[iy,ix].item()**2+By[iy,ix].item()**2+Bz[iy,ix].item()**2)) * (Bz[iy,ix].item()*dp_dx[iy,ix].item()+Bx[iy,ix].item()*dp_dz[iy,ix].item()) #A/m^2\n",
    "                new_row[26] = new_row[26] + 1/((Bx[iy,ix].item()**2+By[iy,ix].item()**2+Bz[iy,ix].item()**2)) * (Bx[iy,ix].item()*dp_dy[iy,ix].item()+By[iy,ix].item()*dp_dx[iy,ix].item()) #A/m^2\n",
    "                new_row[27] = new_row[27] + Jx[iy,ix].item()\n",
    "                new_row[28] = new_row[28] + Jy[iy,ix].item()\n",
    "                new_row[29] = new_row[29] + Jz[iy,ix].item()\n",
    "\n",
    "                Bz_max_ls.append(Bz[iy,ix]) # Save all the Bz values to find the max in the DF\n",
    "                \n",
    "            # Divide by the total number of cells for this DF to get the average quantity\n",
    "            new_row = new_row/(i+1) \n",
    "            new_row[0] = time # Set the first column to the time\n",
    "            new_row[30] = np.max(Bz_max_ls) # Set the 9th column to the max Bz\n",
    "            new_row[31] = (1/64)**2*(i+1) # Set the last row to the area\n",
    "            \n",
    "            temp = df_data[key]\n",
    "            temp.loc[len(temp)] = new_row\n",
    "            df_data[key] = temp # Add this new row to the correct dataframe\n",
    "\n",
    "            # Show a trace of each current DF's path\n",
    "            #ax.plot(temp[\"X\"],temp[\"Y\"],temp[\"Z\"], color = color_ls[key%10])\n",
    "\n",
    "            ######################## PLOT2 START ################################\n",
    "            \n",
    "            # Plot outline and traces of each DF\n",
    "        \n",
    "            # Pull out X,Y,Z coords of each cell of this DF in the current sheet\n",
    "            X_df, Y_df = df_dict[key]\n",
    "            Z_df = Z[find_indices(X_df, Y_df, X, Y)]\n",
    "            Jx_df = Jx[find_indices(X_df, Y_df, X, Y)] # Comes in A/m^2\n",
    "            Jy_df = Jy[find_indices(X_df, Y_df, X, Y)]\n",
    "            Jz_df = Jz[find_indices(X_df, Y_df, X, Y)]\n",
    "            Bx_df = Bx[find_indices(X_df, Y_df, X, Y)]*1e-9 # Comes in nT\n",
    "            By_df = By[find_indices(X_df, Y_df, X, Y)]*1e-9\n",
    "            Bz_df = Bz[find_indices(X_df, Y_df, X, Y)]*1e-9\n",
    "            dp_dx_df = dp_dx[find_indices(X_df, Y_df, X, Y)]*1e-9 # Comes in nPa/m\n",
    "            dp_dy_df = dp_dy[find_indices(X_df, Y_df, X, Y)]*1e-9\n",
    "            dp_dz_df = dp_dz[find_indices(X_df, Y_df, X, Y)]*1e-9\n",
    "            uex_df = uex[find_indices(X_df, Y_df, X, Y)] # Comes in km/s\n",
    "            uey_df = uey[find_indices(X_df, Y_df, X, Y)]\n",
    "\n",
    "            zoom_scale = (np.max(X)-np.min(X))/(zoom_xmax-zoom_xmin)\n",
    "            \n",
    "            ax.scatter(X_df, Y_df, Z_df, s = 0.15*zoom_scale, color = color_ls[key%9],zorder=5)#, label=str('DF '+str(key)),zorder=5)\n",
    "            ax.quiver(np.mean(X_df),np.mean(Y_df),np.mean(Z_df),np.mean(uex_df),np.mean(uey_df),0,color='red',length = 1e-4)\n",
    "            qskip = int(10/zoom_scale)\n",
    "            #J_quiver = ax.quiver(X_df[::qskip],Y_df[::qskip],Z_df[::qskip],Jx_df[::qskip],Jy_df[::qskip],Jz_df[::qskip],\n",
    "            #          color='black',length = 2e5, cmap=J_cmap, norm=J_norm)\n",
    "            JxB_quiver = ax.quiver(X_df[::qskip],Y_df[::qskip],Z_df[::qskip],\n",
    "                                   (Jy_df*Bz_df - Jz_df*By_df)[::qskip],(Jz_df*Bx_df - Jx_df*Bz_df)[::qskip],(Jx_df*By_df - Jy_df*Bz_df)[::qskip]*0,\n",
    "                                      color='fuchsia',length=6.5e12*zoom_scale,linewidths = 0.4*zoom_scale,zorder=5.5) # Comes out in units of rho du/dt = N/m^3\n",
    "            gradp_quiver = ax.quiver(X_df[::qskip],Y_df[::qskip],Z_df[::qskip],\n",
    "                                   -dp_dx_df[::qskip],-dp_dy_df[::qskip],-dp_dz_df[::qskip]*0,\n",
    "                                      color='deepskyblue',length=6.5e12*zoom_scale,linewidths = 0.4*zoom_scale,zorder=5.5)\n",
    "\n",
    "        #,length=3e13,linewidths = 0.8)\n",
    "\n",
    "            # Line added for back-compatibility\n",
    "            X_region = X_df \n",
    "            Y_region = Y_df\n",
    "            # Find seed points for field lines\n",
    "            if key in df_seeds.keys():   \n",
    "                # Update DF seeds through bulk electron velocity\n",
    "                df_seeds[key][:,0] = df_seeds[key][:,0] + dt*df_data[key]['uex'].iloc[-1]*1e3/R_M\n",
    "                df_seeds[key][:,1] = df_seeds[key][:,1] + dt*df_data[key]['uey'].iloc[-1]*1e3/R_M\n",
    "                # Field lines tend to advect outside of the DF, so iterate through each to check\n",
    "                for iseed in range(len(df_seeds[key])):\n",
    "                    if (df_seeds[key][iseed,0] > np.max(X_region)) or (df_seeds[key][iseed,0] < np.min(X_region)) or (df_seeds[key][iseed,1] > np.max(Y_region)) or (df_seeds[key][iseed,1] < np.min(Y_region)):\n",
    "                        new_loc = random.randint(0,len(X_region)-1)\n",
    "                        print(\"Field line seed left the DF! Moved seed at\",df_seeds[key][iseed,:],\"to\",X_region[new_loc],Y_region[new_loc],0.2)\n",
    "                        df_seeds[key][iseed,0] = X_region[new_loc]\n",
    "                        df_seeds[key][iseed,1] = Y_region[new_loc]\n",
    "                        df_seeds[key][iseed,2] = 0.2\n",
    "                    \n",
    "            # For first time this DF is generated, make all new seed points\n",
    "            else:\n",
    "                # Add stream traces\n",
    "                trace_skip=10\n",
    "                df_seeds[key] = np.zeros((len(X_region)//trace_skip+1,3))\n",
    "                df_seeds[key][:,0] = X_region[::max(len(X_region),trace_skip)]\n",
    "                df_seeds[key][:,1] = Y_region[::max(len(X_region),trace_skip)]\n",
    "                df_seeds[key][:,2] = Z_region[::max(len(X_region),trace_skip)]\n",
    "\n",
    "            # Trace the field lines\n",
    "            tracer.trace(df_seeds[key], grid)\n",
    "\n",
    "            # Plot them\n",
    "            for iseed in range(len(df_seeds[key])):\n",
    "                if do_zoom and (float(time)>zoom_time_start):\n",
    "                    above = np.where((tracer.xs[iseed][:,2]>=df_seeds[key][iseed][2]) & (tracer.xs[iseed][:,0]<zoom_xmax) & (tracer.xs[iseed][:,0]>zoom_xmin) & (tracer.xs[iseed][:,1]<zoom_ymax) & (tracer.xs[iseed][:,1]>zoom_xmin) & (tracer.xs[iseed][:,2]<zoom_zmax) & (tracer.xs[iseed][:,2]>zoom_zmin))[0]\n",
    "                    below = np.where((tracer.xs[iseed][:,2]<df_seeds[key][iseed][2]) & (tracer.xs[iseed][:,0]<zoom_xmax) & (tracer.xs[iseed][:,0]>zoom_xmin) & (tracer.xs[iseed][:,1]<zoom_ymax) & (tracer.xs[iseed][:,1]>zoom_xmin) & (tracer.xs[iseed][:,2]<zoom_zmax) & (tracer.xs[iseed][:,2]>zoom_zmin))[0]\n",
    "                else:\n",
    "                    above = np.where(tracer.xs[iseed][:,2]>=df_seeds[key][iseed][2])[0]\n",
    "                    below = np.where(tracer.xs[iseed][:,2]<df_seeds[key][iseed][2])[0]\n",
    "                # Plot the streamlines as a series of lines, without connecting between places where the indexing jumps\n",
    "                start = 0 \n",
    "                for j in range(1,len(above)):\n",
    "                    if (above[j]-above[j-1]>1) or (j==(len(above)-1)):\n",
    "                        ax.plot(tracer.xs[iseed][above[start:j-1],0],tracer.xs[iseed][above[start:j-1],1],tracer.xs[iseed][above[start:j-1],2],\n",
    "                               color=color_ls[key%9],lw=0.3,alpha=1,zorder=6) \n",
    "                        start = j\n",
    "                    \n",
    "                start = 0\n",
    "                for j in range(1,len(below)):\n",
    "                    if (below[j]-below[j-1]>1) or (j==(len(below)-1)):\n",
    "                        ax.plot(tracer.xs[iseed][below[start:j-1],0],tracer.xs[iseed][below[start:j-1],1],tracer.xs[iseed][below[start:j-1],2],\n",
    "                               color=color_ls[key%9],lw=0.3,alpha=1,zorder=0.5) \n",
    "                        start = j\n",
    "                #ax.scatter(tracer.xs[iseed][above,0],tracer.xs[iseed][above,1],tracer.xs[iseed][above,2],color=color_ls[key%9],s=0.0005,alpha=0.8,zorder=3.6)\n",
    "                #ax.scatter(tracer.xs[iseed][below,0],tracer.xs[iseed][below,1],tracer.xs[iseed][below,2],color=color_ls[key%9],s=0.0005,alpha=0.8,zorder=0.5)\n",
    "\n",
    "        # Set axes\n",
    "        if do_zoom and (float(time)>zoom_time_start):\n",
    "            ax.set_xlim(zoom_xmin,zoom_xmax)\n",
    "            ax.set_ylim(zoom_ymin,zoom_ymax)\n",
    "            ax.set_zlim(zoom_zmin,zoom_zmax)\n",
    "            x_range = zoom_xmax - zoom_xmin\n",
    "            y_range = zoom_ymax - zoom_ymin\n",
    "            z_range = zoom_zmax - zoom_zmin\n",
    "            ax.set_box_aspect([x_range, y_range, z_range])\n",
    "        else:\n",
    "            ax.set_xlim(X.min(),X.max())\n",
    "            ax.set_ylim(Y.min(),Y.max())\n",
    "            ax.set_zlim(z_lower,z_upper)\n",
    "            x_range = X.max() - X.min()\n",
    "            y_range = Y.max() - Y.min()\n",
    "            z_range = z_upper - z_lower\n",
    "            ax.set_box_aspect([x_range, y_range, z_range])  # Aspect ratio is set based on the data limits\n",
    "\n",
    "        ######################## PLOT2 END ################################\n",
    "\n",
    "    \n",
    "        # Save\n",
    "        fig.savefig(str(str(dir[:-1])+\"_plots/\"+plot_preset+\"_\"+\"%.2f\"%round(float(time),2)+'.png'),bbox_inches='tight',dpi = 300)\n",
    "        plt.close(fig)\n",
    "\n",
    "    iter+=1\n",
    "\n",
    "# Save data\n",
    "if plot_preset == 'cross_tail':\n",
    "    pickle.dump(cross_tail_data, open(str(dir+\"cross_tail_data\"), 'wb') )\n",
    "    print(\"Cross tail data saved to:\",str(dir+\"cross_tail_data\"))\n",
    "elif plot_preset == '3D_df_tracker':\n",
    "    pickle.dump(df_data, open(str(dir+\"df_data\"), 'wb') )\n",
    "    print(\"DF data data saved to:\",str(dir+\"df_data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "527b8c16-8607-40da-970f-e158dcc342f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.8201890e-16, -5.5039047e-16, -1.4452087e-15, -1.4749508e-15,\n",
       "       -1.5864119e-15, -1.1508451e-16, -1.2425335e-15, -1.7371213e-15,\n",
       "       -1.3186858e-15, -1.0470059e-15, -9.0118821e-16, -8.3771521e-16],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_dx_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c116d0-f7dd-4c9b-a290-df85dd1f3c31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
