{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ca0547c-8600-4ba2-b2d8-d90a4696de26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This document is for making 3D plots of MHD-AEPIC runs, using both PIC and MHD data. \n",
    "# The PIC data and MHD data can be read in at two different cadences. The PIC data overrides the MHD data\n",
    "\n",
    "# Essential Jupyter Notebook Magic\n",
    "%matplotlib inline\n",
    "\n",
    "# General Purpose and Data Handling Libraries\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from natsort import natsorted\n",
    "import pickle\n",
    "from operator import add\n",
    "import random\n",
    "import math\n",
    "\n",
    "# MatPlotlib for Plotting and Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.tri as tri\n",
    "import matplotlib as mpl\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib import cm, ticker\n",
    "from matplotlib.colors import LogNorm, LightSource, ListedColormap, BoundaryNorm\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib.ticker import LogFormatter, LogFormatterSciNotation\n",
    "from matplotlib.ticker import LogLocator, MultipleLocator, NullFormatter\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from streamtracer import StreamTracer, VectorGrid\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "from mpl_toolkits.mplot3d.proj3d import proj_transform\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d.art3d import Line3DCollection\n",
    "from cmap import Colormap\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.colors import SymLogNorm\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "\n",
    "# Scipy for Scientific Computing and Analysis\n",
    "from scipy import stats, interpolate\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.interpolate import interp1d, griddata\n",
    "from scipy.ndimage import label, gaussian_filter\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "from skimage import measure\n",
    "from shapely.geometry import Polygon\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "# Image Handling and Processing\n",
    "from PIL import Image\n",
    "\n",
    "# Tecplot for Scientific Data Visualization\n",
    "import tecplot as tp\n",
    "from tecplot.exception import *\n",
    "from tecplot.constant import *\n",
    "\n",
    "# For 3d plotting\n",
    "from skimage import measure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17551fd9-936c-4275-b9c4-0f1bc1e10f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Constants\n",
    "amu = 1.67e-27\n",
    "k_b = 1.38e-23\n",
    "mu_0 = 1.257e-6\n",
    "R_M = 2440e3 #m\n",
    "m_p = 1.67e-27 # kg\n",
    "e = 1.60218e-19 # C\n",
    "\n",
    "# Define utility functions\n",
    "def read_dataset(mypath,port=7600):\n",
    "    # Reads in file \"mypath\" and returns a dataset object. May take a while for larger files.\n",
    "\n",
    "    print(\"reading:\",mypath)\n",
    "    # First connect to TecPlot\n",
    "    tp.session.connect(port=port)\n",
    "\n",
    "    # Configure layout\n",
    "    tp.new_layout()\n",
    "    dataset = tp.data.load_tecplot(mypath)\n",
    "    frame = tp.active_frame()\n",
    "    frame.plot_type = PlotType.Cartesian3D\n",
    "\n",
    "    # Return dataset\n",
    "    return dataset\n",
    "\n",
    "def Bz_dip(x_array,y_array,z_array):\n",
    "    # Input: arrays of x,y,z (in planet centered coords).\n",
    "    # Output: Bz at each point\n",
    "    \n",
    "    return - 200.9 * (3*(z_array-0.2)**2 - (x_array**2+y_array**2+(z_array-0.2)**2))/((x_array**2+y_array**2+(z_array-0.2)**2)**(5/2))\n",
    "\n",
    "def get_files(dir, start_time, t_bound, dt, key=\".*cut_particle_region0_0.*\", read_time = False, reduce = True):\n",
    "    # For a directory \"dir\", return a list of all files which match the regex expression \"key\"\n",
    "    \n",
    "    all_files = [f for f in listdir(dir) if isfile(join(dir, f))]\n",
    "    files=[]\n",
    "    for file in all_files:\n",
    "        match = re.search(key,file)\n",
    "        if match != None:\n",
    "            files.append(file)\n",
    "    files.sort()\n",
    "\n",
    "    # Now give them the appropriate name for their time\n",
    "    # If we haven't already named these files with their time, do that now\n",
    "    named_files = {}\n",
    "    if read_time == False:\n",
    "        for i in range(len(files)):\n",
    "            time = round(i*dt+start_time,3)\n",
    "            named_files[time] = files[i]\n",
    "    # Otherwise, read the time right from the (last 6 elements) filename\n",
    "    else:\n",
    "        for i in range(len(files)):\n",
    "            time = str(\"%.2f\"%float(files[i][-6:]))\n",
    "            named_files[time] = files[i]\n",
    "\n",
    "    # Now cut the list down to files inside t_bound\n",
    "    if reduce:\n",
    "        reduced_files = {}\n",
    "        for file_time in list(named_files.keys()):#[int((t_bound[0]-start_time)/dt):int((t_bound[1]-start_time)/dt)]: #only loop over the times within t_bound\n",
    "            if t_bound[0]<=float(file_time)<t_bound[1]:\n",
    "                reduced_files[file_time] = str(named_files[file_time])\n",
    "        return reduced_files\n",
    "\n",
    "    else:\n",
    "        return named_files\n",
    "\n",
    "def dat_to_plt(dir,files):\n",
    "    # Hand it a directory with the dict of files in it, and it will convert them to .plt and save in dir\n",
    "    \n",
    "    for file in files:\n",
    "        dataset=read_dataset(str(dir+files[file]))\n",
    "        print(\"saving file:\",str(dir+files[file][:-3]+\"plt\"))\n",
    "        tp.data.save_tecplot_plt(str(dir+files[file][:-3]+\"plt\"))\n",
    "        os.remove(str(dir+files[file]))\n",
    "        print(f\"Deleted original .dat file: {files[file]}\")\n",
    "\n",
    "def plt_to_numpy(dataset,var_ls=[\"Bz\"],save_cs = True):\n",
    "    # Input: the path to a .plt file, and a list of variables to convert into a numpy meshgrid\n",
    "    # Output: a dictionary of arrays, each labelled according to its name in var_ls\n",
    "    # Var_ls should be *extensive*, so that this long process does not need to be rerun\n",
    "\n",
    "    # Extract the coordinate axes\n",
    "    x_axis = np.unique(dataset.variable(\"X\").values(0).as_numpy_array())\n",
    "    y_axis = np.unique(dataset.variable(\"Y\").values(0).as_numpy_array())[1:-1]\n",
    "    z_axis = np.unique(dataset.variable(\"Z\").values(0).as_numpy_array())\n",
    "\n",
    "    # Create an ordered zone\n",
    "    rect_zone = dataset.add_ordered_zone('rect_zone',[len(x_axis),len(y_axis-2),len(z_axis)])\n",
    "\n",
    "    # Create 3D coordinate meshgrids\n",
    "    xxx,yyy,zzz = np.meshgrid(x_axis,y_axis,z_axis)\n",
    "\n",
    "    # Assign coordinate values to the rect_zone using the meshgrids\n",
    "    rect_zone.values('X')[:] = xxx.ravel()\n",
    "    rect_zone.values('Y')[:] = yyy.ravel()\n",
    "    rect_zone.values('Z')[:] = zzz.ravel()\n",
    "\n",
    "    # Compute derivatives in tecplot, which does it efficiently\n",
    "    # Compute current density, in A/m^2\n",
    "    if (\"Jx\" in var_ls) or (\"Jy\" in var_ls) or (\"Jz\" in var_ls):\n",
    "        print(\"Computing J = ∇xB\")\n",
    "        tp.data.operate.execute_equation(equation='{Jx} = (ddy({Bz}) - ddz({By}))/(1.2566*10**(-6))/2440000*10**(-9)',\n",
    "            ignore_divide_by_zero=True)\n",
    "        tp.data.operate.execute_equation(equation='{Jy} = (ddz({Bx}) - ddx({Bz}))/(1.2566*10**(-6))/2440000*10**(-9)',\n",
    "            ignore_divide_by_zero=True)\n",
    "        tp.data.operate.execute_equation(equation='{Jz} = (ddx({By}) - ddy({Bx}))/(1.2566*10**(-6))/2440000*10**(-9)',\n",
    "            ignore_divide_by_zero=True)\n",
    "\n",
    "    # Compute plasma pressure gradient, in nPa / m\n",
    "    if (\"dp_dx\" in var_ls) or (\"dp_dy\" in var_ls) or (\"dp_dz\" in var_ls):\n",
    "        print(\"Computing ∇$p$\")\n",
    "        tp.data.operate.execute_equation(equation='{dp_dx} = (ddx({pxxS1}+{pxxS0}+{pyyS1}+{pyyS0}+{pzzS1}+{pzzS0}))/3/2440000',\n",
    "        ignore_divide_by_zero=True)\n",
    "        tp.data.operate.execute_equation(equation='{dp_dy} = (ddy({pxxS1}+{pxxS0}+{pyyS1}+{pyyS0}+{pzzS1}+{pzzS0}))/3/2440000',\n",
    "            ignore_divide_by_zero=True)\n",
    "        tp.data.operate.execute_equation(equation='{dp_dz} = (ddz({pxxS1}+{pxxS0}+{pyyS1}+{pyyS0}+{pzzS1}+{pzzS0}))/3/2440000',\n",
    "            ignore_divide_by_zero=True)\n",
    "        \n",
    "    # Compute magnetic field gradient , in nT / m\n",
    "    if (\"dB_dx\" in var_ls) or (\"dB_dy\" in var_ls) or (\"dB_dz\" in var_ls): \n",
    "        print(\"Computing ∇B\")\n",
    "        tp.data.operate.execute_equation(equation='{dB_dx} = (ddx(({Bx}*{Bx}+{By}*{By}+{Bz}*{Bz})**(0.5)))/2440000',\n",
    "            ignore_divide_by_zero=True)\n",
    "        tp.data.operate.execute_equation(equation='{dB_dy} = (ddy(({Bx}*{Bx}+{By}*{By}+{Bz}*{Bz})**(0.5)))/2440000',\n",
    "            ignore_divide_by_zero=True)\n",
    "        tp.data.operate.execute_equation(equation='{dB_dz} = (ddz(({Bx}*{Bx}+{By}*{By}+{Bz}*{Bz})**(0.5)))/2440000',\n",
    "            ignore_divide_by_zero=True)\n",
    "\n",
    "    # Compute advective derivative (u . del) u\n",
    "    if (\"duix_dx\" in var_ls):\n",
    "        print(\"Computing jacobian for $(u_i\\cdot∇)u_i$\")\n",
    "        tp.data.operate.execute_equation(equation='{duix_dx} = (ddx({uxS1}))/2440000', # km/s /m\n",
    "            ignore_divide_by_zero=True)\n",
    "        tp.data.operate.execute_equation(equation='{duiy_dx} = (ddx({uyS1}))/2440000', # km/s /m\n",
    "            ignore_divide_by_zero=True)\n",
    "        tp.data.operate.execute_equation(equation='{duiz_dx} = (ddx({uzS1}))/2440000', # km/s /m\n",
    "            ignore_divide_by_zero=True)\n",
    "        tp.data.operate.execute_equation(equation='{duix_dy} = (ddy({uxS1}))/2440000', # km/s /m\n",
    "            ignore_divide_by_zero=True)\n",
    "        tp.data.operate.execute_equation(equation='{duiy_dy} = (ddy({uyS1}))/2440000', # km/s /m\n",
    "            ignore_divide_by_zero=True)\n",
    "        tp.data.operate.execute_equation(equation='{duiz_dy} = (ddy({uzS1}))/2440000', # km/s /m\n",
    "            ignore_divide_by_zero=True)\n",
    "        tp.data.operate.execute_equation(equation='{duix_dz} = (ddz({uxS1}))/2440000', # km/s /m\n",
    "            ignore_divide_by_zero=True)\n",
    "        tp.data.operate.execute_equation(equation='{duiy_dz} = (ddz({uyS1}))/2440000', # km/s /m\n",
    "            ignore_divide_by_zero=True)\n",
    "        tp.data.operate.execute_equation(equation='{duiz_dz} = (ddz({uzS1}))/2440000', # km/s /m\n",
    "            ignore_divide_by_zero=True)\n",
    "\n",
    "    print(\"Beginning interpolation...\")\n",
    "    # Interpolate onto rect_zone\n",
    "    tp.data.operate.interpolate_linear(source_zones=[0],\n",
    "        destination_zone=1,\n",
    "        fill_value=0)\n",
    "\n",
    "    # Define dictionary to save results\n",
    "    data3d = {\"X\":xxx,\"Y\":yyy,\"Z\":zzz}\n",
    "\n",
    "    # All all variables to data\n",
    "    for var in var_ls:\n",
    "        data3d[var] = rect_zone.values(var).as_numpy_array().reshape(xxx.shape)\n",
    "\n",
    "    # Save in place\n",
    "    print(\"Extraction complete! Saving 3D data ...\")\n",
    "    save_file = open(str(dir+file[:-4]+\"_numpy_t_\"+'{:06.2f}'.format(round(time,2))), 'wb') \n",
    "    pickle.dump(data3d, save_file) \n",
    "    print(\"Done!\")\n",
    "\n",
    "    if save_cs:\n",
    "        #Calculate the plasma beta meshgrid\n",
    "        beta_meshgrid = (2*mu_0*(rect_zone.values(\"pxxS0\").as_numpy_array()+rect_zone.values(\"pyyS0\").as_numpy_array()+rect_zone.values(\"pzzS0\").as_numpy_array()+rect_zone.values(\"pxxS1\").as_numpy_array()+\n",
    "                                rect_zone.values(\"pyyS1\").as_numpy_array()+rect_zone.values(\"pzzS1\").as_numpy_array())*1e9/3/(rect_zone.values(\"Bx\").as_numpy_array()**2+rect_zone.values(\"By\").as_numpy_array()**2+rect_zone.values(\"Bz\").as_numpy_array()**2)).reshape(xxx.shape)\n",
    "        beta_meshgrid[np.isnan(beta_meshgrid)] = -1\n",
    "        \n",
    "         # New code: extract all of the Z coords, smooth them, and then find the values interpolated to those points!\n",
    "        data = {\"X\":xxx[:,:,0],\"Y\":yyy[:,:,0]} #, \"Z\":np.zeros_like(xxx[:,:,0])}\n",
    "        print(\"Saving cs data...\")\n",
    "        # Define empty array to save the unsmoothed Z values to\n",
    "        Z_rough = np.zeros_like(xxx[:,:,0])+0.2\n",
    "        # At each x/y, find the z coord of max beta and save that\n",
    "        for idy in range(len(yyy[:,0,0])):\n",
    "            for idx in range(len(xxx[0,:,0])):\n",
    "                # If any of the beta values in this column are -1 near the middle, that means we are at the inner edge of the bounding box\n",
    "                # In this case, set the data value to 0 to let me know where the boundary is!\n",
    "                if np.min(beta_meshgrid[idy,idx,len(z_axis)//4:-len(z_axis)//4]) == -1:\n",
    "                    Z_rough[idy,idx] = 0.2\n",
    "                else:\n",
    "                    idz = np.argmax(beta_meshgrid[idy,idx,:])\n",
    "                    Z_rough[idy,idx] = zzz[idy,idx,idz]\n",
    "    \n",
    "        # Smoothing parameter\n",
    "        smoothing_param = 5\n",
    "        # Smooth the Z meshgrid\n",
    "        data['Z'] = smooth_meshgrid(xxx[:,:,0], yyy[:,:,0], Z_rough, smoothing_param)\n",
    "    \n",
    "        # Use this as a template to extract all the other data with\n",
    "        for name in var_ls:\n",
    "            data[name] = np.zeros_like(xxx[:,:,0])\n",
    "    \n",
    "            # Extract each variable from tecplot as an array\n",
    "            var = rect_zone.values(name).as_numpy_array().reshape(xxx.shape)\n",
    "    \n",
    "            # At each x/y, find the z coord of max beta and save that\n",
    "            for idy in range(len(yyy[:,0,0])):\n",
    "                for idx in range(len(xxx[0,:,0])):\n",
    "                    # If any of the beta values in this column are -1 near the middle, that means we are at the inner edge of the bounding box\n",
    "                    # In this case, set the data value to 0 to let me know where the boundary is!\n",
    "                    if np.min(beta_meshgrid[idy,idx,len(z_axis)//4:-len(z_axis)//4]) == -1:\n",
    "                        data[name][idy,idx] = 0\n",
    "                    else:\n",
    "                        # Find the indices of the two nearest points\n",
    "                        lower_idz = np.searchsorted(zzz[idy,idx,:], data['Z'][idy,idx]) - 1\n",
    "                        upper_idz = lower_idz + 1\n",
    "    \n",
    "                        # Get the coordinates of the nearest points\n",
    "                        Z_lower = zzz[idy,idx,lower_idz]\n",
    "                        Z_upper = zzz[idy,idx,upper_idz]\n",
    "                        var_lower = var[idy,idx,lower_idz]\n",
    "                        var_upper = var[idy,idx,upper_idz]\n",
    "                        \n",
    "                        # Perform linear interpolation\n",
    "                        data[name][idy,idx] = var_lower + (var_upper - var_lower) * (data['Z'][idy,idx] - Z_lower) / (Z_upper - Z_lower)\n",
    "    \n",
    "        print(\"Done!\")\n",
    "        save_file = open(str(dir+file[:-4]+\"_csdata_t_\"+'{:06.2f}'.format(round(time,2))), 'wb') \n",
    "        pickle.dump(data, save_file) \n",
    "\n",
    "def MHD_to_numpy(dataset,x_axis,y_axis,z_axis,var_ls=[\"Bz\"],save_cs = True, smoothing_param = 5/8):\n",
    "    # Input: the path to a .plt file, and a list of variables to convert into a numpy meshgrid\n",
    "    # Output: a dictionary of arrays, each labelled according to its name in var_ls\n",
    "    # Var_ls should be *extensive*, so that this long process does not need to be rerun\n",
    "\n",
    "    # Create an ordered zone`\n",
    "    rect_zone = dataset.add_ordered_zone('rect_zone',[len(x_axis),len(y_axis),len(z_axis)])\n",
    "\n",
    "    # Create 3D coordinate meshgrids\n",
    "    xxx,yyy,zzz = np.meshgrid(x_axis,y_axis,z_axis)\n",
    "\n",
    "    # Assign coordinate values to the rect_zone using the meshgrids\n",
    "    rect_zone.values('X [[]R[]]')[:] = xxx.ravel()\n",
    "    rect_zone.values('Y [[]R[]]')[:] = yyy.ravel()\n",
    "    rect_zone.values('Z [[]R[]]')[:] = zzz.ravel()\n",
    "\n",
    "    # Compute derivatives in tecplot, which does it efficiently\n",
    "    # Compute plasma pressure gradient, in nPa / m\n",
    "    if (\"dp_dx\" in var_ls) or (\"dp_dy\" in var_ls) or (\"dp_dz\" in var_ls):\n",
    "        print(\"Computing ∇$p$\")\n",
    "        tp.data.operate.execute_equation(equation='{dp_dx} = {P [[]nPa[]]}/2440000',\n",
    "            ignore_divide_by_zero=True)\n",
    "        tp.data.operate.execute_equation(equation='{dp_dy} = (ddy({P [[]nPa[]]}))/2440000',\n",
    "            ignore_divide_by_zero=True)\n",
    "        tp.data.operate.execute_equation(equation='{dp_dz} = (ddz({P [[]nPa[]]}))/2440000',\n",
    "            ignore_divide_by_zero=True)\n",
    "        \n",
    "    # Compute magnetic field gradient , in nT / m\n",
    "    if (\"dB_dx\" in var_ls) or (\"dB_dy\" in var_ls) or (\"dB_dz\" in var_ls): \n",
    "        print(\"Computing ∇B\")\n",
    "        tp.data.operate.execute_equation(equation='{dB_dx} = (ddx(({B_x [[]nT[]]}*{B_x [[]nT[]]}+{B_y [[]nT[]]}*{B_y [[]nT[]]}+{B_z [[]nT[]]}*{B_z [[]nT[]]})**(0.5)))/2440000',\n",
    "            ignore_divide_by_zero=True)\n",
    "        tp.data.operate.execute_equation(equation='{dB_dy} = (ddy(({B_x [[]nT[]]}*{B_x [[]nT[]]}+{B_y [[]nT[]]}*{B_y [[]nT[]]}+{B_z [[]nT[]]}*{B_z [[]nT[]]})**(0.5)))/2440000',\n",
    "            ignore_divide_by_zero=True)\n",
    "        tp.data.operate.execute_equation(equation='{dB_dz} = (ddz(({B_x [[]nT[]]}*{B_x [[]nT[]]}+{B_y [[]nT[]]}*{B_y [[]nT[]]}+{B_z [[]nT[]]}*{B_z [[]nT[]]})**(0.5)))/2440000',\n",
    "            ignore_divide_by_zero=True)\n",
    "\n",
    "    # Compute advective derivative (u . del) u\n",
    "    if (\"dux_dx\" in var_ls):\n",
    "        print(\"Computing jacobian for $(u_i\\cdot∇)u_i$\")\n",
    "        tp.data.operate.execute_equation(equation='{dux_dx} = (ddx({U_x [km/s]}))/2440000', # km/s /m\n",
    "            ignore_divide_by_zero=True)\n",
    "        tp.data.operate.execute_equation(equation='{duy_dx} = (ddx({U_y [km/s]}))/2440000', # km/s /m\n",
    "            ignore_divide_by_zero=True)\n",
    "        tp.data.operate.execute_equation(equation='{duz_dx} = (ddx({U_z [km/s]}))/2440000', # km/s /m\n",
    "            ignore_divide_by_zero=True)\n",
    "        tp.data.operate.execute_equation(equation='{dux_dy} = (ddy({U_x [km/s]}))/2440000', # km/s /m\n",
    "            ignore_divide_by_zero=True)\n",
    "        tp.data.operate.execute_equation(equation='{duy_dy} = (ddy({U_y [km/s]}))/2440000', # km/s /m\n",
    "            ignore_divide_by_zero=True)\n",
    "        tp.data.operate.execute_equation(equation='{duz_dy} = (ddy({U_z [km/s]}))/2440000', # km/s /m\n",
    "            ignore_divide_by_zero=True)\n",
    "        tp.data.operate.execute_equation(equation='{dux_dz} = (ddz({U_x [km/s]}))/2440000', # km/s /m\n",
    "            ignore_divide_by_zero=True)\n",
    "        tp.data.operate.execute_equation(equation='{duy_dz} = (ddz({U_y [km/s]}))/2440000', # km/s /m\n",
    "            ignore_divide_by_zero=True)\n",
    "        tp.data.operate.execute_equation(equation='{duz_dz} = (ddz({U_z [km/s]}))/2440000', # km/s /m\n",
    "            ignore_divide_by_zero=True)\n",
    "\n",
    "    print(\"Beginning interpolation...\")\n",
    "    # Interpolate onto rect_zone\n",
    "    tp.data.operate.interpolate_linear(source_zones=[0],\n",
    "        destination_zone=1,\n",
    "        fill_value=0)\n",
    "\n",
    "    # Define dictionary to save results\n",
    "    data3d = {\"X\":xxx,\"Y\":yyy,\"Z\":zzz}\n",
    "\n",
    "    # All all variables to data\n",
    "    for var in var_ls:\n",
    "        data3d[var] = rect_zone.values(var).as_numpy_array().reshape(xxx.shape)\n",
    "\n",
    "    # Save in place\n",
    "    print(\"Extraction complete! Saving 3D data ...\")\n",
    "    save_file = open(str(dir+file[:-4]+\"_numpy_t_\"+'{:06.2f}'.format(round(time,2))), 'wb') \n",
    "    pickle.dump(data3d, save_file) \n",
    "    print(\"Done!\")\n",
    "\n",
    "    if save_cs:\n",
    "        #Calculate the plasma beta meshgrid\n",
    "        beta_meshgrid = (2*mu_0*rect_zone.values(\"P [[]nPa[]]\").as_numpy_array()*1e9/(rect_zone.values(\"B_x [[]nT[]]\").as_numpy_array()**2+rect_zone.values(\"B_y [[]nT[]]\").as_numpy_array()**2+rect_zone.values(\"B_z [[]nT[]]\").as_numpy_array()**2)).reshape(xxx.shape)\n",
    "        beta_meshgrid[np.isnan(beta_meshgrid)] = -1\n",
    "        \n",
    "         # New code: extract all of the Z coords, smooth them, and then find the values interpolated to those points!\n",
    "        data = {\"X\":xxx[:,:,0],\"Y\":yyy[:,:,0]} #, \"Z\":np.zeros_like(xxx[:,:,0])}\n",
    "        print(\"Saving cs data...\")\n",
    "        # Define empty array to save the unsmoothed Z values to\n",
    "        Z_rough = np.zeros_like(xxx[:,:,0])+0.2\n",
    "        # At each x/y, find the z coord of max beta and save that\n",
    "        for idy in range(len(yyy[:,0,0])):\n",
    "            for idx in range(len(xxx[0,:,0])):\n",
    "                # If any of the beta values in this column are -1 near the middle, that means we are at the inner edge of the bounding box\n",
    "                # In this case, set the data value to 0 to let me know where the boundary is!\n",
    "                if np.min(beta_meshgrid[idy,idx,len(z_axis)//4:-len(z_axis)//4]) == -1:\n",
    "                    Z_rough[idy,idx] = 0.2\n",
    "                else:\n",
    "                    idz = np.argmax(beta_meshgrid[idy,idx,:])\n",
    "                    # Sse 0.2 if it tries to go too far away from the magnetic equator\n",
    "                    if (np.abs(zzz[idy,idx,idz] - 0.2)>0.2):\n",
    "                        Z_rough[idy,idx] = 0.2\n",
    "                    else:\n",
    "                        Z_rough[idy,idx] = zzz[idy,idx,idz]\n",
    "    \n",
    "        # Smooth the Z meshgrid\n",
    "        data['Z'] = smooth_meshgrid(xxx[:,:,0], yyy[:,:,0], Z_rough, smoothing_param)\n",
    "    \n",
    "        # Use this as a template to extract all the other data with\n",
    "        for name in var_ls:\n",
    "            data[name] = np.zeros_like(xxx[:,:,0])\n",
    "    \n",
    "            # Extract each variable from tecplot as an array\n",
    "            var = rect_zone.values(name).as_numpy_array().reshape(xxx.shape)\n",
    "    \n",
    "            # At each x/y, find the z coord of max beta and save that\n",
    "            for idy in range(len(yyy[:,0,0])):\n",
    "                for idx in range(len(xxx[0,:,0])):\n",
    "                    # If any of the beta values in this column are -1 near the middle, that means we are at the inner edge of the bounding box\n",
    "                    # In this case, set the data value to 0 to let me know where the boundary is!\n",
    "                    if np.min(beta_meshgrid[idy,idx,len(z_axis)//4:-len(z_axis)//4]) == -1:\n",
    "                        data[name][idy,idx] = 0\n",
    "                    else:\n",
    "                        # Find the indices of the two nearest points\n",
    "                        lower_idz = np.searchsorted(zzz[idy,idx,:], data['Z'][idy,idx]) - 1\n",
    "                        upper_idz = lower_idz + 1\n",
    "    \n",
    "                        # Get the coordinates of the nearest points\n",
    "                        Z_lower = zzz[idy,idx,lower_idz]\n",
    "                        Z_upper = zzz[idy,idx,upper_idz]\n",
    "                        var_lower = var[idy,idx,lower_idz]\n",
    "                        var_upper = var[idy,idx,upper_idz]\n",
    "                        \n",
    "                        # Perform linear interpolation\n",
    "                        data[name][idy,idx] = var_lower + (var_upper - var_lower) * (data['Z'][idy,idx] - Z_lower) / (Z_upper - Z_lower)\n",
    "    \n",
    "        print(\"Done!\")\n",
    "        save_file = open(str(dir+file[:-4]+\"_csdata_t_\"+'{:06.2f}'.format(round(time,2))), 'wb') \n",
    "        pickle.dump(data, save_file) \n",
    "\n",
    "\n",
    "def smooth_meshgrid(X, Y, Z, smoothing_param):\n",
    "    \"\"\"\n",
    "    Smooth the Z values of a meshgrid defined by X, Y coordinates using a Gaussian filter.\n",
    "    \n",
    "    Parameters:\n",
    "    X (2D numpy array): The X coordinates of the meshgrid.\n",
    "    Y (2D numpy array): The Y coordinates of the meshgrid.\n",
    "    Z (2D numpy array): The Z coordinates of the meshgrid.\n",
    "    smoothing_param (float): The standard deviation for the Gaussian kernel, controlling the smoothing.\n",
    "    \n",
    "    Returns:\n",
    "    Z_smoothed (2D numpy array): The smoothed Z values of the meshgrid.\n",
    "    \"\"\"\n",
    "    # Check if X, Y, Z are of the same shape\n",
    "    if X.shape != Y.shape or X.shape != Z.shape:\n",
    "        raise ValueError(\"X, Y, and Z meshgrids must have the same shape\")\n",
    "    \n",
    "    # Apply Gaussian filter to the Z meshgrid\n",
    "    Z_smoothed = gaussian_filter(Z, sigma=smoothing_param)\n",
    "    \n",
    "    return Z_smoothed\n",
    "\n",
    "def plot_sphere(ax, u = np.linspace(0, 2 * np.pi, 200), v = np.linspace(0, np.pi, 100), radius=1, center=(0, 0, 0), color='b', alpha=0.5, zorder = 1, xlims = [-10,10], ylims = [-10,10], zlims = [-10,10]):\n",
    "    \"\"\"\n",
    "    Plots a sphere of given radius centered at center on the provided 3D axis.\n",
    "    \n",
    "    Parameters:\n",
    "    - ax: The 3D axis to plot the sphere on.\n",
    "    - radius: The radius of the sphere (default: 1).\n",
    "    - center: The (x, y, z) coordinates of the sphere's center (default: (0, 0, 0)).\n",
    "    - color: The color of the sphere (default: blue).\n",
    "    - alpha: The transparency of the sphere (default: 0.5).\n",
    "    \"\"\"\n",
    "    x = radius * np.outer(np.cos(u), np.sin(v)) + center[0]\n",
    "    y = radius * np.outer(np.sin(u), np.sin(v)) + center[1]\n",
    "    z = radius * np.outer(np.ones(np.size(u)), np.cos(v)) + center[2]\n",
    "\n",
    "    # Mask out any values outside the axes lims\n",
    "    mask = (x < xlims[0]) | (x > xlims[1]) | (y < ylims[0]) | (y > ylims[1]) | (z < zlims[0]) | (z > zlims[1]) \n",
    "    x[mask] = np.nan\n",
    "    y[mask] = np.nan\n",
    "    z[mask] = np.nan\n",
    "\n",
    "    ax.plot_surface(x, y, z, color=color, alpha=alpha, zorder=zorder)\n",
    "\n",
    "def average_value(var_ls,t0,t_start,t_stop,type='csdata'):\n",
    "    # Input: Variables to average, the current time (t0), and the times relative to present to average over (t0+t_start to t0+t_stop)\n",
    "    # Ouput: dictionary of arrays of time-averaged values\n",
    "\n",
    "    averages = {}\n",
    "    count = 0\n",
    "\n",
    "    temp_files = get_files(dir,key=\"3d\\_fluid.*\"+type+\"\\_t\\_...\\...\",read_time = True, reduce = False)\n",
    "\n",
    "    for t in list(temp_files.keys()): \n",
    "        # Check to see if this file is in the time range we want\n",
    "        if (float(t) >= (t0+t_start)) and (float(t) <= t0+t_stop):\n",
    "            temp_file = str(temp_files[t])\n",
    "    \n",
    "            # Read in this data\n",
    "            with open(dir+temp_file, 'rb') as f:\n",
    "                temp_data = pickle.load(f) \n",
    "            \n",
    "            # Add the data to our running average for each variable\n",
    "            for var in var_ls:\n",
    "                if var not in averages.keys():\n",
    "                    averages[var] = temp_data[var]\n",
    "                else:\n",
    "                    averages[var] += temp_data[var]\n",
    "\n",
    "            count += 1\n",
    "        \n",
    "    # Divide by total time steps\n",
    "    for var in var_ls:\n",
    "        averages[var] = averages[var]/count\n",
    "\n",
    "    return averages\n",
    "\n",
    "def find_indices(X, Y, XX, YY):\n",
    "    # Function used to get ix and iy for some coordinates X and Y\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    XX = np.array(XX)\n",
    "    YY = np.array(YY)\n",
    "\n",
    "    ix = []\n",
    "    iy = []\n",
    "    \n",
    "    for (x, y) in zip(X, Y):\n",
    "        # Find the closest index in the meshgrid for the x coordinate\n",
    "        ix_index = np.abs(XX[0] - x).argmin()\n",
    "        # Find the closest index in the meshgrid for the y coordinate\n",
    "        iy_index = np.abs(YY[:, 0] - y).argmin()\n",
    "        \n",
    "        ix.append(ix_index)\n",
    "        iy.append(iy_index)\n",
    "        \n",
    "    return iy, ix\n",
    "\n",
    "def remove_duplicate_rows(arr):\n",
    "    # Used in df_tracker... does something to remove repeated rows in the matching matrix\n",
    "    seen = set()\n",
    "    filtered_rows = []\n",
    "    for row in arr:\n",
    "        if row[0] not in seen:\n",
    "            filtered_rows.append(row)\n",
    "            seen.add(row[0])\n",
    "    return np.array(filtered_rows)\n",
    "\n",
    "def find_boundary_points(X, Y):\n",
    "    # Combine the coordinate lists into a single array of points\n",
    "    points = np.column_stack((X, Y))\n",
    "\n",
    "    # Compute the convex hull of the points\n",
    "    hull = ConvexHull(points)\n",
    "\n",
    "    # Extract the boundary points\n",
    "    boundary_points = hull.vertices\n",
    "\n",
    "    # Boundary points in original coordinate lists\n",
    "    boundary_X = points[boundary_points, 0]\n",
    "    boundary_Y = points[boundary_points, 1]\n",
    "\n",
    "    return boundary_X.tolist(), boundary_Y.tolist()\n",
    "\n",
    "def create_above_surface_mask(X, Y, Z, XX, YY, ZZ):\n",
    "    # Works out all the 3D points above a 2D surface ie all the points above the current sheet.\n",
    "    # Used for 3D plotting to determine what is above what.\n",
    "    # Check that XX, YY, ZZ have the same shape\n",
    "    assert XX.shape == YY.shape == ZZ.shape, \"Arrays XX, YY, and ZZ must have the same shape\"\n",
    "    \n",
    "    # Check that X, Y, Z have the same shape\n",
    "    assert X.shape == Y.shape == Z.shape, \"Arrays X, Y, and Z must have the same shape\"\n",
    "\n",
    "    # Determine the shape of the input arrays\n",
    "    nx, ny, nz = XX.shape\n",
    "\n",
    "    # Initialize a mask with the same shape as ZZ\n",
    "    mask = np.zeros_like(ZZ, dtype=bool)\n",
    "\n",
    "    # Iterate over the entire 3D meshgrid\n",
    "    for i in range(nx):\n",
    "        for j in range(ny):\n",
    "            # Find the index in the 2D arrays corresponding to the x and y coordinates\n",
    "            xi = np.argmin(np.abs(X[0] - XX[i, j, 0]))\n",
    "            yi = np.argmin(np.abs(Y[:, 0] - YY[i, j, 0]))\n",
    "\n",
    "            # Compare ZZ with Z to determine the mask\n",
    "            mask[i, j, :] = ZZ[i, j, :] > Z[yi, xi]\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def compute_dt(var_ls,time,type='csdata'):\n",
    "    # Input: variables to compute the time derivative for, and the current time\n",
    "    # Output: dictionary of time derivatives for each variable, calculated as dvar_dt = var(time+dt)-var(time-dt)/(2*dt)\n",
    "    # If earlier or later times are not available, we do either var(time+dt)-var(time)/dt or var(time)-var(time-dt)/dt\n",
    "\n",
    "    # Declare output dictionary\n",
    "    deriv_dict = {}\n",
    "    #print(\"Computing time derivatives at time\",time)\n",
    "    key_minus = '{:.2f}'.format((float(time)-dt), 'wb')\n",
    "    key_plus = '{:.2f}'.format((float(time)+dt), 'wb')\n",
    "    #print(files.keys())\n",
    "    #print(key_minus)\n",
    "    #print(key_plus)\n",
    "\n",
    "    if type=='csdata':\n",
    "        temp_files = filescs\n",
    "        data = datacs\n",
    "    elif type=='numpy':\n",
    "        temp_files = files3D\n",
    "        data = data3d\n",
    "\n",
    "    # Read in the data depending on whether its available\n",
    "    if (key_minus in temp_files.keys()) and (key_plus in temp_files.keys()):\n",
    "        # Case one: earlier and later timestep available, so use both\n",
    "        #print(\"Earlier and later timesteps available!\")\n",
    "        with open(dir+temp_files[key_minus], 'rb') as f:\n",
    "            data_tminus = pickle.load(f) \n",
    "        with open(dir+temp_files[key_plus], 'rb') as f:\n",
    "            data_tplus = pickle.load(f) \n",
    "        for var in var_ls:\n",
    "            deriv_dict[var] = (data_tplus[var]-data_tminus[var])/(2*dt)\n",
    "    \n",
    "    elif (key_minus in temp_files.keys()):\n",
    "        # Case two: only earlier time available\n",
    "        #print(\"Only earlier timestep available!\")\n",
    "        with open(dir+temp_files[key_minus], 'rb') as f:\n",
    "            data_tminus = pickle.load(f) \n",
    "        for var in var_ls:\n",
    "            deriv_dict[var] = (data[var]-data_tminus[var])/(dt)\n",
    "\n",
    "    elif (key_plus in temp_files.keys()):\n",
    "        # Case three: only later time available\n",
    "        #print(\"Only later timestep available!\")\n",
    "        print(dir+temp_files[key_plus])\n",
    "        with open(dir+temp_files[key_plus], 'rb') as f:\n",
    "            data_tplus = pickle.load(f) \n",
    "        for var in var_ls:\n",
    "            deriv_dict[var] = (data_tplus[var]-data[var])/(dt)\n",
    "\n",
    "    else:\n",
    "        print(\"ERROR: NO OTHER TIMESTEPS FOUND FOR DERIVATIVE AT TIME =\",time)\n",
    "            \n",
    "    return deriv_dict\n",
    "\n",
    "def plane_intersection(x, y, z, plane_z=0.2):\n",
    "    # Used in 3D_df_tracker2 to check whether a given field line intersects the current sheet multiple times or not\n",
    "    intersections = 0  # Counter for intersections with the plane\n",
    "\n",
    "    # Iterate over the list of points\n",
    "    for i in range(1, len(z)):\n",
    "        if (z[i-1] - plane_z) * (z[i] - plane_z) < 0:\n",
    "            # There is an intersection between z[i-1] and z[i] since their signs are different\n",
    "            intersections += 1\n",
    "        elif z[i-1] == plane_z and z[i] != plane_z:\n",
    "            # Edge case: the point is exactly on the plane\n",
    "            intersections += 1\n",
    "\n",
    "    return intersections\n",
    "\n",
    "def symlog(x):\n",
    "    \"\"\" Returns the symmetric log10 value \"\"\"\n",
    "    return np.sign(x) * np.log10(np.abs(x))\n",
    "\n",
    "def symroot(x):\n",
    "    \"\"\" Returns the symmetric sqrt value \"\"\"\n",
    "    return np.sign(x) * np.sqrt(np.abs(x))\n",
    "\n",
    "# Functions for adding arrows; use \"setattr(Axes3D, 'arrow3D', _arrow3D)\" after defining your axes\n",
    "class Arrow3D(FancyArrowPatch):\n",
    "            def __init__(self, x, y, z, dx, dy, dz, *args, **kwargs):\n",
    "                super().__init__((0, 0), (0, 0), *args, **kwargs)\n",
    "                self._xyz = (x, y, z)\n",
    "                self._dxdydz = (dx, dy, dz)\n",
    "        \n",
    "            def draw(self, renderer):\n",
    "                x1, y1, z1 = self._xyz\n",
    "                dx, dy, dz = self._dxdydz\n",
    "                x2, y2, z2 = (x1 + dx, y1 + dy, z1 + dz)\n",
    "        \n",
    "                xs, ys, zs = proj_transform((x1, x2), (y1, y2), (z1, z2), self.axes.M)\n",
    "                self.set_positions((xs[0], ys[0]), (xs[1], ys[1]))\n",
    "                super().draw(renderer)\n",
    "                \n",
    "            def do_3d_projection(self, renderer=None):\n",
    "                x1, y1, z1 = self._xyz\n",
    "                dx, dy, dz = self._dxdydz\n",
    "                x2, y2, z2 = (x1 + dx, y1 + dy, z1 + dz)\n",
    "        \n",
    "                xs, ys, zs = proj_transform((x1, x2), (y1, y2), (z1, z2), self.axes.M)\n",
    "                self.set_positions((xs[0], ys[0]), (xs[1], ys[1]))\n",
    "                \n",
    "                return np.min(zs) \n",
    "def _arrow3D(ax, x, y, z, dx, dy, dz, *args, **kwargs):\n",
    "    '''Add an 3d arrow to an `Axes3D` instance.'''\n",
    "\n",
    "    arrow = Arrow3D(x, y, z, dx, dy, dz, *args, **kwargs)\n",
    "    ax.add_artist(arrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "98be63a8-0059-48d3-9f5f-5c7756f2492a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing MHD data for t = 40\n",
      "reading: /Volumes/My Book Duo/runs/nightside_v5_run1/ta-2/3d__var_3_t00000040_n00263576.plt\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7605\n",
      "Connection established.\n",
      "Beginning interpolation...\n",
      "Extraction complete! Saving 3D data ...\n",
      "Done!\n",
      "Saving cs data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l9/dnt9qhfd1psfsmj9t5zfr0j00000gq/T/ipykernel_90441/1566400592.py:309: RuntimeWarning: invalid value encountered in divide\n",
      "  beta_meshgrid = (2*mu_0*rect_zone.values(\"P [[]nPa[]]\").as_numpy_array()*1e9/(rect_zone.values(\"B_x [[]nT[]]\").as_numpy_array()**2+rect_zone.values(\"B_y [[]nT[]]\").as_numpy_array()**2+rect_zone.values(\"B_z [[]nT[]]\").as_numpy_array()**2)).reshape(xxx.shape)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Preprocessing MHD data for t = 41\n",
      "reading: /Volumes/My Book Duo/runs/nightside_v5_run1/ta-2/3d__var_3_t00000041_n00267876.plt\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7605\n",
      "Connection established.\n",
      "Beginning interpolation...\n",
      "Extraction complete! Saving 3D data ...\n",
      "Done!\n",
      "Saving cs data...\n",
      "Done!\n",
      "Preprocessing MHD data for t = 42\n",
      "reading: /Volumes/My Book Duo/runs/nightside_v5_run1/ta-2/3d__var_3_t00000042_n00272136.plt\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7605\n",
      "Connection established.\n",
      "Beginning interpolation...\n",
      "Extraction complete! Saving 3D data ...\n",
      "Done!\n",
      "Saving cs data...\n",
      "Done!\n",
      "Preprocessing MHD data for t = 43\n",
      "reading: /Volumes/My Book Duo/runs/nightside_v5_run1/ta-2/3d__var_3_t00000043_n00276366.plt\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7605\n",
      "Connection established.\n",
      "Beginning interpolation...\n",
      "Extraction complete! Saving 3D data ...\n",
      "Done!\n",
      "Saving cs data...\n",
      "Done!\n",
      "Preprocessing MHD data for t = 44\n",
      "reading: /Volumes/My Book Duo/runs/nightside_v5_run1/ta-2/3d__var_3_t00000044_n00280540.plt\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7605\n",
      "Connection established.\n",
      "Beginning interpolation...\n",
      "Extraction complete! Saving 3D data ...\n",
      "Done!\n",
      "Saving cs data...\n",
      "Done!\n",
      "Preprocessing MHD data for t = 45\n",
      "reading: /Volumes/My Book Duo/runs/nightside_v5_run1/ta-2/3d__var_3_t00000045_n00284740.plt\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7605\n",
      "Connection established.\n",
      "Beginning interpolation...\n",
      "Extraction complete! Saving 3D data ...\n",
      "Done!\n",
      "Saving cs data...\n",
      "Done!\n",
      "Preprocessing MHD data for t = 46\n",
      "reading: /Volumes/My Book Duo/runs/nightside_v5_run1/ta-2/3d__var_3_t00000046_n00288940.plt\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7605\n",
      "Connection established.\n",
      "Beginning interpolation...\n",
      "Extraction complete! Saving 3D data ...\n",
      "Done!\n",
      "Saving cs data...\n",
      "Done!\n",
      "Preprocessing MHD data for t = 47\n",
      "reading: /Volumes/My Book Duo/runs/nightside_v5_run1/ta-2/3d__var_3_t00000047_n00293140.plt\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7605\n",
      "Connection established.\n",
      "Beginning interpolation...\n",
      "Extraction complete! Saving 3D data ...\n",
      "Done!\n",
      "Saving cs data...\n",
      "Done!\n",
      "Preprocessing MHD data for t = 48\n",
      "reading: /Volumes/My Book Duo/runs/nightside_v5_run1/ta-2/3d__var_3_t00000048_n00297340.plt\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7605\n",
      "Connection established.\n",
      "Beginning interpolation...\n",
      "Extraction complete! Saving 3D data ...\n",
      "Done!\n",
      "Saving cs data...\n",
      "Done!\n",
      "Preprocessing MHD data for t = 49\n",
      "reading: /Volumes/My Book Duo/runs/nightside_v5_run1/ta-2/3d__var_3_t00000049_n00301540.plt\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7605\n",
      "Connection established.\n",
      "Beginning interpolation...\n",
      "Extraction complete! Saving 3D data ...\n",
      "Done!\n",
      "Saving cs data...\n",
      "Done!\n",
      "Preprocessing MHD data for t = 50\n",
      "reading: /Volumes/My Book Duo/runs/nightside_v5_run1/ta-2/3d__var_3_t00000050_n00305740.plt\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7605\n",
      "Connection established.\n",
      "Beginning interpolation...\n",
      "Extraction complete! Saving 3D data ...\n",
      "Done!\n",
      "Saving cs data...\n",
      "Done!\n",
      "Preprocessing MHD data for t = 51\n",
      "reading: /Volumes/My Book Duo/runs/nightside_v5_run1/ta-2/3d__var_3_t00000051_n00309940.plt\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7605\n",
      "Connection established.\n",
      "Beginning interpolation...\n",
      "Extraction complete! Saving 3D data ...\n",
      "Done!\n",
      "Saving cs data...\n",
      "Done!\n",
      "Preprocessing MHD data for t = 52\n",
      "reading: /Volumes/My Book Duo/runs/nightside_v5_run1/ta-2/3d__var_3_t00000052_n00314140.plt\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7605\n",
      "Connection established.\n",
      "Beginning interpolation...\n",
      "Extraction complete! Saving 3D data ...\n",
      "Done!\n",
      "Saving cs data...\n",
      "Done!\n",
      "Preprocessing MHD data for t = 53\n",
      "reading: /Volumes/My Book Duo/runs/nightside_v5_run1/ta-2/3d__var_3_t00000053_n00318315.plt\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7605\n",
      "Connection established.\n",
      "Beginning interpolation...\n",
      "Extraction complete! Saving 3D data ...\n",
      "Done!\n",
      "Saving cs data...\n",
      "Done!\n",
      "Preprocessing MHD data for t = 54\n",
      "reading: /Volumes/My Book Duo/runs/nightside_v5_run1/ta-2/3d__var_3_t00000054_n00322415.plt\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7605\n",
      "Connection established.\n",
      "Beginning interpolation...\n",
      "Extraction complete! Saving 3D data ...\n",
      "Done!\n",
      "Saving cs data...\n",
      "Done!\n",
      "Preprocessing MHD data for t = 55\n",
      "reading: /Volumes/My Book Duo/runs/nightside_v5_run1/ta-2/3d__var_3_t00000055_n00326515.plt\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7605\n",
      "Connection established.\n",
      "Beginning interpolation...\n",
      "Extraction complete! Saving 3D data ...\n",
      "Done!\n",
      "Saving cs data...\n",
      "Done!\n",
      "Preprocessing MHD data for t = 56\n",
      "reading: /Volumes/My Book Duo/runs/nightside_v5_run1/ta-2/3d__var_3_t00000056_n00330615.plt\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7605\n",
      "Connection established.\n",
      "Beginning interpolation...\n",
      "Extraction complete! Saving 3D data ...\n",
      "Done!\n",
      "Saving cs data...\n",
      "Done!\n",
      "Preprocessing MHD data for t = 57\n",
      "reading: /Volumes/My Book Duo/runs/nightside_v5_run1/ta-2/3d__var_3_t00000057_n00334715.plt\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7605\n",
      "Connection established.\n",
      "Beginning interpolation...\n",
      "Extraction complete! Saving 3D data ...\n",
      "Done!\n",
      "Saving cs data...\n",
      "Done!\n",
      "Preprocessing MHD data for t = 58\n",
      "reading: /Volumes/My Book Duo/runs/nightside_v5_run1/ta-2/3d__var_3_t00000058_n00338768.plt\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7605\n",
      "Connection established.\n",
      "Beginning interpolation...\n",
      "Extraction complete! Saving 3D data ...\n",
      "Done!\n",
      "Saving cs data...\n",
      "Done!\n",
      "Preprocessing MHD data for t = 59\n",
      "reading: /Volumes/My Book Duo/runs/nightside_v5_run1/ta-2/3d__var_3_t00000059_n00342868.plt\n",
      "Connecting to Tecplot 360 TecUtil Server on:\n",
      "    tcp://localhost:7605\n",
      "Connection established.\n",
      "Beginning interpolation...\n",
      "Extraction complete! Saving 3D data ...\n",
      "Done!\n",
      "Saving cs data...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "############################## PREPROCESSING ##############################\n",
    "#dir = \"/Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-2e/\"\n",
    "dir = \"/Volumes/My Book Duo/runs/nightside_v5_run1/ta-2/\"\n",
    "pre_proc_MHD = True\n",
    "MHD_start_time = 40  # First time step of MHD data saved in this directory\n",
    "t_bound = [40,60]    # Start and stop times of this data to be plot (cannot go beyond available PIC data time range)\n",
    "MHD_dt = 1 # File time cadence of MHD data [s]\n",
    "preproc_xlims = [-10,4]\n",
    "preproc_ylims = [-5,5]\n",
    "preproc_zlims = [-5,5]\n",
    "MHD_var_ls = [\"Rho [[]amu/cm^3[]]\",\"U_x [[]km/s[]]\",\"U_y [[]km/s[]]\",\"U_z [[]km/s[]]\",\"B_x [[]nT[]]\",\"B_y [[]nT[]]\",\"B_z [[]nT[]]\",\n",
    "             \"P [[]nPa[]]\",\"J_x [[]`mA/m^2[]]\",\"J_y [[]`mA/m^2[]]\",\"J_z [[]`mA/m^2[]]\"]#,\"dp_dx\",\"dp_dy\",\"dp_dz\",\n",
    "              #\"dB_dx\",\"dB_dy\",\"dB_dz\",\"dux_dx\",\"duy_dx\",\"duz_dx\",\"dux_dy\",\"duy_dy\",\"duz_dy\",\"dux_dz\",\"duy_dz\",\"duz_dz\"]\n",
    "\n",
    "PIC_var_ls = [\"Bx\",\"By\",\"Bz\",\"Ex\",\"Ey\",\"Ez\",\"rhoS0\",\"uxS0\",\"uyS0\",\"uzS0\",\"pxxS0\",\"pyyS0\",\"pzzS0\",\"pxyS0\",\"pxzS0\",\"pyzS0\",\n",
    "          \"rhoS1\",\"uxS1\",\"uyS1\",\"uzS1\",\"pxxS1\",\"pyyS1\",\"pzzS1\",\"pxyS1\",\"pxzS1\",\"pyzS1\",\"Jx\",\"Jy\",\"Jz\",\"dp_dx\",\"dp_dy\",\"dp_dz\",\n",
    "          \"dB_dx\",\"dB_dy\",\"dB_dz\",\"duix_dx\",\"duiy_dx\",\"duiz_dx\",\"duix_dy\",\"duiy_dy\",\"duiz_dy\",\"duix_dz\",\"duiy_dz\",\"duiz_dz\"]\n",
    "\n",
    "# Cell data from PIC (found by directly examining the actual output grid)\n",
    "PIC_xmin = -3.99219\n",
    "PIC_ymin = -1.22656\n",
    "PIC_zmin = -0.742188\n",
    "PIC_dx = 0.01562501\n",
    "dx_factor = 4 # The MHD grid will be limited to steps of this size factor \n",
    "PIC_dx1 = PIC_dx * dx_factor\n",
    "\n",
    "############################## PREPROCESSING ##############################\n",
    "\n",
    "if pre_proc_MHD:\n",
    "    xmin_idx = int(round((PIC_xmin - preproc_xlims[0])/PIC_dx1,0)) # How many PIC_dx between PIC_xmin and preproc_xlims[0]\n",
    "    ymin_idx = int(round((PIC_ymin - preproc_ylims[0])/PIC_dx1,0))\n",
    "    zmin_idx = int(round((PIC_zmin - preproc_zlims[0])/PIC_dx1,0))\n",
    "    xmax_idx = int(round((preproc_xlims[1] - PIC_xmin)/PIC_dx1,0))\n",
    "    ymax_idx = int(round((preproc_ylims[1] - PIC_ymin)/PIC_dx1,0))\n",
    "    zmax_idx = int(round((preproc_zlims[1] - PIC_zmin)/PIC_dx1,0))\n",
    "\n",
    "    MHD_xlims = [PIC_xmin - xmin_idx*PIC_dx1, PIC_xmin + xmax_idx*PIC_dx1]\n",
    "    MHD_ylims = [PIC_ymin - ymin_idx*PIC_dx1, PIC_ymin + ymax_idx*PIC_dx1]\n",
    "    MHD_zlims = [PIC_zmin - zmin_idx*PIC_dx1, PIC_zmin + zmax_idx*PIC_dx1]\n",
    "\n",
    "    MHD_xaxis = np.arange(MHD_xlims[0],MHD_xlims[1]+PIC_dx1,PIC_dx1)\n",
    "    MHD_yaxis = np.arange(MHD_ylims[0],MHD_ylims[1]+PIC_dx1,PIC_dx1)\n",
    "    MHD_zaxis = np.arange(MHD_zlims[0],MHD_zlims[1]+PIC_dx1,PIC_dx1)\n",
    "    \n",
    "    MHD_files = get_files(dir,MHD_start_time,t_bound,MHD_dt,key=\"3d\\_\\_var\\_3\\_t.*\\.plt\",reduce = True)\n",
    "    for time in list(MHD_files.keys()): \n",
    "        print(\"Preprocessing MHD data for t =\",time)\n",
    "        file = str(MHD_files[time])\n",
    "    \n",
    "        # Read in dataset\n",
    "        dataset = read_dataset(dir+file,port=7605)\n",
    "        # Save .plt as numpy data\n",
    "        data = MHD_to_numpy(dataset,MHD_xaxis,MHD_yaxis,MHD_zaxis,var_ls=MHD_var_ls)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0f421ed8-1784-4118-804a-130926559b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## USER INPUT ##############################\n",
    "\n",
    "# Plotting control parameters\n",
    "# Directory data\n",
    "dir = \"/Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-234e/\"   # Directory with data \n",
    "#dir = \"/Volumes/My Book Duo/runs/nightside_v5_run1/ta-2/\"\n",
    "\n",
    "# Time range: this sets the times and timing of the plots\n",
    "t_bound = [42,60]    # Start and stop times of this data to be plot (cannot go beyond available PIC data time range)\n",
    "PIC_start_time = 30  # First time step of PIC data saved in this directory\n",
    "MHD_start_time = 40  # First time step of MHD data saved in this directory\n",
    "PIC_dt = 0.05  # File time cadence of PIC data [s]\n",
    "MHD_dt = 1 # File time cadence of MHD data [s]\n",
    "cell_size = R_M/64  # Edge length of Pic cell, in m\n",
    "\n",
    "# Spatial range: this sets the spatial extent of the data to be loaded in\n",
    "xlims = [-6.5,3.5]\n",
    "ylims = [-4,4.5]\n",
    "zlims = [-1,1.2]\n",
    "\n",
    "# Zoom region: where the data should be zoomed to view\n",
    "xlims_zoom = [-3,-1]\n",
    "ylims_zoom = [-1.5,1.5]\n",
    "zlims_zoom = [0,1]\n",
    "\n",
    "# Viewing angle\n",
    "azim = -150\n",
    "elev = 30\n",
    "\n",
    "# Smoothing scale (best to use 8, which is standard for PIC postproc)\n",
    "smoothing_param = 8\n",
    "\n",
    "# Testing -- enable if data is already read in and we are just adjusting a plot\n",
    "plot_testing = True\n",
    "\n",
    "# Plot presets\n",
    "plot_preset = \"hybrid_Jy\"\n",
    "'''\n",
    "\"hybrid_Bz1\": Bz1 in stated domain.\n",
    "\n",
    "\"hybrid_Jy\": Jy in stated domain.\n",
    "'''\n",
    "\n",
    "############################## USER INPUT ##############################\n",
    "\n",
    "var_matching = {\"X\":\"X\",\"Y\":\"Y\",\"Z\":\"Z\",\n",
    "                \"Bx\":\"B_x [[]nT[]]\",\"By\":\"B_y [[]nT[]]\",\"Bz\":\"B_z [[]nT[]]\",\n",
    "                \"Ex\":None,\"Ey\":None,\"Ez\":None,\n",
    "                \"rhoS0\":\"Rho [[]amu/cm^3[]]\",\n",
    "                \"uxS0\":None,\"uyS0\":None,\"uzS0\":None,\n",
    "                \"pxxS0\":None,\"pyyS0\":None,\"pzzS0\":None,\"pxyS0\":None,\"pxzS0\":None,\"pyzS0\":None,\n",
    "                \"rhoS1\":\"Rho [[]amu/cm^3[]]\",\n",
    "                \"uxS1\":\"U_x [[]km/s[]]\",\"uyS1\":\"U_y [[]km/s[]]\",\"uzS1\":\"U_z [[]km/s[]]\",\n",
    "                \"pxxS1\":None,\"pyyS1\":None,\"pzzS1\":None,\"pxyS1\":None,\"pxzS1\":None,\"pyzS1\":None,\n",
    "                \"Jx\":\"J_x [[]`mA/m^2[]]\",\"Jy\":\"J_y [[]`mA/m^2[]]\",\"Jz\":\"J_z [[]`mA/m^2[]]\",\n",
    "                \"dp_dx\":\"dp_dx\",\"dp_dy\":\"dp_dy\",\"dp_dz\":\"dp_dz\",\n",
    "                \"dB_dx\":\"dB_dx\",\"dB_dy\":\"dB_dy\",\"dB_dz\":\"dB_dz\",\n",
    "                \"duix_dx\":\"dux_dx\",\"duiy_dx\":\"duy_dx\",\"duiz_dx\":\"duz_dx\",\n",
    "                \"duix_dy\":\"dux_dy\",\"duiy_dy\":\"duy_dy\",\"duiz_dy\":\"duz_dy\",\n",
    "                \"duix_dz\":\"dux_dz\",\"duiy_dz\":\"duy_dz\",\"duiz_dz\":\"duz_dz\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6c65cf7d-579b-40c9-be00-7826ddeeda50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotmode: hybrid_Jy\n",
      "Plotting t = 42.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l9/dnt9qhfd1psfsmj9t5zfr0j00000gq/T/ipykernel_63582/65533657.py:289: RuntimeWarning: invalid value encountered in divide\n",
      "  J_para = ((Bx3d*Jx3d + By3d*Jy3d + Bz3d*Jz3d) / np.sqrt(Bx3d**2+By3d**2+Bz3d**2)) # nA/m^2\n",
      "/var/folders/l9/dnt9qhfd1psfsmj9t5zfr0j00000gq/T/ipykernel_63582/65533657.py:370: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  seeds[iseed][2] = griddata(points,values,seeds[iseed,0:2])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved as /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-234e_plots/hybrid_Jy_42.00.png\n",
      "Plotting t = 42.05\n",
      "Saved as /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-234e_plots/hybrid_Jy_42.05.png\n",
      "Plotting t = 42.1\n",
      "Saved as /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-234e_plots/hybrid_Jy_42.10.png\n",
      "Plotting t = 42.15\n",
      "Saved as /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-234e_plots/hybrid_Jy_42.15.png\n",
      "Plotting t = 42.2\n",
      "Saved as /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-234e_plots/hybrid_Jy_42.20.png\n",
      "Plotting t = 42.25\n",
      "Saved as /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-234e_plots/hybrid_Jy_42.25.png\n",
      "Plotting t = 42.3\n",
      "Saved as /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-234e_plots/hybrid_Jy_42.30.png\n",
      "Plotting t = 42.35\n",
      "Saved as /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-234e_plots/hybrid_Jy_42.35.png\n",
      "Plotting t = 42.4\n",
      "Saved as /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-234e_plots/hybrid_Jy_42.40.png\n",
      "Plotting t = 42.45\n",
      "Saved as /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-234e_plots/hybrid_Jy_42.45.png\n",
      "Plotting t = 42.5\n",
      "Saved as /Users/atcushen/Documents/MercuryModelling/runs/nightside_v4_run1/ta-234e_plots/hybrid_Jy_42.50.png\n",
      "Plotting t = 42.55\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 456\u001b[0m\n\u001b[1;32m    453\u001b[0m         ax\u001b[38;5;241m.\u001b[39mscatter(xlims_zoom[\u001b[38;5;241m1\u001b[39m],ylims_zoom[\u001b[38;5;241m1\u001b[39m],label,color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;66;03m# Save\u001b[39;00m\n\u001b[0;32m--> 456\u001b[0m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_plots/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mplot_preset\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mtime_str\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbbox_inches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mpad_inches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved as\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mdir\u001b[39m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_plots/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mplot_preset\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mtime_str\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m    458\u001b[0m plt\u001b[38;5;241m.\u001b[39mclose(fig)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/matplotlib/figure.py:3395\u001b[0m, in \u001b[0;36mFigure.savefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   3393\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes:\n\u001b[1;32m   3394\u001b[0m         _recursively_make_axes_transparent(stack, ax)\n\u001b[0;32m-> 3395\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/matplotlib/backend_bases.py:2175\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2172\u001b[0m     \u001b[38;5;66;03m# we do this instead of `self.figure.draw_without_rendering`\u001b[39;00m\n\u001b[1;32m   2173\u001b[0m     \u001b[38;5;66;03m# so that we can inject the orientation\u001b[39;00m\n\u001b[1;32m   2174\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(renderer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_draw_disabled\u001b[39m\u001b[38;5;124m\"\u001b[39m, nullcontext)():\n\u001b[0;32m-> 2175\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bbox_inches:\n\u001b[1;32m   2177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/matplotlib/artist.py:95\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw_wrapper\u001b[39m(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 95\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m renderer\u001b[38;5;241m.\u001b[39m_rasterizing:\n\u001b[1;32m     97\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/matplotlib/figure.py:3162\u001b[0m, in \u001b[0;36mFigure.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3159\u001b[0m             \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[1;32m   3161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[0;32m-> 3162\u001b[0m     \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3165\u001b[0m     renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigure\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   3166\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/matplotlib/image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[0;32m--> 132\u001b[0m         \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/mpl_toolkits/mplot3d/axes3d.py:452\u001b[0m, in \u001b[0;36mAxes3D.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m artist \u001b[38;5;129;01min\u001b[39;00m collections_and_patches:\n\u001b[0;32m--> 452\u001b[0m         \u001b[43martist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_3d_projection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_axis3don:\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;66;03m# Draw panes first\u001b[39;00m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_axis_map\u001b[38;5;241m.\u001b[39mvalues():\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/mpl_toolkits/mplot3d/art3d.py:1039\u001b[0m, in \u001b[0;36mPoly3DCollection.do_3d_projection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         cedge \u001b[38;5;241m=\u001b[39m cedge\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;28mlen\u001b[39m(xyzlist), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xyzlist:\n\u001b[1;32m   1038\u001b[0m     \u001b[38;5;66;03m# sort by depth (furthest drawn first)\u001b[39;00m\n\u001b[0;32m-> 1039\u001b[0m     z_segments_2d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_zsortfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mys\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mxyzlist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcface\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcedge\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1045\u001b[0m     _, segments_2d, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_facecolors2d, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_edgecolors2d, idxs \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m   1046\u001b[0m         \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mz_segments_2d)\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/mpl_toolkits/mplot3d/art3d.py:1040\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         cedge \u001b[38;5;241m=\u001b[39m cedge\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;28mlen\u001b[39m(xyzlist), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xyzlist:\n\u001b[1;32m   1038\u001b[0m     \u001b[38;5;66;03m# sort by depth (furthest drawn first)\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m     z_segments_2d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\n\u001b[0;32m-> 1040\u001b[0m         ((\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_zsortfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzs\u001b[49m\u001b[43m)\u001b[49m, np\u001b[38;5;241m.\u001b[39mcolumn_stack([xs, ys]), fc, ec, idx)\n\u001b[1;32m   1041\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m idx, ((xs, ys, zs), fc, ec)\n\u001b[1;32m   1042\u001b[0m          \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(xyzlist, cface, cedge))),\n\u001b[1;32m   1043\u001b[0m         key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m0\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1045\u001b[0m     _, segments_2d, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_facecolors2d, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_edgecolors2d, idxs \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m   1046\u001b[0m         \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mz_segments_2d)\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/numpy/lib/function_base.py:520\u001b[0m, in \u001b[0;36maverage\u001b[0;34m(a, axis, weights, returned, keepdims)\u001b[0m\n\u001b[1;32m    517\u001b[0m     keepdims_kw \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims}\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 520\u001b[0m     avg \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkeepdims_kw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m     avg_as_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(avg)\n\u001b[1;32m    522\u001b[0m     scl \u001b[38;5;241m=\u001b[39m avg_as_array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype(a\u001b[38;5;241m.\u001b[39msize\u001b[38;5;241m/\u001b[39mavg_as_array\u001b[38;5;241m.\u001b[39msize)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/numpy/core/_methods.py:112\u001b[0m, in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# Cast bool, unsigned int, and int to float64 by default\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43missubclass\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mnt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minteger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbool_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    113\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m mu\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(arr\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, nt\u001b[38;5;241m.\u001b[39mfloat16):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _draw_all_if_interactive at 0x10ec16dc0> (for post_execute):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function flush_figures at 0x10ebd9430> (for post_execute):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/matplotlib_inline/backend_inline.py:126\u001b[0m, in \u001b[0;36mflush_figures\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m InlineBackend\u001b[38;5;241m.\u001b[39minstance()\u001b[38;5;241m.\u001b[39mclose_figures:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;66;03m# ignore the tracking, just draw and close all figures\u001b[39;00m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 126\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    128\u001b[0m         \u001b[38;5;66;03m# safely show traceback if in IPython, else raise\u001b[39;00m\n\u001b[1;32m    129\u001b[0m         ip \u001b[38;5;241m=\u001b[39m get_ipython()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/matplotlib_inline/backend_inline.py:90\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m figure_manager \u001b[38;5;129;01min\u001b[39;00m Gcf\u001b[38;5;241m.\u001b[39mget_all_fig_managers():\n\u001b[0;32m---> 90\u001b[0m         \u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfigure_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fetch_figure_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfigure_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     show\u001b[38;5;241m.\u001b[39m_to_draw \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/display_functions.py:298\u001b[0m, in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m     publish_display_data(data\u001b[38;5;241m=\u001b[39mobj, metadata\u001b[38;5;241m=\u001b[39mmetadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 298\u001b[0m     format_dict, md_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m format_dict:\n\u001b[1;32m    300\u001b[0m         \u001b[38;5;66;03m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/formatters.py:179\u001b[0m, in \u001b[0;36mDisplayFormatter.format\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    177\u001b[0m md \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;66;03m# FIXME: log the exception\u001b[39;00m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[1;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[0;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/formatters.py:223\u001b[0m, in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 223\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;66;03m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_return(\u001b[38;5;28;01mNone\u001b[39;00m, args[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/formatters.py:340\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprinter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[1;32m    342\u001b[0m method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/pylabtools.py:152\u001b[0m, in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_bases\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[1;32m    150\u001b[0m     FigureCanvasBase(fig)\n\u001b[0;32m--> 152\u001b[0m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbytes_io\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m data \u001b[38;5;241m=\u001b[39m bytes_io\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fmt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/matplotlib/backend_bases.py:2175\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2172\u001b[0m     \u001b[38;5;66;03m# we do this instead of `self.figure.draw_without_rendering`\u001b[39;00m\n\u001b[1;32m   2173\u001b[0m     \u001b[38;5;66;03m# so that we can inject the orientation\u001b[39;00m\n\u001b[1;32m   2174\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(renderer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_draw_disabled\u001b[39m\u001b[38;5;124m\"\u001b[39m, nullcontext)():\n\u001b[0;32m-> 2175\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bbox_inches:\n\u001b[1;32m   2177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/matplotlib/artist.py:95\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw_wrapper\u001b[39m(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 95\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m renderer\u001b[38;5;241m.\u001b[39m_rasterizing:\n\u001b[1;32m     97\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/matplotlib/figure.py:3162\u001b[0m, in \u001b[0;36mFigure.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3159\u001b[0m             \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[1;32m   3161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[0;32m-> 3162\u001b[0m     \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3165\u001b[0m     renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigure\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   3166\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/matplotlib/image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[0;32m--> 132\u001b[0m         \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/mpl_toolkits/mplot3d/axes3d.py:452\u001b[0m, in \u001b[0;36mAxes3D.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m artist \u001b[38;5;129;01min\u001b[39;00m collections_and_patches:\n\u001b[0;32m--> 452\u001b[0m         \u001b[43martist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_3d_projection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_axis3don:\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;66;03m# Draw panes first\u001b[39;00m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_axis_map\u001b[38;5;241m.\u001b[39mvalues():\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/mpl_toolkits/mplot3d/art3d.py:1045\u001b[0m, in \u001b[0;36mPoly3DCollection.do_3d_projection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xyzlist:\n\u001b[1;32m   1038\u001b[0m     \u001b[38;5;66;03m# sort by depth (furthest drawn first)\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m     z_segments_2d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\n\u001b[1;32m   1040\u001b[0m         ((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_zsortfunc(zs), np\u001b[38;5;241m.\u001b[39mcolumn_stack([xs, ys]), fc, ec, idx)\n\u001b[1;32m   1041\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m idx, ((xs, ys, zs), fc, ec)\n\u001b[1;32m   1042\u001b[0m          \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(xyzlist, cface, cedge))),\n\u001b[1;32m   1043\u001b[0m         key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m0\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 1045\u001b[0m     _, segments_2d, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_facecolors2d, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_edgecolors2d, idxs \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m   1046\u001b[0m         \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mz_segments_2d)\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1048\u001b[0m     segments_2d \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Begin plotting\n",
    "# Get all the files in the time range\n",
    "PIC_files_3D = get_files(dir,PIC_start_time,t_bound,PIC_dt,key=\"3d\\_fluid.*numpy\\_t\\_...\\...\",read_time = True,reduce = True)\n",
    "PIC_files_cs = get_files(dir,PIC_start_time,t_bound,PIC_dt,key=\"3d\\_fluid.*csdata\\_t\\_...\\...\",read_time = True,reduce = True)\n",
    "MHD_files_3D = get_files(dir,MHD_start_time,t_bound,MHD_dt,key=\"3d\\_\\_var\\_3\\_t.*numpy\\_t\\_...\\...\",read_time = True,reduce = True)\n",
    "MHD_files_cs = get_files(dir,MHD_start_time,t_bound,MHD_dt,key=\"3d\\_\\_var\\_3\\_t.*csdata\\_t\\_...\\...\",read_time = True,reduce = True)\n",
    "\n",
    "# Begin iteration loop\n",
    "iter = 0\n",
    "print(\"Plotmode:\",plot_preset)\n",
    "for time_str in list(PIC_files_3D.keys()): \n",
    "    time = float(time_str)\n",
    "    print(\"Plotting t =\",time)\n",
    "\n",
    "    ############################## DATASET FORMATION START ##############################\n",
    "\n",
    "    if not plot_testing:\n",
    "        # Read in the 3D PIC data\n",
    "        my_file = str(PIC_files_3D[time_str])\n",
    "        with open(dir+my_file, 'rb') as f:\n",
    "            PIC_data_3D = pickle.load(f) \n",
    "    \n",
    "        # Read in the cs PIC data\n",
    "        my_file = str(PIC_files_cs[time_str])\n",
    "        with open(dir+my_file, 'rb') as f:\n",
    "            PIC_data_cs = pickle.load(f) \n",
    "    \n",
    "        # Compute the coordinate axes for the data\n",
    "        if iter==0:\n",
    "            dx_ls = []\n",
    "            for i in range(1,len(PIC_data_3D['X'][0,:,0])):\n",
    "            \n",
    "                dx_ls.append(PIC_data_3D['X'][0,i,0] - PIC_data_3D['X'][0,i-1,0])\n",
    "            PIC_dx = np.mean(dx_ls)\n",
    "            \n",
    "            xmin_idx = int(round((np.min(PIC_data_3D['X']) - xlims[0])/PIC_dx,0)) # How many PIC_dx between PIC_xmin and preproc_xlims[0]\n",
    "            ymin_idx = int(round((np.min(PIC_data_3D['Y']) - ylims[0])/PIC_dx,0))\n",
    "            zmin_idx = int(round((np.min(PIC_data_3D['Z']) - zlims[0])/PIC_dx,0))\n",
    "            xmax_idx = int(round((xlims[1] - np.min(PIC_data_3D['X']))/PIC_dx,0))\n",
    "            ymax_idx = int(round((ylims[1] - np.min(PIC_data_3D['Y']))/PIC_dx,0))\n",
    "            zmax_idx = int(round((zlims[1] - np.min(PIC_data_3D['Z']))/PIC_dx,0))\n",
    "            \n",
    "            corrected_xlims = [np.min(PIC_data_3D['X']) - xmin_idx*PIC_dx, np.min(PIC_data_3D['X']) + xmax_idx*PIC_dx]\n",
    "            corrected_ylims = [np.min(PIC_data_3D['Y']) - ymin_idx*PIC_dx, np.min(PIC_data_3D['Y']) + ymax_idx*PIC_dx]\n",
    "            corrected_zlims = [np.min(PIC_data_3D['Z']) - zmin_idx*PIC_dx, np.min(PIC_data_3D['Z']) + zmax_idx*PIC_dx]\n",
    "            \n",
    "            x_axis = np.arange(corrected_xlims[0],corrected_xlims[1]+PIC_dx,PIC_dx)\n",
    "            y_axis = np.arange(corrected_ylims[0],corrected_ylims[1]+PIC_dx,PIC_dx)\n",
    "            z_axis = np.arange(corrected_zlims[0],corrected_zlims[1]+PIC_dx,PIC_dx)\n",
    "            print(\"Total number of cells to load:\", x_axis.shape[0]*y_axis.shape[0]*z_axis.shape[0])\n",
    "    \n",
    "        # Create data structures for the desired spatial range\n",
    "        data3D={}\n",
    "        datacs={}\n",
    "    \n",
    "        # Check if we need to load in MHD data to fill gaps (usually is the case)\n",
    "        add_MHD = np.min(PIC_data_3D['X']) > corrected_xlims[0] or np.min(PIC_data_3D['X']) < corrected_xlims[0] or np.min(PIC_data_3D['Y']) > corrected_ylims[0] or np.max(PIC_data_3D['Y']) < corrected_ylims[1] or np.min(PIC_data_3D['Z']) > corrected_zlims[0] or np.max(PIC_data_3D['Z']) < corrected_zlims[1]\n",
    "        if add_MHD:\n",
    "            # Determine the closest available MHD time\n",
    "            MHD_time = min(list(MHD_files_3D.keys()), key=lambda s: abs(float(s) - time))\n",
    "            print(\"MHD_TIME:\",MHD_time)\n",
    "            # Read in 3D MHD data\n",
    "            my_file = str(MHD_files_3D[MHD_time])\n",
    "            with open(dir+my_file, 'rb') as f:\n",
    "                MHD_data_3D = pickle.load(f)\n",
    "            # Read in cs MHD data\n",
    "            my_file = str(MHD_files_cs[MHD_time])\n",
    "            with open(dir+my_file, 'rb') as f:\n",
    "                MHD_data_cs = pickle.load(f)\n",
    "    \n",
    "            # Determine the scale factor used for MHD data compression\n",
    "            dx_factor = int(round((MHD_data_cs['X'][0,1] - MHD_data_cs['X'][0,0])/PIC_dx,0))\n",
    "    \n",
    "        # Move all of the PIC data into the correct slots\n",
    "        for key, var_data in PIC_data_3D.items():\n",
    "            #if key in ['X', 'Y', 'Z']:\n",
    "            #    continue\n",
    "            # If we are adding MHD data, we use that as our baseline to overwrite\n",
    "            if add_MHD:\n",
    "                # The MHD_data has been downscaled by a factor of dx_factor, and covers a larger area than we want.\n",
    "                # We first need to cut it down to the region of interest, and then increase its resolution\n",
    "                # First, work out the region of MHD data we want\n",
    "                MHD_key = var_matching[key]\n",
    "                MHD_trim_mask_3D = (MHD_data_3D['X']>=corrected_xlims[0]) & (MHD_data_3D['X']<=corrected_xlims[1]) & (MHD_data_3D['Y']>=corrected_ylims[0]) & (MHD_data_3D['Y']<=corrected_ylims[1]) & (MHD_data_3D['Z']>=corrected_zlims[0]) & (MHD_data_3D['Z']<=corrected_zlims[1])\n",
    "                #MHD_trim_mask_cs = (MHD_data_cs['X']>=corrected_xlims[0]) & (MHD_data_cs['X']<=corrected_xlims[1]) & (MHD_data_cs['Y']>=corrected_ylims[0]) & (MHD_data_cs['Y']<=corrected_ylims[1])\n",
    "                \n",
    "                mask_indices = np.where(MHD_trim_mask_3D)\n",
    "                min_indices = np.min(mask_indices, axis=1)\n",
    "                max_indices = np.max(mask_indices, axis=1) + 1  # Add 1 for inclusive slicing\n",
    "    \n",
    "                \n",
    "                # Make sure this data is available and translateable\n",
    "                # NOTE: SPECIAL CASES NEEDED TO BE ADDED\n",
    "                if MHD_key is not None and MHD_key in MHD_data_3D.keys():\n",
    "                    variable_available = True\n",
    "                    if iter==0:\n",
    "                        print(\"Adding MHD data:\",MHD_key,\" -> \",key)\n",
    "                    \n",
    "                    # Slice the large MHD data according to our indices\n",
    "                    sliced_MHD_data_3D = MHD_data_3D[MHD_key][min_indices[0]:max_indices[0],\n",
    "                                                min_indices[1]:max_indices[1],min_indices[2]:max_indices[2]]\n",
    "                    sliced_MHD_data_cs = MHD_data_cs[MHD_key][min_indices[0]:max_indices[0],\n",
    "                                                min_indices[1]:max_indices[1]]\n",
    "    \n",
    "                    # Then, zoom in by dx_factor\n",
    "                    # Calculate the zoom factors for each dimension\n",
    "                    zoom_factors_3D = [dx_factor,dx_factor,dx_factor] #[n/o for n, o in zip(data3D['X'].shape, MHD_data_3D[MHD_key].shape)]\n",
    "                    zoom_factors_cs = [dx_factor,dx_factor] #[n/o for n, o in zip(datacs['X'].shape, MHD_data_cs[MHD_key].shape)]\n",
    "                    \n",
    "                    # Interpolate to the new shape\n",
    "                    zoomed_MHD_data_3D = zoom(sliced_MHD_data_3D, zoom_factors_3D, order=1)\n",
    "                    zoomed_MHD_data_cs = zoom(sliced_MHD_data_cs, zoom_factors_cs, order=1)\n",
    "    \n",
    "                    # Correct the units of Jy, since PIC saves as A/m^2 and MHD in mA/m^2\n",
    "                    if key in [\"Jx\",\"Jy\",\"Jz\"]:\n",
    "                        zoomed_MHD_data_3D = zoomed_MHD_data_3D * 1e-6\n",
    "                        zoomed_MHD_data_cs = zoomed_MHD_data_cs * 1e-6\n",
    "                        \n",
    "                    # Use this zoomed MHD data as the backdrop for this variable\n",
    "                    new_3D_elem = np.copy(zoomed_MHD_data_3D)\n",
    "                    new_cs_elem = np.copy(zoomed_MHD_data_cs)\n",
    "    \n",
    "                    # Debug: show results\n",
    "                    '''\n",
    "                    plt.imshow(new_cs_elem,origin='lower',extent = [*corrected_xlims,*corrected_ylims])\n",
    "                    plt.title(str(MHD_key+\" -> \"+key))\n",
    "                    plt.colorbar()\n",
    "                    plt.show()\n",
    "                    plt.close()\n",
    "                    '''\n",
    "                \n",
    "                else:\n",
    "                    variable_available = False\n",
    "                    if iter==0:\n",
    "                        print(\"PIC data\",key,\"is not available in MHD\")\n",
    "                    new_3D_elem = np.zeros_like(data3D['X'],dtype=float)\n",
    "                    new_cs_elem = np.zeros_like(datacs['X'],dtype=float)\n",
    "                \n",
    "            else:\n",
    "                new_3D_elem = np.zeros_like(data3D['X'],dtype=float)\n",
    "                new_cs_elem = np.zeros_like(datacs['X'],dtype=float)\n",
    "            \n",
    "            # Overwrite MHD data with PIC\n",
    "            new_3D_elem[ymin_idx:ymin_idx+len(PIC_data_3D['X'][:,0,0]),xmin_idx:xmin_idx+len(PIC_data_3D['X'][0,:,0]),zmin_idx:zmin_idx+len(PIC_data_3D['X'][0,0,:])] = var_data\n",
    "            new_cs_elem[ymin_idx:ymin_idx+len(PIC_data_cs['X'][:,0]),xmin_idx:xmin_idx+len(PIC_data_cs['X'][0,:])] = PIC_data_cs[key]\n",
    "    \n",
    "            # We need to overwrite the region close to the planet where PIC data is all 0\n",
    "            # For this to work, it relies on Bx being the first variable added to data3d/datacs\n",
    "            if key not in ['X', 'Y', 'Z'] and variable_available:\n",
    "                correction_mask_3D = (new_3D_elem == 0) & (data3D['X']>=np.min(PIC_data_3D['X'])) & (data3D['X']<=np.max(PIC_data_3D['X'])) & (data3D['Y']>=np.min(PIC_data_3D['Y'])) & (data3D['Y']<=np.max(PIC_data_3D['Y'])) & (data3D['Z']>=np.min(PIC_data_3D['Z'])) & (data3D['Z']<=np.max(PIC_data_3D['Z']))\n",
    "                correction_mask_cs = (new_cs_elem == 0) & (datacs['X']>=np.min(PIC_data_cs['X'])) & (datacs['X']<=np.max(PIC_data_cs['X'])) & (datacs['Y']>=np.min(PIC_data_cs['Y'])) & (datacs['Y']<=np.max(PIC_data_cs['Y']))\n",
    "                new_3D_elem[correction_mask_3D] = zoomed_MHD_data_3D[correction_mask_3D]\n",
    "                new_cs_elem[correction_mask_cs] = zoomed_MHD_data_cs[correction_mask_cs]\n",
    "            \n",
    "            # Save the hybrid array\n",
    "            data3D[key] = new_3D_elem\n",
    "            datacs[key] = new_cs_elem\n",
    "    \n",
    "        # Resmooth the cs array\n",
    "        datacs['Z'] = smooth_meshgrid(datacs['X'], datacs['Y'], datacs['Z'], smoothing_param)\n",
    "    \n",
    "        # Add a pic_active array\n",
    "        pic_active_3D = np.zeros_like(data3D['X'])\n",
    "        pic_active_3D[(data3D['X']>=np.min(PIC_data_3D['X'])) & (data3D['X']<=np.max(PIC_data_3D['X'])) & (data3D['Y']>=np.min(PIC_data_3D['Y'])) & (data3D['Y']<=np.max(PIC_data_3D['Y'])) & (data3D['Z']>=np.min(PIC_data_3D['Z'])) & (data3D['Z']<=np.max(PIC_data_3D['Z']))] = 1\n",
    "        data3D['pic_active'] = pic_active_3D\n",
    "        pic_active_cs = np.zeros_like(datacs['X'])\n",
    "        pic_active_cs[(datacs['X']>=np.min(PIC_data_cs['X'])) & (datacs['X']<=np.max(PIC_data_cs['X'])) & (datacs['Y']>=np.min(PIC_data_cs['Y'])) & (datacs['Y']<=np.max(PIC_data_cs['Y']))] = 1\n",
    "        data3D['pic_active'] = pic_active_cs\n",
    "    \n",
    "        ############################## DATASET FORMATION COMPLETE ##############################\n",
    "\n",
    "    # PLOT PRESET 'hybrid_Bz1'\n",
    "    if plot_preset=='hybrid_Bz1':\n",
    "        fig = plt.figure(figsize=(13,6), constrained_layout=True)\n",
    "        ax = fig.add_subplot(111, projection=\"3d\",computed_zorder=False)\n",
    "\n",
    "        # Unpack variables\n",
    "        X = datacs[\"X\"]\n",
    "        Y = datacs[\"Y\"]\n",
    "        Z = datacs[\"Z\"]\n",
    "        Bzcs = datacs[\"Bz\"]\n",
    "        Bz1cs = Bzcs - Bz_dip(X,Y,Z)\n",
    "        \n",
    "        X3d = data3D[\"X\"]\n",
    "        Y3d = data3D[\"Y\"]\n",
    "        Z3d = data3D[\"Z\"]\n",
    "        Bz3d = data3D[\"Bz\"]\n",
    "        Bz13d = Bz3d - Bz_dip(X3d,Y3d,Z3d)\n",
    "\n",
    "        # Mask out values in core\n",
    "        radius = 0.8\n",
    "        mask = (X**2 + Y**2) < radius**2\n",
    "        Z[mask] = np.nan\n",
    "\n",
    "        # Define cutoff for midnight plane\n",
    "        mid = int((0.5 - (0.5/180) * (azim))*len(Y[:,0]))\n",
    "        # Define colormap and lighting\n",
    "        vmin=-100\n",
    "        vmax=0\n",
    "        norm = plt.Normalize(vmin,vmax)\n",
    "        dawn_colors = cm.plasma(norm(Bz1cs[:mid,:]),alpha=0.5)\n",
    "        dusk_colors = cm.plasma(norm(Bz1cs[mid:,:]),alpha=0.5)\n",
    "\n",
    "        # Set the lighting\n",
    "        light = LightSource()  # Azimuth and altitude of the light source\n",
    "        dawn_illuminated_colors = light.shade_rgb(dawn_colors, Z[:mid,:], blend_mode='soft')  # Apply light source shading\n",
    "        dusk_illuminated_colors = light.shade_rgb(dusk_colors, Z[mid:,:], blend_mode='soft')  # Apply light source shading\n",
    "\n",
    "        # move camera view\n",
    "        ax.view_init(elev=elev, azim=azim)\n",
    "\n",
    "        # Create the surface plot\n",
    "        surf1 = ax.plot_surface(X[:mid,:], Y[:mid,:], Z[:mid,:], facecolors=dawn_illuminated_colors, rstride=1, cstride=1, antialiased=False, zorder=2)\n",
    "        surf2 = ax.plot_surface(X[mid:,:], Y[mid:,:], Z[mid:,:], facecolors=dusk_illuminated_colors, rstride=1, cstride=1, antialiased=False, zorder=1)\n",
    "        plot_sphere(ax,u = np.linspace(0, 2 * np.pi, 200), v = np.linspace(0, np.pi/2, 100),\n",
    "                    radius=1, color='lightgrey', alpha=0.5, zorder=1)\n",
    "        plot_sphere(ax,u = np.linspace(0, 2 * np.pi, 200), v = np.linspace(0, np.pi/2, 100),\n",
    "                    radius=0.8, color='grey', alpha=1, zorder=1.25)\n",
    "        #plot_sphere(ax,radius=0.8,color='grey',alpha=1,zorder=1.25)\n",
    "        \n",
    "        # Add isosurfaces\n",
    "        #b1min = 0\n",
    "        #iso = ax.scatter(X3d[Bz13d>b1min],Y3d[Bz13d>b1min],Z3d[Bz13d>b1min],c=Bz13d[Bz13d>b1min],\n",
    "         #                vmin=vmin,vmax=vmax,cmap='plasma',s=1,alpha=0.5)\n",
    "\n",
    "        # Add a color bar \n",
    "        m = cm.ScalarMappable(cmap=cm.plasma, norm=norm)\n",
    "        m.set_array(Bz1cs)\n",
    "        clb = fig.colorbar(m, ax=ax, shrink=0.3, aspect=7,anchor=(0.5,0.3))\n",
    "        clb.ax.tick_params(labelsize=12)\n",
    "        clb.ax.set_title('$B_{z1}$ [nT]',fontsize=12,pad=10)\n",
    "\n",
    "        # Set axes\n",
    "        z_lower = -0.6\n",
    "        z_upper = 1.0\n",
    "        ax.set_zlim(z_lower,z_upper)\n",
    "        x_range = X.max() - X.min()\n",
    "        y_range = Y.max() - Y.min()\n",
    "        z_range = z_upper - z_lower\n",
    "        ax.set_box_aspect([x_range, y_range, z_range])  # Aspect ratio is set based on the data limits\n",
    "        \n",
    "        # Add labels\n",
    "        ax.set_xlabel(\"X [$R_M$]\",fontsize=12)\n",
    "        ax.set_ylabel(\"Y [$R_M$]\",fontsize=12)\n",
    "        ax.set_zlabel(\"Z [$R_M$]\",fontsize=12)\n",
    "        ax.tick_params(axis='both',labelsize=12)\n",
    "        ax.set_title(str(\"$B_{z1}$ at t=\"+time_str+\"s\"),fontsize=12,y=1.0, pad=-14)\n",
    "\n",
    "        # Save\n",
    "        fig.savefig(str(str(dir[:-1])+\"_plots/\"+plot_preset+\"_\"+time_str+'.png'),bbox_inches='tight',pad_inches=0.3, dpi=300)\n",
    "        print(\"Saved as\",str(str(dir[:-1])+\"_plots/\"+plot_preset+\"_\"+time_str+'.png'))\n",
    "        plt.close(fig)\n",
    "\n",
    "\n",
    "    # PLOT PRESET 'hybrid_Jy'\n",
    "    if plot_preset=='hybrid_Jy':\n",
    "        fig = plt.figure(figsize=(13,6), constrained_layout=True)\n",
    "        ax = fig.add_subplot(111, projection=\"3d\",computed_zorder=False)\n",
    "        \n",
    "        # Unpack variables\n",
    "        X = datacs[\"X\"]\n",
    "        Y = datacs[\"Y\"]\n",
    "        Z = datacs[\"Z\"]\n",
    "        Jy = datacs[\"Jy\"]*1e9 # convert to nA\n",
    "        \n",
    "        X3d = data3D[\"X\"]\n",
    "        Y3d = data3D[\"Y\"]\n",
    "        Z3d = data3D[\"Z\"]\n",
    "        Bx3d = data3D[\"Bx\"]\n",
    "        By3d = data3D[\"By\"]\n",
    "        Bz3d = data3D[\"Bz\"]\n",
    "        Jx3d = data3D[\"Jx\"]*1e9\n",
    "        Jy3d = data3D[\"Jy\"]*1e9\n",
    "        Jz3d = data3D[\"Jz\"]*1e9\n",
    "\n",
    "        # Set up field line tracing\n",
    "        ny,nx,nz = Bx3d.shape\n",
    "        field = np.zeros((nx,ny,nz,3))\n",
    "        field[:,:,:,0] = np.transpose(Bx3d,axes=[1,0,2])\n",
    "        field[:,:,:,1] = np.transpose(By3d,axes=[1,0,2])\n",
    "        field[:,:,:,2] = np.transpose(Bz3d,axes=[1,0,2])\n",
    "        grid_spacing = [1/64,1/64,1/64]\n",
    "        grid = VectorGrid(field, grid_spacing, origin_coord = [X3d.min(),Y3d.min(),Z3d.min()])\n",
    "        nsteps = 10000\n",
    "        step_size = 0.001\n",
    "        tracer = StreamTracer(nsteps, step_size)\n",
    "\n",
    "        # Compute J_para\n",
    "        J_para = ((Bx3d*Jx3d + By3d*Jy3d + Bz3d*Jz3d) / np.sqrt(Bx3d**2+By3d**2+Bz3d**2)) # nA/m^2\n",
    "\n",
    "        # Define spherical section to project J_r onto\n",
    "        r_proj = 1.05\n",
    "        center = [0,0,0]\n",
    "        num_points = 512\n",
    "        u = np.linspace(0, 2 * np.pi, num_points)\n",
    "        v = np.linspace(0, np.pi/2, num_points)\n",
    "        x = r_proj * np.outer(np.cos(u), np.sin(v)) + center[0]\n",
    "        y = r_proj * np.outer(np.sin(u), np.sin(v)) + center[1]\n",
    "        z = r_proj * np.outer(np.ones(np.size(u)), np.cos(v)) + center[2]\n",
    "        mask = (z < 0.2) \n",
    "        x[mask] = np.nan\n",
    "        y[mask] = np.nan\n",
    "        z[mask] = np.nan\n",
    "        points = np.array([np.ravel(x), np.ravel(y), np.ravel(z)]).T\n",
    "        \n",
    "        # Interpolate J_r onto the spherical section\n",
    "        interpolator = RegularGridInterpolator((X3d[0,:,0], Y3d[:,0,0], Z3d[0,0,:]), J_para.transpose(1, 0, 2), bounds_error=False)\n",
    "        J_interp = interpolator(points).reshape(x.shape)\n",
    "        \n",
    "        # Mask out values in core\n",
    "        radius = 0.8\n",
    "        mask = (X**2 + Y**2) < radius**2\n",
    "        Z[mask] = np.nan\n",
    "        \n",
    "        # Define cutoff for midnight plane\n",
    "        mid = len(Y[:,0])-3#int((0.5 - (0.5/180) * (azim))*len(Y[:,0]))\n",
    "        # Define colormap and lighting\n",
    "        vmin=-500\n",
    "        vmax=500\n",
    "        linthresh = 10  # Define the range around zero where the plot is linear\n",
    "        linscale = 1   # Scale factor for linear region\n",
    "        norm = SymLogNorm(linthresh=linthresh, linscale=linscale, vmin=vmin, vmax=vmax, base=10)\n",
    "        J_norm = SymLogNorm(linthresh=linthresh, linscale=linscale, vmin=vmin, vmax=vmax, base=10)\n",
    "        #norm = plt.Normalize(vmin,vmax)\n",
    "        dawn_colors = cm.PuOr(norm(Jy[:mid,:]),alpha=0.3)\n",
    "        dusk_colors = cm.PuOr(norm(Jy[mid:,:]),alpha=0.3)\n",
    "        J_colors = cm.coolwarm(J_norm(J_interp))\n",
    "        \n",
    "        # Set the lighting\n",
    "        light = LightSource()  # Azimuth and altitude of the light source\n",
    "        dawn_illuminated_colors = light.shade_rgb(dawn_colors, Z[:mid,:], blend_mode='soft')  # Apply light source shading\n",
    "        dusk_illuminated_colors = light.shade_rgb(dusk_colors, Z[mid:,:], blend_mode='soft')  # Apply light source shading\n",
    "        J_illuminated_colors = light.shade_rgb(J_colors, z, blend_mode='soft')\n",
    "        \n",
    "        # move camera view\n",
    "        ax.view_init(elev=elev, azim=azim)\n",
    "        \n",
    "        # Create the surface plot\n",
    "        surf1 = ax.plot_surface(X[:mid,:], Y[:mid,:], Z[:mid,:], facecolors=dawn_illuminated_colors, rstride=1, cstride=1, antialiased=False, zorder=-10)\n",
    "        surf2 = ax.plot_surface(X[mid:,:], Y[mid:,:], Z[mid:,:], facecolors=dusk_illuminated_colors, rstride=1, cstride=1, antialiased=False, zorder=-20)\n",
    "        J_plot = ax.plot_surface(x,y,z,facecolors=J_illuminated_colors, rstride=1, cstride=1, antialiased=False, zorder=2.1)\n",
    "        #plot_sphere(ax,u = np.linspace(0, 2 * np.pi, 200), v = np.linspace(0, np.pi/2, 100),\n",
    "        #        radius=1, color='lightgrey', alpha=0.3, zorder=2.1,zlims = [0.2,10])\n",
    "        #plot_sphere(ax,u = np.linspace(0, 2 * np.pi, 200), v = np.linspace(0, np.pi/2, 100),\n",
    "        #        radius=0.8, color='grey', alpha=1, zorder=2.2,zlims = [0.2,10])\n",
    "        \n",
    "        # Add isosurfaces\n",
    "        #J_mask = (Jy3d<-100) & (X3d<0.5) & (Z3d > 0.2) & (Z3d < 1.5) & (X3d**2+Y3d**2+Z3d**2>0.85**2)\n",
    "        #iso1 = ax.scatter(X3d[J_mask],Y3d[J_mask],Z3d[J_mask],c=(Jy3d[J_mask]),cmap='PuOr',norm=norm,\n",
    "        #                     s=0.5,zorder=3,alpha = 0.9)\n",
    "\n",
    "        # Define low-res grid for checking fieldline collisions\n",
    "        down_resolve=10\n",
    "        points = np.column_stack((X[::down_resolve,::down_resolve].ravel(), Y[::down_resolve,::down_resolve].ravel()))\n",
    "        values = Z[::down_resolve,::down_resolve].ravel()\n",
    "\n",
    "        # Trace fieldlines\n",
    "        # Trace the field lines\n",
    "        seeds = np.array([[-1.35,0.14,0.2],\n",
    "                         [-1.32,0.38,0.2],\n",
    "                         #[-1.44,-0.14,0.2],\n",
    "                         #[-1.50,-0.43,0.2],\n",
    "                         [-1.34,-0.23,0.2],\n",
    "                         [-1.4,-0.5,0.2]])\n",
    "                         #[-1.39,0.73,0.2],\n",
    "                         #[-1.39,1.2,0.2]])\n",
    "        seed_colors = [\"red\",\"blue\",\"blue\",\"red\"]\n",
    "        # Move the seeds down to the cs\n",
    "        for iseed in range(len(seeds)):\n",
    "            seeds[iseed][2] = griddata(points,values,seeds[iseed,0:2])\n",
    "        tracer.trace(seeds, grid)\n",
    "\n",
    "\n",
    "        # Plot them\n",
    "        for iseed in range(len(seeds)):\n",
    "            above = np.where(tracer.xs[iseed][:,2]>=griddata(points, values, tracer.xs[iseed][:,0:2], method='linear'))[0]\n",
    "            below = np.where(tracer.xs[iseed][:,2]<griddata(points, values, tracer.xs[iseed][:,0:2], method='linear'))[0]\n",
    "            # Plot the streamlines as a series of lines, without connecting between places where the indexing jumps\n",
    "            start = 0 \n",
    "            for j in range(1,len(above)):\n",
    "                if (above[j]-above[j-1]>1) or (j==(len(above)-1)):\n",
    "                    ax.plot(tracer.xs[iseed][above[start:j-1],0],tracer.xs[iseed][above[start:j-1],1],tracer.xs[iseed][above[start:j-1],2], \n",
    "                            color=seed_colors[iseed],lw=1,alpha=0.8,zorder=7) \n",
    "                    ax.scatter(*seeds[iseed],c=seed_colors[iseed],s=1.5)\n",
    "                    start = j\n",
    "                \n",
    "            #start = 0\n",
    "            #for j in range(1,len(below)):\n",
    "            #    if (below[j]-below[j-1]>1) or (j==(len(below)-1)):\n",
    "            #        ax.plot(tracer.xs[iseed][below[start:j-1],0],tracer.xs[iseed][below[start:j-1],1],tracer.xs[iseed][below[start:j-1],2],\n",
    "            #               color='black',lw=0.5,alpha=1,zorder=2.5) \n",
    "            #        start = j\n",
    "\n",
    "        \n",
    "        # Add a color bar \n",
    "        m1 = cm.ScalarMappable(cmap=cm.PuOr, norm=norm)\n",
    "        m2 = cm.ScalarMappable(cmap=cm.coolwarm, norm=J_norm)\n",
    "        m1.set_array(Jy)\n",
    "        m2.set_array(J_interp)\n",
    "        cbax1 = inset_axes(ax, width=\"30%\", height=\"30%\", loc=3) \n",
    "        clb1 = fig.colorbar(m1, ax=cbax1, shrink=0.3, aspect=7, anchor= (0.75,-0.02))\n",
    "        clb1.ax.tick_params(labelsize=12,labelcolor='white')\n",
    "        clb1.ax.set_title('$J_y$[nA/m$^2$]',fontsize=12,pad=10,color='white')\n",
    "        #cbax2 = inset_axes(ax, width=\"30%\", height=\"30%\", loc=3) \n",
    "        clb2 = fig.colorbar(m2, ax=cbax1, shrink=0.3, aspect=7, anchor= (0,-0.02))\n",
    "        clb2.ax.tick_params(labelsize=12,labelcolor='white')\n",
    "        clb2.ax.set_title('$J_{para}$[nA/m$^2$]',fontsize=12,pad=10,color='white')\n",
    "        \n",
    "        # Set axes\n",
    "        z_lower = -0.6\n",
    "        z_upper = 1.0\n",
    "        ax.set_zlim(z_lower,z_upper)\n",
    "        x_range = X.max() - X.min()\n",
    "        y_range = Y.max() - Y.min()\n",
    "        z_range = z_upper - z_lower\n",
    "        ax.set_box_aspect([x_range, y_range, z_range])  # Aspect ratio is set based on the data limits\n",
    "        \n",
    "        # Add labels\n",
    "        ax.set_xlabel(\"X [$R_M$]\",fontsize=12)\n",
    "        ax.set_ylabel(\"Y [$R_M$]\",fontsize=12,zorder=100)\n",
    "        ax.set_zlabel(\"Z [$R_M$]\",fontsize=12)\n",
    "        ax.tick_params(axis='both',labelsize=12,zorder=10)\n",
    "        #ax.set_title(str(\"$J_y$ at t=\"+time_str+\"s\"),fontsize=12,y=1.0, pad=-14)\n",
    "        \n",
    "        # Zoom to region of interest\n",
    "        ax.set_xlim(xlims_zoom)\n",
    "        ax.set_ylim(ylims_zoom)\n",
    "        ax.set_zlim(zlims_zoom)\n",
    "        \n",
    "        # Fix aspect ratio\n",
    "        x_range = xlims_zoom[1] - xlims_zoom[0]\n",
    "        y_range = ylims_zoom[1] - ylims_zoom[0]\n",
    "        z_range = zlims_zoom[1] - zlims_zoom[0]\n",
    "        ax.set_box_aspect([x_range, y_range, z_range])\n",
    "        \n",
    "        # Control axes \n",
    "        ax.set_axis_off()\n",
    "        cbax1.set_axis_off()\n",
    "        #cbax2.set_axis_off()\n",
    "        \n",
    "        # Manually draw axes\n",
    "        if -180<azim<-90:\n",
    "            # Lines\n",
    "            ax.plot(xlims_zoom,[ylims_zoom[1],ylims_zoom[1]],[0.2,0.2],color='black')\n",
    "            ax.plot([xlims_zoom[1],xlims_zoom[1]],ylims_zoom,[0.2,0.2],color='black')\n",
    "            ax.plot([xlims_zoom[1],xlims_zoom[1]],[ylims_zoom[1],ylims_zoom[1]],[0.2,zlims_zoom[1]],color='black')\n",
    "            # Markers\n",
    "            for label in np.arange(math.ceil(xlims_zoom[0]),math.floor(xlims_zoom[1]+1)):\n",
    "                ax.scatter(label,ylims_zoom[1],0.2,color='black')\n",
    "            for label in np.arange(float(np.fix(ylims_zoom[0])),float(np.fix(ylims_zoom[1]+1))):\n",
    "                ax.scatter(xlims_zoom[1],label,0.2,color='black')\n",
    "            for label in np.arange(math.ceil(0.2),math.floor(zlims_zoom[1])+1):\n",
    "                ax.scatter(xlims_zoom[1],ylims_zoom[1],label,color='black')\n",
    "\n",
    "        # Save\n",
    "        fig.savefig(str(str(dir[:-1])+\"_plots/\"+plot_preset+\"_\"+time_str+'.png'),bbox_inches='tight',pad_inches=0.3, dpi=300)\n",
    "        print(\"Saved as\",str(str(dir[:-1])+\"_plots/\"+plot_preset+\"_\"+time_str+'.png'))\n",
    "        plt.close(fig)\n",
    "        \n",
    "    iter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f91584f1-8010-4abd-9f4e-2e69722c0d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x15dbe9400>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(*seeds[iseed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b9b5632-ddbe-4857-a89a-ccf38860ce4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iseed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c99f4e-f809-4f4e-8ca6-3184c4a39793",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
